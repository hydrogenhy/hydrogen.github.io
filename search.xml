<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hi, 很高兴见到你</title>
    <url>/2023/07/17/Hi-%E5%BE%88%E9%AB%98%E5%85%B4%E8%A7%81%E5%88%B0%E4%BD%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>
        <div id="aplayer-tVoIbLMN" class="aplayer aplayer-tag-marker" style="margin-bottom: 20px;">
            <pre class="aplayer-lrc-content"></pre>
        </div>
        <script>
          var ap = new APlayer({
            element: document.getElementById("aplayer-tVoIbLMN"),
            narrow: false,
            autoplay: false,
            showlrc: false,
            music: {
              title: "日落大道",
              author: "梁博",
              url: "/music/日落大道.mp3",
              pic: "/music/日落大道.jpg",
              lrc: ""
            }
          });
          window.aplayers || (window.aplayers = []);
          window.aplayers.push(ap);
        </script>

<center><strong><font size="5">欢迎来到我的博客！</font></strong></center>

<p>&emsp;&emsp;在这里我将分享我的<strong>学习心得</strong>、<strong>some projects</strong>、<strong>吉他谱</strong>和<strong>一些个人想法</strong>等等。希望能够对你有所帮助。</p>
<p>&emsp;&emsp;创建博客博客的初衷，一是希望有个<strong>个人空间</strong>来存储我的经历，博客就是很好的选择；二是我希望我的心得能够让更多人看见，<strong>帮助一些人</strong>少走一些弯路——在学习过程中我被各路“开源”大佬的文章启发，因此我也想将我的思考“开源”出去。</p>
<p>&emsp;&emsp;整个博客使用<code>hexo</code>搭建，主题是<code>ayer</code>。这两个链接我放在了“<strong>友链</strong>”中供大家参考。此外也运用了如播放器、搜索等功能，大家可自行去探索<code>hexo</code>的诸多功能。</p>
<p>&emsp;<strong>&emsp;那么，enjoy！！！; -)</strong></p>
<p><del>所以你是被谁骗到这里的？</del></p>
<p><strong>既然来了，Why not leave a comment ? （要先点进此博客）</strong> </p>
<p align="right"><strong>2023.07.17</strong></p>

]]></content>
      <tags>
        <tag>About</tag>
      </tags>
  </entry>
  <entry>
    <title>《Understanding over-squashing and bottlenecks on graphs via curvature》论文浅析</title>
    <url>/2024/08/18/over-squashing%20and%20bottlenecks%20via%20curvature/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://openreview.net/pdf?id=7UmjRGzp-A">click here</a></p>
<h3 id="论文简述"><a href="#论文简述" class="headerlink" title="论文简述"></a>论文简述</h3><p>本文是ICLR 2022中的一篇高分工作（openreview：10&#x2F;8&#x2F;8&#x2F;8）。</p>
<p>本文从理论上提出了一种Ricci曲率计算方法，并根据对其的分析指出重要结论：<strong>负曲率是导致瓶颈的原因</strong>。而后将其与Cheeger constant联系，说明了他们一定程度上是比较相似的，后期也使用Cheeger constant来说明随机游走重建方法的劣势。<span id="more"></span></p>
<p>根据Ricci曲率的计算方法与得到的结论，文章提出了一种<strong>仅仅基于图结构</strong>的图重建方法。此外，文章对当前基于随机游走的方法进行了分析，说明其并不能消除瓶颈效应。</p>
<p>最后通过实验证明了方法的有效性。</p>
<p><strong>与我之前介绍的ICML2024论文不同，那一篇只基于feature而不用structure，本篇只基于原始structure而不基于feature。</strong></p>
<p>本文内容实在是太丰富且深入了。因此这里仅对文章的核心内容简单聊个大概。</p>
<hr>
<h3 id="Balanced-Forman-curvature"><a href="#Balanced-Forman-curvature" class="headerlink" title="Balanced Forman curvature"></a>Balanced Forman curvature</h3><p>这个定义是比较复杂的，我也不好简单对其进行描述，因此将原文的内容在这里展示。其中每一条每一句对理解都很重要。特别要搞清楚里面每个变量是怎么算出来的。</p>
<p><img src="/../pic/image-20240818150323312.png"></p>
<p>曲率反映了空间的性质，曲率大于0那么平行线会相交，等于0则距离不变，小于零会发散。分别对应着球形空间、平面和双曲空间：</p>
<p><img src="/../pic/image-20240818150859196.png"></p>
<hr>
<h3 id="曲率与瓶颈"><a href="#曲率与瓶颈" class="headerlink" title="曲率与瓶颈"></a>曲率与瓶颈</h3><p>常见的信息传递范式如下：<br>$$<br>h_i^{(\ell+1)}&#x3D;\phi_\ell\left(h_i^{(\ell)},\sum_{j&#x3D;1}^n\hat A_{ij}\psi_\ell(h_i^{(\ell)},h_j^{(\ell)})\right)<br>$$<br>存在点 $i$ 二阶邻居的一个子集满足如下条件：</p>
<p><img src="/../pic/image-20240818151111460.png"></p>
<p>当 $\delta$ 越小，则导数绝对值越小，即点 $i$ 对 $k$ 的影响越小——信息瓶颈。又因为Ricci曲率本身有性质 $Ric(i,j)&gt;-2$，因此根据 $(ii)$ 可知 $\delta$ 越小也就代表着<strong>更大的负曲率</strong>。从而得到文章中可能是最重要的一个结论：</p>
<p><img src="/../pic/image-20240818151409865.png"></p>
<hr>
<h3 id="Cheeger-constant"><a href="#Cheeger-constant" class="headerlink" title="Cheeger constant"></a>Cheeger constant</h3><p>图的spectral gap可以解释为<strong>图被划分为两个社区的拓扑障碍</strong>，这个量与图瓶颈有关。因此其应该可以由曲率控制。</p>
<p>从一个直观的解释开始：假设我们得到一个图 $G$，其中两个社区由少数边分隔。在这种情况下，我们看到图可以很容易地断开连接——这就是一个瓶颈。</p>
<p>具体度量方法为：</p>
<p><img src="/../pic/image-20240818151857289.png"></p>
<p>更进一步的，作者通过一些定理与推导，得到：<strong>曲率的正下界</strong>为我们<strong>提供了对 $h_G$ 的控制</strong>，即对图的spectral gap的控制。</p>
<p><img src="/../pic/image-20240818152203528.png"></p>
<hr>
<h3 id="根据Ricci曲率的图结构改造方法"><a href="#根据Ricci曲率的图结构改造方法" class="headerlink" title="根据Ricci曲率的图结构改造方法"></a>根据Ricci曲率的图结构改造方法</h3><p>直观来看，本方法就是干了如下的事：</p>
<p><img src="/../pic/image-20240818155015913.png"></p>
<p>伪代码为：</p>
<p><img src="/../pic/image-20240818152537354.png"></p>
<p>简单来说，主要做了两件事：</p>
<ul>
<li>以添加边后Ricci增益为度量，进行一定概率的加边。大的Ricci曲率增益有更高可能性被添加新边，反之更小概率。</li>
<li>减少曲率过大的边缘。</li>
</ul>
<p>其中 $B_1(i)$ 代表的是到 $i$ 距离小于等于1的点的集合，其实就是<strong>一阶邻居加自己</strong>，核心其实是添加三元环或四元环，这些变量在Ricci曲率计算中起着重要的作用。</p>
<p>经过这样操作后，大大减少了负曲率的数量，同时减少过大正曲率，让整体曲率分布较为集中。</p>
<p>从<strong>图结构保存</strong>的角度来讲，主要实现了两点（原文）：</p>
<ul>
<li>Theorem 4 tells us how to do the rewiring under such constraints in order to best address the over-squashing: the topological modifications <strong>need to be localized around the most negatively-curved edges</strong>.</li>
<li>Secondly, we also point out that $Ric(i, j) &lt; −2 + \delta$ implies that $\min\{di, dj\} &gt; 2&#x2F;\delta$. Therefore, if we mostly modify the edge set at those nodes $i, j$ joined by an edge with large negative curvature, then we are perturbing nodes with <strong>high degree where such a change is relatively insignificant</strong>, and thus <strong>overall statistical properties</strong> of the rewired graph such as degree distribution <strong>are likely to be better preserved</strong>.</li>
</ul>
<p>从结果上来看，本方法得到的度分布与原图是很像的，并不像其他方法一般大大改变了度的分布。因此这也反映出本方法能够较好的保留原图的信息。</p>
<p><img src="/../pic/image-20240818154910051.png"></p>
<hr>
<h3 id="为什么随机游走方法无法解决瓶颈问题"><a href="#为什么随机游走方法无法解决瓶颈问题" class="headerlink" title="为什么随机游走方法无法解决瓶颈问题"></a>为什么随机游走方法无法解决瓶颈问题</h3><p>随机游走模型为：<br>$$<br>R_{\alpha}:&#x3D;\sum_{k&#x3D;0}^{\infty}\theta_k^{PPR}(D^{-1}A)^k&#x3D;\alpha\sum_{k&#x3D;0}^{\infty}\left((1-\alpha)(D^{-1}A)\right)^k<br>$$<br>其中 $\alpha$ 是停机概率，即当前状态有 $\alpha$ 的可能不继续游走，$1-\alpha$ 的概率继续游走。</p>
<p>作者此时就用到了之前提到的Cheeger constant。给出游走后的一个上界。</p>
<p><img src="/../pic/image-20240818154416713.png"></p>
<p>文章指出这种方法优先在community内部进行加边操作而非community间，这也就代表它不会处理掉瓶颈问题。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>Over-Squashing</tag>
      </tags>
  </entry>
  <entry>
    <title>《Residual Entropy-based Graph Generative Algorithms》论文解读</title>
    <url>/2024/08/18/Residual%20Entropy/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://dl.acm.org/doi/10.5555/3535850.3535942">click here</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本文是AAMAS 2022中的一篇工作。</p>
<p>本篇文章的核心工作为：<strong>设计了一种通过原图构造防御图的算法（非神经网络）</strong>。其意义在于通过对原始graph进行加边处理使得其结构信息更加显著，从而帮助模型更好的学习到structure信息。</p>
<p>文章通过1-dimensional structure entropy和2-dimensional structure entropy定义出残差熵（Residual Entropy），这个熵反映了图结构所携带的信息——本文希望最大化这个量。</p>
<p>文章通过残差熵的定义推导出使得残差熵增大的条件，进而根据这个条件对图进行加边处理，旨在提高图的残差熵，从而得到<strong>防御图</strong>。<span id="more"></span></p>
<p>我之前看的论文大多是基于1-dimensional structure entropy，在架构上进行大大小小的改动。而这边文章从底层使用了一种不同的度量方法，因此我还是简单总结一下这篇文章的主要内容。</p>
<p>这篇文章中从定义推导方法的过程值得借鉴，尽管我感觉有些不够严谨，但这个思路是能够将一个工作顺下来的。</p>
<p>补：后来发现残差熵这个概念在<a href="https://proceedings.neurips.cc/paper/2019/file/328347805873e9a9c700591812fb0ec2-Paper.pdf">REM: From Structural Entropy To Community Structure Deception</a>中提出，且部分结论在这里面也有。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><p><img src="/../pic/image-20240818115633508.png"></p>
<h4 id="残差熵"><a href="#残差熵" class="headerlink" title="残差熵"></a>残差熵</h4><p>先介绍本文提出残差熵用到的两个熵计算方法：</p>
<ul>
<li><p>1-dimensional structure entropy: 1-dimensional structure entropy is defined by the average codeword length of <strong>all interactions</strong> from nodes in $V$。<br>$$<br>\mathcal H(G)&#x3D;-\sum_{v_i\in V}\frac{d_i}{2|E|}\log_2\frac{d_i}{2|E|}<br>$$<br>其中 $d_i$ 是节点 $v_i$ 的度，$E$ 是总边数。这个度量方式<strong>没有假设任何社区结构</strong>。</p>
</li>
<li><p>2-dimensional structure entropy: 2-dimensional structure entropy is defined by the average encode length of all calls with community partition $P$。<br>$$<br>\mathcal H_P(G)&#x3D;\sum_{j&#x3D;1}^L\left(-\frac{\nu_j}{2|E|}\mathcal H(G|X_j)-\frac{g_j}{2|E|}\log_2\frac{\nu_j}{2|E|}\right)<br>$$<br>$P&#x3D;\{X_1,\dots,X_L\}$ 是对节点的一个分割。 $\mathcal H(G|X_j) &#x3D; -\sum_{v_i\in X_j} \frac{d_i}{v_j}\log_2\frac{d_i}{v_j}$，$v_i$ 代表第 $i$ 个分割团 $X_i$ 的度之和；$g_i$ 代表只有一个端点在 $X_i$ 内的边数（其实就是连向外面的边数）。这个结构熵反映了一直社区机构后的信息熵。</p>
</li>
</ul>
<p>接下来便可以引出残差熵（已normalized）了：<br>$$<br>\rho p:&#x3D;R_{P}&#x2F;\mathcal H(G), \quad R_P&#x3D;\mathcal H(G)-\mathcal H_P(G)&#x3D;\frac{v_j-g_j}{2|E|}\log_2\frac{v_j}{2|E|}<br>$$<br>残差熵<strong>表示有关图社区结构的信息量</strong>。一个相对高的残差熵表示分区 $P$ 包含更多的信息。</p>
<h4 id="如何提高残差熵"><a href="#如何提高残差熵" class="headerlink" title="如何提高残差熵"></a>如何提高残差熵</h4><p>提高残差熵无非就两个思路：分子越大越好，分母越小越好。文章给出了几个引理和推论，简单来说如下：</p>
<ul>
<li>对分割 $X_i$ 内部加边后 $R_P$ 会增加更多。</li>
<li>待加边两个端点的度之和越大，则加边后 $H$ 越小。</li>
<li>若度之和相等，则待加边两个端点的度之差越小，加边后 $H$ 越小。</li>
</ul>
<p>根据以上三种规则，我们就可以实现加边算法了。</p>
<h4 id="防御图构建算法"><a href="#防御图构建算法" class="headerlink" title="防御图构建算法"></a>防御图构建算法</h4><p>文中提到了两种攻击方法：无目标攻击（对全图进行攻击），有目标共计（对某一partial进行攻击）。</p>
<p><img src="/../pic/image-20240818140718481.png"></p>
<p>两个算法比较相似，只不过是作用域不同。核心思想与之前介绍的方法是一致的：目标加边集合的选取方法为：</p>
<p><img src="/../pic/image-20240818140835357.png"></p>
<p>具体就不过多介绍了，伪代码比较清晰。</p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><p>文章使用了两种大类评估方法：</p>
<ul>
<li>不需要feature：Louvain、DeepWalk、SCD</li>
<li>需要feature：GCN、GAT、SSP、GCN-LPA</li>
</ul>
<p>节点分类的评估指标采取标准化的互信息（Normalized Mutual Information，NMI）。</p>
<h4 id="有目的加边-or-随机加边"><a href="#有目的加边-or-随机加边" class="headerlink" title="有目的加边 or 随机加边"></a>有目的加边 or 随机加边</h4><p>作者用随机加边作为对比，证明了加边的有效性（有目的当然会比随机加边好）。</p>
<p><img src="/../pic/image-20240818141800928.png"></p>
<h4 id="对无目标攻击的抵御"><a href="#对无目标攻击的抵御" class="headerlink" title="对无目标攻击的抵御"></a>对无目标攻击的抵御</h4><p>攻击方法为REM和DICE。流程为先攻击后训练（即对不完全正确的图结构进行学习）。怎么有的攻击完了反而更好，还好了不少。</p>
<p><img src="/../pic/image-20240818142125546.png"></p>
<h4 id="对有目标攻击的抵御"><a href="#对有目标攻击的抵御" class="headerlink" title="对有目标攻击的抵御"></a>对有目标攻击的抵御</h4><p>攻击方法为FDA和RND，流程与上面一样。</p>
<p><img src="/../pic/image-20240818142353895.png"></p>
<hr>
<h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>本方法感觉还是有一些局限，比如只考虑了加边。或许这样方法的表现上线就已经被原图结构进行限制了。</p>
<p>另外一个重要的点是添加的边数是超参数 $K$ 控制的（或者是是实验中 $K&#x3D;p|E|$ 的 $p$），所以其效果一定程度上还是依赖于人的参数设计的。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>一亩三分地——宿舍桌面v2.0版</title>
    <url>/2024/08/16/desktop/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>hi，陆陆续续，从上次装修宿舍以来也已经过了一年了吧。</p>
<p>这期间又经历了很多事，大学从 50% 到 75%，有多少难熬的夜晚，有多少内心的悸动，但都经历过了。岁月留痕，一件物品，一段故事。<span id="more"></span></p>
<p><img src="/../pic/image-20240816232619968.png" alt="我的桌面"></p>
<ul>
<li>这一年，我重拾了魔方，从 sub 28s 练习到 sub 18s。于是我的桌面上多了两个魔方：rs3m2020（自己做了磁力加强）以及奇艺智能魔方竞速版。</li>
<li>花的摆件是我迟来的生日礼物，来自她。这是一个木质拼插积木，却又看起来并不呆板，很好看。</li>
<li>高达旁边的摆件是来自Eason Nuo的维也纳礼物，至于维也纳，2024ICML会议在此召开。</li>
<li>尤克里里是装饰，能弹出声音但并不准，毕竟也只是个摆件价格。上面是空白的，留下了无限可能，或许在未来的某日，我会克服懒惰萌生想法，去装饰它。</li>
<li>尤克里里下面的琴架是我用纸板自己做的，并不难，诚然并不好看，但毕竟也不太能看到……</li>
<li>台灯上的“照片”是我很久以前的QQ头像，一个背着吉他的男孩。这是我很久以前的生日礼物——来自17岁那一年，四年前。</li>
<li>电脑壁纸也是我珍藏很久的一张，抱着吉他，在夜晚吹风。这并不孤独。</li>
<li>高达下面的小相机虽说是个摆件，却真有着拍照和录像功能，在2024年有着2004年的画质，挺好玩的，不过现在仅仅是个摆件罢了。</li>
<li>其他的似乎与之前没什么不同：装饰用的黑胶，Tommy、披头士的海报，假期绘制的数字油画，来自她的奶龙和头戴耳机……</li>
</ul>
<p>我在这个位置还能够待一年的时间，也应该是仅有的一年时间了。时间过后，一切痕迹都会被收拾——露出并不洁白的墙壁，以及部分粗糙的水泥。</p>
<p>但我会将他们布置在新的地方，应该会的。</p>
<p>愿大四精彩。</p>
]]></content>
      <categories>
        <category>杂</category>
        <category>生活分享</category>
      </categories>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
  <entry>
    <title>《Edge Entropy as an Indicator of the Effectiveness of GNNs over CNNs for Node Classification》论文解读</title>
    <url>/2024/08/11/Edge%20Entropy/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://ieeexplore.ieee.org/document/9443451">click here</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>这是CMU在2021 Asilomar Conference上的一篇工作。</p>
<p>GNN与CNN的区别在于，GNN引入了图的结构信息。从实验结果来看，有效的图结构训练结果要远好于简单的单位阵或随机矩阵当做图结构的结果：<span id="more"></span></p>
<p><img src="/../pic/image-20240811140440410.png"></p>
<p>那么结构信息对GNN有了什么样的帮助呢，这篇文章基于此提出两个问题：</p>
<ul>
<li>如何评估图结构对GNN的有效性？</li>
<li>如何评估图结构的有效性？</li>
</ul>
<p>本文以<strong>边缘熵</strong>的思想来对如上问题进行解答。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><h4 id="直观而言"><a href="#直观而言" class="headerlink" title="直观而言"></a>直观而言</h4><p><img src="/../pic/image-20240811140646283.png"></p>
<ul>
<li>(a) 每一个团都只有一类，那么知道其邻居的颜色自身颜色就知道了。但是 (b) 不行</li>
<li>intra-class ration能够代表一定信息，如 (c) 邻居与本身类别一致比例是0，能够提供信息</li>
<li>clustering coefficient能够作为一个指标，比如 (d) 完全图的聚类系数为1，基本不提供信息</li>
</ul>
<p>如何找到一个通用的评判方法？——Edge Entropy。</p>
<h4 id="Edge-Entropy"><a href="#Edge-Entropy" class="headerlink" title="Edge Entropy"></a>Edge Entropy</h4><p>设图 $G$ 有 $M$ 类别，对于任意类别 $l$ 当前类别的熵为：</p>
<p>计算方式如下：<br>$$<br>H(l):&#x3D;-\sum_{m\in\{1,\dots,M\}}p_{lm}(n)\log_M(p_{lm}(n))<br>$$<br>其中：<br>$$<br>p_{lm}:&#x3D;\frac{|{\text{edge }w:\text{start}(w)\in\mathcal V_l\wedge\text{end}(w)\in\mathcal V_m}|}{|{\text{edge }w:\text{start}(w)\in\mathcal V_l}|}<br>$$<br>最终整个图的Edge Entropy就可以计算为：<br>$$<br>\hat H&#x3D;-\sum_{m\in\{1,\dots,M\}} H(m)w_m<br>$$<br>$w_m$ 就是第 $m$ 类节点个数的占比。</p>
<p>接下来就是实验部分——这个特征如何刻画efficiency。</p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><h4 id="在自建图上的实验"><a href="#在自建图上的实验" class="headerlink" title="在自建图上的实验"></a>在自建图上的实验</h4><p>文章生成具有<strong>特定边缘熵</strong>的合成数据集。$r_i$ 代表第 $i$ 类节点数量，同时有 $\sum r_i&#x3D;N$。</p>
<p>为了具有特定的边缘熵，生成的连通图必须在每个类的节点之间<strong>有一定数量的边</strong>。通过创建一个具有所需边缘熵的 $M \times M$ 矩阵 $T$，其中 $T_{i,j}$ 是将类 $i$ 节点连接到类 $j$ 节点的边数。我们对 $T$ 的每一行进行归一化以产生概率矩阵 $P$ （实际上每一元素就是 $p_{l,m}$）。同时设置了一个变量 $\rho$。</p>
<p><strong>具体图构建方法为</strong>：从 $N$ 个孤立节点开始。每个节点都有一个自循环和随机特征。根据类 $r_i$ 的节点分布，为每个节点分配一个标签。然后我们考虑每对节点 $v_i, v_j$ ，对于每对节点，我们以 $\rho P_{l,m}$ 的概率从 $v_i$ 到 $v_j$ 创建一个有向边，其中 $l$ 是 $v_i$ 的类，$m$ 是 $v_j$ 的类。</p>
<p>设置参数 $N&#x3D;3000,M&#x3D;300,r_1&#x3D;r_2&#x3D;r_3&#x3D;1&#x2F;3,\rho_1&#x3D;0.1,\rho_2&#x3D;0.5$，同时设置低熵 $\hat H_{low} \approx 0.52$ 和高熵 $\hat H_{low} \approx 0.97$ 对应的概率矩阵：<br>$$<br>P_{\text{low}}&#x3D;\begin{bmatrix}0.8&amp;0.05&amp;0.15\\0.05&amp;0.9&amp;0.05\\0.27&amp;0.03&amp;0.7\end{bmatrix}, P_{\text{high}}&#x3D;\begin{bmatrix}0.4&amp;0.26&amp;0.34\\0.2&amp;0.5&amp;0.3\\0.33&amp;0.31&amp;0.37\end{bmatrix}<br>$$<br>简单来说：$\rho$ 代表在相对比率不变的情况下控制边生成的比例，$P$ 控制边的相对生成比例。</p>
<p>根据如上参数构建四个数据集：</p>
<ul>
<li>dense_low：$\rho_2,P_{low}$</li>
<li>sparse_low：$\rho_1,P_{low}$</li>
<li>dense_high：$\rho_2,P_{high}$</li>
<li>sparse_high：$\rho_1,P_{high}$</li>
</ul>
<p>实验结果为：</p>
<p><img src="/../pic/image-20240811144320893.png"></p>
<p>即<strong>低熵更好</strong>。（为什么不对dense和sparse再进行一下对比）</p>
<p>此外坐着还用了一些真实的数据集来证明这个结论，这里不做展示。</p>
<p>核心就是，Edge Entropy能够代表图结构的作用，并且结论是低熵better。</p>
<hr>
<h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>从<strong>边缘上进行熵</strong>的计算是一种不错的思路。与经典的图熵不同，边缘能够考虑相邻两个节点的关系以及本身的结构关系，是一种更加合理的结构原子（一个点的度终究核心还是一个节点，结构信息可能不够全面）。</p>
<p>整篇论文读下来感觉很有道理，但仔细想想似乎也没有什么意料之外的内容，毕竟我们很容易有意识到边的链接以及图的复杂性会影响GNN表现能力。</p>
<p>但是能够借鉴的，或许可以通过label计算出当前边缘的分布概率，换句话来说可以从<strong>大的结构上来计算某一区域structure的分布，计算熵</strong>（这才是我觉得合理的结构熵，而非还是着眼于小的点）。</p>
<p>此外根据label计算structure能够有效的将feature与structure进行结合，更加对图结构的信息进行统一刻画。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>《Delaunay Graph：Addressing Over-Squashing and Over-Smoothing Using Delaunay Triangulation》论文解读</title>
    <url>/2024/08/09/Delaunay%20Graph/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://openreview.net/pdf?id=uyhjKoaIQa">click here</a></p>
<p>code：<a href="https://github.com/Hugo-Attali/Delaunay-Rewiring/blob/main">Delaunay Graph(github)</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本文是来自2024ICML的论文。</p>
<p>图神经网络在计算节点的特征时采用了聚合的思路，但随着gnn层数的增长，会面对如下两个问题：</p>
<ul>
<li><p><strong>Over-smoothing</strong>：如果GNN层很深的话，随着聚合节点的不断扩散，任意两个节点所共享的邻居就会非常多（感受野重叠），导致这两个节点的嵌入非常相似。<span id="more"></span></p>
<p><img src="/../pic/869d48783ef46b9e15b4924b497da972.png"></p>
</li>
<li><p><strong>Over-Squashing</strong>：随着层数的增加，一个结点的k-hop邻居的数量将会呈指数的形式增长，但是与前几层gnn相比，更多的信息被压缩到了一个定长的向量中，这就是 over squashing。</p>
<p><img src="/../pic/8969f6d4a50ada9a8a471cf99feb7023.png"></p>
</li>
</ul>
<p>本文就针对这两个现象，通过改变图结构来得到更好的gnn效果。</p>
<p>与前人的工作不同，此工作<strong>不需要原始的图结构信息</strong>，即仅根据feature即可对图结构进行重构。</p>
<p>本工作从曲率的角度出发，通过引入Delaunay rewiring方法来使得最大化曲率。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><p><img src="/../pic/image-20240809165221218.png"></p>
<h4 id="曲率计算方式"><a href="#曲率计算方式" class="headerlink" title="曲率计算方式"></a>曲率计算方式</h4><p><strong>Augmented Forman Curvature</strong>：此种曲率度量建议考虑图中的三角形来扩展 Forman 的曲率，以使其更具表现力。对于无向图，边 $e_{ij}$ 的曲率 $c_{ij}$ 计算如下:<br>$$<br>c_{ij}&#x3D;4-d_i-d_j+3m<br>$$<br>其中 $m$ 是包含 $e_{ij}$ 的三角形数。</p>
<p><strong>Balanced Forman Curvature</strong>：考虑了四元环：<br>$$<br>c_{ij}&#x3D;\frac2{d_i}+\frac2{d_i}-2\frac m{\max(d_i,d_j)}+\frac m{\min(d_i,d_j)} + \frac {(\Gamma_{max})^{-1}}{\max(d_i,d_j)}(\gamma_i+\gamma_j)<br>$$</p>
<ul>
<li>$\Gamma_{max}(i,j)$ 代表以 $e_{ij}$ 为边且过相同其它节点的四元环数目的最大值</li>
<li>$\gamma_i$ 代表以 $e_{ij}$ 为边，参与到形成<strong>无对角线</strong>的四元环中 $i$ 的邻居的数目</li>
</ul>
<p><a href="https://openreview.net/pdf?id=7UmjRGzp-A">这篇论文</a>有详细的介绍。</p>
<h4 id="Delaunay三角剖分"><a href="#Delaunay三角剖分" class="headerlink" title="Delaunay三角剖分"></a>Delaunay三角剖分</h4><p>对于 $d$ 维欧几里得空间中的一组点集合 $P$，Delaunay 三角剖分表示为 $DT (P )$，是一个三角剖分，其中 $P$ 中没有点位于 $DT (P)$ 中任何 d-单纯形的环绕超球面内。</p>
<p><a href="https://blog.csdn.net/qq_39784672/article/details/131067426">网上资料</a>有如下描述：</p>
<p><img src="/../pic/image-20240809165814229.png"></p>
<p>这种剖分方法有两点好处：</p>
<ul>
<li>最大化由一组点形成的三角形的角度，努力创建尽可能接近等边三角形。（最大化三角形中最小角度的读书）</li>
<li>它确保每个三角形的外接圆不包含集合中的其他点</li>
</ul>
<p>而这导致：<strong>两个节点越像，则越可能在一个三角形内</strong>。</p>
<p>为了缓解Over-Squashing的问题，我们希望<strong>减少负弯曲边的数量</strong>。根据曲率的许多定义，入射在边缘上的三角形数量 $m$ 在增加边缘曲率方面起着重要作用。应用三角剖分可以最大化上述两个曲率的值，同时确保最大团大小为 3。</p>
<h4 id="实验流程"><a href="#实验流程" class="headerlink" title="实验流程"></a>实验流程</h4><p><img src="/../pic/image-20240809163735329.png"></p>
<p><strong>整体流程</strong>：首先对feature进行GNN编码，对得到的编码使用UMAP方法进行降为，对降维后的数据进行Delaunay三角剖分，最终在新的图结构上进行GNN的编码与预测。</p>
<p><strong>为什么不直接对feature进行降维？</strong>因为作者发现这样的效果不好：</p>
<p><img src="/../pic/image-20240809172549426.png"></p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><h4 id="初步检验图结构的有效性"><a href="#初步检验图结构的有效性" class="headerlink" title="初步检验图结构的有效性"></a>初步检验图结构的有效性</h4><p><strong>Homophily</strong>：图的<strong>同质性</strong>在确定节点分类任务体系结构的效率方面起着至关重要的作用。且有方法可以度量。对新得到的图结构计算其同质性，能够发现有极大的改善——一定程度上证明了方法的有效性。此外<strong>边的数量也大大减少</strong>。</p>
<p><img src="/../pic/image-20240809172716523.png"></p>
<p><strong>Ollivier curvature</strong>：使用Olliver的曲率(Ollivier, 2007)来统计图的曲率分布，因为它是有界的，更容易解释。在三角剖分之后构建的图，<strong>删除了自然高度负弯曲的边缘</strong>，这些边缘负责瓶颈（Ttopping 等人，2022），减轻Over-Squashing；得到的新图<strong>不具有强正弯曲的边缘</strong>，减轻Over-Smoothing。</p>
<p><img src="/../pic/image-20240809173236484.png"></p>
<p>其中 $D_i$ 代表第 $i$ 个十分位数。</p>
<h4 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h4><h5 id="图结构已知"><a href="#图结构已知" class="headerlink" title="图结构已知"></a>图结构已知</h5><p>使用不同的图结构重构方法，对构造得到的新图进行分类任务。结果表明DR方法得到了最好的效果。</p>
<p><img src="/../pic/image-20240809163501234.png"></p>
<h5 id="图结构未知"><a href="#图结构未知" class="headerlink" title="图结构未知"></a>图结构未知</h5><p>在图结构未知的情况下，与基本的 $k$-NN 方法进行比对，依旧DR效果整体更优：</p>
<p><img src="/../pic/image-20240809163648408.png"></p>
<hr>
<h3 id="一些想法"><a href="#一些想法" class="headerlink" title="一些想法"></a>一些想法</h3><p>这篇论文是我目前看到的思路很简单代码也很少的例子之一，清晰地提出了一个思路，有着很简单的实施过程，但是有着很好地实验效果——四两拨千斤的感觉。</p>
<p>感觉很有意思。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>图神经网络</tag>
        <tag>Over-Squashing</tag>
        <tag>Over-Smoothing</tag>
      </tags>
  </entry>
  <entry>
    <title>《Rethinking Independent Cross-Entropy Loss For Graph-Structured Data》论文解读</title>
    <url>/2024/08/02/rethinking%20CEL/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://proceedings.mlr.press/v235/zhang24bt.html">click here</a></p>
<p>code：<a href="https://github.com/MR9812/Joint-Cluster-Supervised-Learning">Joint-Cluster(github)</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本文是来自2024ICML的论文。</p>
<p> 对于节点的表示与预测，会存在如下问题：</p>
<ul>
<li>由独立条件分布 $P(y_i|z_i)$ 和 $CE(y_i, P(y_i|z_i))$ 所导致的：<ul>
<li>过拟合</li>
<li>容易受到adversarial attacks的影响 <span id="more"></span></li>
</ul>
</li>
<li>基于独立同分布的假设：$P(y_1,\cdots,y_n|z_1,\cdots,z_n)&#x3D;\prod P(y_i|z_i)$<ul>
<li>这种通过独立同分布的假设从而直接分解 $P$，导致未能全面解释固有的节点相关性。</li>
</ul>
</li>
</ul>
<p>本文的解决方式就是将图分成不同的集团，根据<strong>自身emb</strong>和聚类后某一<strong>集团整体的emb</strong>来进行联合概率密度的计算。最终的模型有显著<strong>泛化</strong>能力的提升，为被攻击节点生成更<strong>稳健的分类</strong>，正确率更高。</p>
<p><strong>可以理解为本文提出的是一种损失函数形势，或者说计算方法。</strong></p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><p><img src="/../pic/image-20240803140117367.png"></p>
<h4 id="联合分布的建模与优化函数"><a href="#联合分布的建模与优化函数" class="headerlink" title="联合分布的建模与优化函数"></a>联合分布的建模与优化函数</h4><p>想要计算完全的联合分布的话，我们的目标其实就是求解 $p(y_1,\ldots,y_L\mid z_1,\ldots,z_L;\tilde{\theta})$，维度为 $\mathbb R^{c^L}$，这显然是难以计算的，所以我们将其向下转变为：图由若干独立集组成，即 $\{\mathcal C_1, \dots,\mathcal C_M\}$，，那么我们的联合分布便可以由若干独立集的分布相乘得到：<br>$$<br>p\left(y_1,\ldots,y_L:\mid z_1,\ldots,z_L;\theta\right)&#x3D;\prod_{m&#x3D;1}^Mp\left(\{y_i\mid v_i\in\mathcal C_m\}\mid\{z_i\mid v_i\in\mathcal C_m\} ;\theta\right)<br>$$<br>这种集群上的 i.i.d 假设在一定程度上降低了计算复杂度，但节点子集的<strong>联合建模仍然不切实际</strong>，并且<strong>不适合用于推断测试节点的类</strong>。</p>
<p>针对这个问题，采用每一集团的特征 $\bar y_m, \bar z_m$ 来代替集团信息，联合分布也就变换为：<br>$$<br>p (y_i,\bar y_m\mid z_i,\bar z_m,;\theta),<br>$$<br>所以我们优化的实际内容是这样的：</p>
<p><img src="/../pic/image-20240803142847475.png"></p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>关于cluster的分割，这里采用的是 <strong>METIS 图聚类</strong>算法。</p>
<p>子团的信息：采用平均池化 $\bar z_m &#x3D; 1&#x2F;L_m\sum_{i&#x3D;1}^{L_m}z_i, \ \bar y_m &#x3D; 1&#x2F;L_m\sum_{i&#x3D;1}^{L_m}y_i$，因此“真实的”联合分布概率定义为 $y_i\bar y_m$，而模型训练是通过将当<strong>前节点的emb与cluster的emb拼接</strong>后经过<strong>图分类器</strong>得到的。<br>$$<br>\mathcal L_{JC}&#x3D;-\sum_{i&#x3D;1}^L{(y_i\bar y_m^{\top})\cdot\log g_{\phi}\left(\text{con}\left(z_i,\bar z_m\right)\right)+(\bar y_my_i^{\top})\cdot\log g_{\phi}\left(\text{con}\left(\bar z_m,z_i\right)\right)}<br>$$<br>为了<strong>对称</strong>联合分布建模，在上述方程的第二项，将节点和集群嵌入的位置进行交换。</p>
<h4 id="从联合分布到边缘分布"><a href="#从联合分布到边缘分布" class="headerlink" title="从联合分布到边缘分布"></a>从联合分布到边缘分布</h4><p>$$<br>\begin{aligned}<br>p(y_i |z_i;\theta)&amp;&#x3D;\int_{\mathbb R^d}\sum_{k&#x3D;1}^c p(y_i,\bar y_m&#x3D;k\mid z_i,\bar z,;\theta)q(\bar z)d \bar z \\<br>&amp;&#x3D;\sum_{k&#x3D;1}^c p(y_i,\bar y_m&#x3D;k\mid z_i,\bar z_m,;\theta)<br>\end{aligned}<br>$$</p>
<p>等号能过去的原因是子团之间是独立的。</p>
<p>也就是说给定了联合分布 $ p(y_i,\bar y_m\mid z_i,\bar z_m,;\theta) \leftrightarrow y_i\bar y_m^\top$，对其进行逐行求和便是 $y_i$ 类别的边缘分布。</p>
<p>值得注意的是，<strong>在模型的推断过程中，训练中cluster的emb的被利用的</strong>。这个操作和batch norm中的run_mean、run_var是一致的。</p>
<h4 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h4><p><img src="/../pic/image-20240803140511284.png"></p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><p>除去正文中展示的实验，其在附录中还存在实验结果。此处只展示部分正文中的实验。</p>
<h4 id="小规模图数据集"><a href="#小规模图数据集" class="headerlink" title="小规模图数据集"></a>小规模图数据集</h4><p>类别均衡：</p>
<p><img src="/../pic/image-20240803152609166.png"></p>
<p>类别不均衡：</p>
<p><img src="/../pic/image-20240803152643124.png"></p>
<p>异质图：</p>
<p><img src="/../pic/image-20240803152715825.png"></p>
<h4 id="大规模图数据"><a href="#大规模图数据" class="headerlink" title="大规模图数据"></a>大规模图数据</h4><p><img src="/../pic/image-20240803152740238.png"></p>
<h4 id="对抗攻击"><a href="#对抗攻击" class="headerlink" title="对抗攻击"></a>对抗攻击</h4><p><img src="/../pic/image-20240803152913681.png"></p>
<h4 id="泛化性更好"><a href="#泛化性更好" class="headerlink" title="泛化性更好"></a>泛化性更好</h4><p><img src="/../pic/image-20240803153455154.png"></p>
<p>他的训练与测试集的误差gap更小。</p>
<hr>
<h3 id="思考与想法"><a href="#思考与想法" class="headerlink" title="思考与想法"></a>思考与想法</h3><ul>
<li><p>本文实际上是吧原本的一维分类交叉熵变为二维的交叉熵。</p>
</li>
<li><p>这里的cluster是训练前直接根据图结构生成的，那么每一个cluster内部label是否一致？或者说这个cluster对节点预测是否有作用（是否是对的）</p>
</li>
<li><p>将图分为若干子团的方法是可以借鉴的</p>
</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>《Learning Graph Representation via Graph Entropy Maximization》论文解读</title>
    <url>/2024/08/01/GeMax/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://proceedings.mlr.press/v235/sun24i.html">click here</a></p>
<p>code：<a href="https://github.com/MathAdventurer/GeMax">GeMax(github)</a></p>
<h3 id="论文任务与个人想法"><a href="#论文任务与个人想法" class="headerlink" title="论文任务与个人想法"></a>论文任务与个人想法</h3><p>本工作来自于2024ICML。</p>
<p>文章的任务是图表示学习，其不仅对每一张图上的<strong>每个节点得到编码</strong>，更在图整体上得到关于<strong>图的编码</strong>。本文提出了一种利<strong>用正交表示进行图熵最大化</strong>的近似方法。</p>
<p>整篇文章读下来，有让我眼前一亮的感觉，是让我觉得蛮有意思的一篇文章。</p>
<p>文章运用了其他文献未运用的，基于<strong>独立集</strong>表示的熵的表示方法。<span id="more"></span>在计算中，用到了“vertex-packing polytope（$VP(G)$）”概念，但是计算复杂，文章论述了为什么<strong>不能</strong>用下界进行训练。为了简化问题，文章取了其子集，并在正交表示的条件下给出了一条定理，从而<strong>转化为一定条件下的优化问题</strong>——规避了复杂的求解独立集的过程。更进一步，将条件转化为优化，使得模型能够学习。</p>
<p>总的来说，我认为论文的亮点如下：</p>
<ul>
<li><p>如何理解文中最大化交叉熵的目的。</p>
</li>
<li><p>找到了正交表示和$VP$之间的一个很妙的关系。</p>
</li>
<li><p>规避了求解独立集的过程，使得计算成为可能。</p>
</li>
<li><p>将有条件的优化问题转化为无条件的优化问题。</p>
</li>
</ul>
<p>光看这一部分大概率是不了解其具体干了什么，那么先往下看，了解完整体内容再回头看，便能够感受到巧妙之处了。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><p><img src="/../pic/image-20240801234721505.png"></p>
<h4 id="图熵，但不能简单优化下界"><a href="#图熵，但不能简单优化下界" class="headerlink" title="图熵，但不能简单优化下界"></a>图熵，但不能简单优化下界</h4><p>这里的图熵是基于独立集定义的，独立集就是集合中任意两个点事没有边相连的。下面这个例子能够较好的展示，其一共有十个独立集：</p>
<p><img src="/../pic/image-20240802000029372.png"></p>
<p>比如 $b_6$ 就代表 $v_1,v_3$ 所组成的独立集（很好理解吧）。</p>
<p>先引入一个概念：<strong>vertex-packing polytope</strong><br>$$<br>\mathrm{VP}(G):&#x3D;\{\boldsymbol a\in\mathbb R^{|V|}:\boldsymbol a&#x3D;\boldsymbol B\boldsymbol{\lambda}, \boldsymbol{\lambda}\geq0, \sum_i\lambda_i&#x3D;1\}<br>$$<br>得到的 $a_i$ 可以理解为其对整个图的独立集所做的贡献。</p>
<p>那么现在就可以引出本文的<strong>图熵</strong>了：<br>$$<br>H_k(G,P):&#x3D;\min_{\boldsymbol a\in\text{VP}(G)}\sum_{i&#x3D;1}^{|G|}-P_i\log(a_i)<br>$$<br>其中 $P_i$ 代表第 $i$ 个节点的额概率密度。$\sum P_i&#x3D;1$，但是<strong>注意</strong> $\sum a_i\neq1$ 。我们希望最大化图熵 $\max\limits_{F\in\mathcal F} \mathbb E_{G\sim\mathcal D}\begin{bmatrix}H_k\left(G,P_{F(G)}\right)\end{bmatrix}$。</p>
<p>设图表示函数为 $F_g$，图节点函数为 $F_z$：<br>$$<br>\mathbf g^\theta&#x3D;F_g(\boldsymbol A,\boldsymbol X;\theta)\quad \boldsymbol Z^\phi&#x3D;F_Z(\boldsymbol A,\boldsymbol X;\phi).<br>$$<br>那么定义Boltzmann distribution:<br>$$<br>P_i(\mathbf g^\theta,\boldsymbol Z^\phi):&#x3D;\frac{\exp(-||\boldsymbol z_i^\phi-\mathbf g^\theta||^2)}{\sum_{l\in V}\exp(-||\boldsymbol z_l^\phi-\mathbf g^\theta||^2)}, \forall i\in V<br>$$<br>从而最终的优化目标为：<br>$$<br>\max_{\theta,\phi} \sum_{j&#x3D;1}^NH_k\left(G_j,P(\boldsymbol A_j,\boldsymbol X_j;\theta,\phi)\right)<br>$$<br>或者可以理解为：<br>$$<br>\max_{\theta,\phi}\sum_{j&#x3D;1}^N\min_{\boldsymbol a\in\mathrm{VP}(G_j)}\sum_{i&#x3D;1}^{n_j}-P_i(\boldsymbol A_j,\boldsymbol X_j;\theta,\phi)\log(a_i)<br>$$<br>这个熵是有<strong>下界</strong>的：<br>$$<br>H(P)-\log\alpha(G)\leq H_k(G,P)<br>$$<br>其中 $H$ 就是independent number，而 $\alpha(G)$ 是<a href="https://mathworld.wolfram.com/IndependenceNumber.html">独立数</a>。</p>
<p>根据这个界去优化的话<strong>不直接捕获图结构的任何拓扑信息</strong>，且效果不好，因此我们需要一种其他方法来对 $H_k$ 进行估计。</p>
<h4 id="pre解决难以优化的问题"><a href="#pre解决难以优化的问题" class="headerlink" title="pre解决难以优化的问题"></a>pre解决难以优化的问题</h4><p>图熵的计算是 <strong>NP-hard</strong> 问题，显然是不可计算的，因此本文提出了一个vertex-packing polytope子集来减少计算量，当然其意义远不止于此，在后续优化中有很大用处。<br>$$<br>\mathrm{VP}_\mathrm{Sub}(G) &#x3D; \{ a\in\mathbb R^{|V|}:\mathbb 1(a)\in \mathrm{VP}(G), 0\leq a_i\leq 1 \}<br>$$<br>接下来求解就在这个子集上进行操作了，减少了求解域的大小。</p>
<p>但这个子集仍然需要计算独立的集合指标矩阵 $B$，这<strong>仍然是 NP-hard</strong>。</p>
<h4 id="正交表示解决求独立集的复杂问题"><a href="#正交表示解决求独立集的复杂问题" class="headerlink" title="正交表示解决求独立集的复杂问题"></a>正交表示解决求独立集的复杂问题</h4><p>首先介绍什么是正交表示，简单来说是模长为1，非相邻节点的编码正交形成的编码集合：<br>$$<br>\mathcal T(G):&#x3D;{Z\in\mathbb R^{n\times d}: |z_i|_2&#x3D;1\  \mathrm{for}\ i&#x3D;1,2,…,n;z_i^{\top}\boldsymbol z_j&#x3D;0, \forall(i,j)\notin E}.<br>$$<br>本文提出Theorem，我认为这是本文<strong>最重要</strong>的点：</p>
<p><img src="/../pic/image-20240802093214151.png"></p>
<p>证明在附录中给出了。</p>
<p>正是因为这个原因，将 $\mathrm{VP}_\mathrm{Sub}(G)$ 条件转化为 $D_a(ZZ^{\top})D_a&#x3D;D_a^2$。从而优化问题转换为：</p>
<p><img src="/../pic/image-20240802093434718.png"></p>
<p>那么 ‘s.t.’ 如何在模型中作出限制呢？</p>
<h4 id="从有限制优化到非限制优化"><a href="#从有限制优化到非限制优化" class="headerlink" title="从有限制优化到非限制优化"></a>从有限制优化到非限制优化</h4><p>对于上面的第一个约束，采用优化如下目标得到：<br>$$<br>\mathcal L_{\mathrm{orth}}(\mathcal G;\phi):&#x3D;\sum_{j&#x3D;1}^N\left|M_j\odot\left(\boldsymbol Z_j^\phi(\boldsymbol Z_j^\phi)^\top-\boldsymbol I_n\right)\right|F^2<br>$$<br>其中 $M_j&#x3D;1_{n_j\times n_j}-A_j$ ，脚标代表第 $j$ 个图。事实上就是一个mask矩阵。</p>
<p>对于上面的第二个约束：<br>$$<br>\mathcal L_{\mathrm{s-vp}}(\mathcal G;\theta,\phi,\mathcal A):&#x3D;\sum_{j&#x3D;1}^N\left|D_{a_j}\left(\boldsymbol Z_j^{\phi}(\boldsymbol Z_j^{\phi})^{\top}\right)\boldsymbol D_{a_j}-\boldsymbol D_{a_j}^2\right|^2<br>$$</p>
<p>$$<br>\mathrm{s.t.} 0\leq a_{ij}\leq1, \forall i\in[n_j], \boldsymbol{a}_j\in\mathcal A<br>$$</p>
<p>这样就大大降低了约束条件。</p>
<p>接下来就是对Loss的优化，因为需要$\max\min$，因此采用交替优化如下两个过程：</p>
<ul>
<li><p>优化图编码器参数：<br>$$<br>\theta^{(t+1)},\phi^{(t+1)}&#x3D;\operatorname*{argmax}_{\theta,\phi}\mathcal J_1(\mathcal G;\theta,\phi,\mathcal A^{(t)})<br>$$</p>
<p>$$<br>\mathcal J_1(\mathcal G;\theta,\phi,\mathcal A):&#x3D;\mathcal L_{H_k}(\mathcal G;\theta,\phi,\mathcal A)-\mu\cdot\mathcal L_{\mathrm{orth}}(\mathcal G;\phi)-\gamma\cdot\mathcal L_{\mathrm{s-vp}}(\mathcal G;\theta,\phi,\mathcal A)<br>$$</p>
</li>
<li><p>优化 $a$：<br>$$<br>\mathcal A^{(t+1)}&#x3D;\underset{\mathcal A\in\mathcal C}{\operatorname*{argmin}}\mathcal J_2(\mathcal G;\theta^{(t+1)},\phi^{(t+1)},\mathcal A )<br>$$</p>
<p>$$<br>\mathcal J_2(\mathcal G;\theta,\phi,\mathcal A):&#x3D;\mathcal L_{H_k}(\mathcal G;\theta,\phi,\mathcal A)+\gamma\cdot\mathcal L_{\mathrm{s-vp}}(\mathcal G;\theta,\phi,\mathcal A)<br>$$</p>
</li>
</ul>
<p>特别的，在 $a$ 更新时，用函数将其限制在 $[0,1]$：<br>$$<br>\operatorname{Proj}_{[0,1]}\left(\bar a\right)&#x3D;\begin{cases}0,&amp;\text{if}\ \bar a\leq0,\\1,&amp;\text{if}\ \bar a\geq1,\\ \bar a,&amp;\text{otherwise}.\end{cases}<br>$$<br>至此，大功告成！</p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><p>本文实验进行了很多，除了下面的还有很多，都在最终的<strong>附录</strong>中。</p>
<h4 id="不同原则之间的比较"><a href="#不同原则之间的比较" class="headerlink" title="不同原则之间的比较"></a>不同原则之间的比较</h4><ul>
<li><p>InfoMax：最大化图级和节点级表示之间的互信息<br>$$<br>\phi^*,\theta^*,\varphi^*&#x3D;\arg\max_{\phi,\theta,\varphi}\sum_{j&#x3D;1}^{|\mathcal G|}\frac1{|V_j|}\sum_{i\in V_j}I_\varphi(\boldsymbol g_j^\theta,\boldsymbol z_{ij}^\phi),<br>$$</p>
</li>
<li><p>Lovasz Principle：其中$\ell_\text{orth}$是正交正则化（orthonormal regularization）<br>$$<br>\phi^*,\theta^*&#x3D;\arg\min_{\phi,\theta}\sum_{j&#x3D;1}^{|\mathcal G|}\max_{i\in V_j}\frac1{\left((z_i^\phi)^\top g_j^\theta\right)^2}+\eta\ell_\text{orth}(\mathcal G;\theta,\phi),<br>$$</p>
</li>
</ul>
<p>具体方法可在<strong>附录</strong>中找到。文章探究了在如上原则与本文提出的最大化图熵的实验效果：</p>
<h5 id="在非监督学习中："><a href="#在非监督学习中：" class="headerlink" title="在非监督学习中："></a>在非监督学习中：</h5><p><img src="/../pic/image-20240801233326255.png"></p>
<p><img src="/../pic/image-20240801233408485.png"></p>
<h5 id="在半监督学习中："><a href="#在半监督学习中：" class="headerlink" title="在半监督学习中："></a>在半监督学习中：</h5><p><img src="/../pic/image-20240801233440667.png"></p>
<p><img src="/../pic/image-20240801233504193.png"></p>
<h4 id="最大化不同熵计算方法之间的比较"><a href="#最大化不同熵计算方法之间的比较" class="headerlink" title="最大化不同熵计算方法之间的比较"></a>最大化不同熵计算方法之间的比较</h4><ul>
<li><p>Shannon entropy：<br>$$<br>J_\mathrm{Sh}(\mathcal G;\theta,\phi)&#x3D;\sum_j^{|\mathcal G|}\sum_{i\in V_j}-P_i(\mathbf g^\theta,\boldsymbol Z^\phi)\log(P_i(\mathbf g^\theta,\boldsymbol Z^\phi))<br>$$</p>
</li>
<li><p>Renyi entropy：<br>$$<br>J_\text{Renyi}(\mathcal G;\theta,\phi)&#x3D;\sum_j^{|\mathcal G|}\frac1{1-\alpha}\log\left(\sum_{i\in V_j}(P_i(\mathbf g^\theta,\boldsymbol Z^\phi))^\alpha\right)<br>$$</p>
</li>
</ul>
<p>当然还包括本文中的结构熵，来进行比较。</p>
<h5 id="在非监督学习中：-1"><a href="#在非监督学习中：-1" class="headerlink" title="在非监督学习中："></a>在非监督学习中：</h5><p><img src="/../pic/image-20240801234032946.png"></p>
<p><img src="/../pic/image-20240801234053411.png"></p>
<h5 id="在半监督学习中：-1"><a href="#在半监督学习中：-1" class="headerlink" title="在半监督学习中："></a>在半监督学习中：</h5><p><img src="/../pic/image-20240801234405457.png"></p>
<p><img src="/../pic/image-20240801234113983.png"></p>
<h4 id="消融实验、灵敏度分析、本文熵在不同模型上的效果"><a href="#消融实验、灵敏度分析、本文熵在不同模型上的效果" class="headerlink" title="消融实验、灵敏度分析、本文熵在不同模型上的效果"></a>消融实验、灵敏度分析、本文熵在不同模型上的效果</h4><p>见附录。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>《Dynamic Graph Information Bottleneck》论文解读</title>
    <url>/2024/07/26/DGIB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://arxiv.org/abs/2402.06716">click here</a></p>
<p>Code：<a href="https://github.com/RingBDStack/DGIB/tree/main">DGIB(github.com)</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本篇论文是2024WWW上的论文。</p>
<p>这篇论文将<strong>信息瓶颈理论</strong>创新性地应用于动态图神经网络中，遇上一篇论文类似，文章核心围绕着信息瓶颈理论的——minimal sufficient 特点展开。但动态图具有时间特征，因此在时间特征上的编码一致性是重要的，针对此问题，本文将minimal - sufficient进行扩展，<strong>得到Minimal-Sufficient-Consensual (MSC)原则</strong>。</p>
<span id="more"></span>

<p>整体论文架构思路与<a href="https://hydrogenhy.github.io/2024/07/24/GIB/">《Graph Information Bottleneck》论文解读</a>有些相似，但应用于不同场景。本文讲重点介绍思想与区别，一些之前提到过得内容会简单略过。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><p><img src="/../pic/image-20240725213950724.png"></p>
<h4 id="DGIB-MS"><a href="#DGIB-MS" class="headerlink" title="$DGIB_{MS}$"></a>$DGIB_{MS}$</h4><p>与GIB类似，仍然有如下假设：当前节点时空特征只与$k$-hop邻居有关，与其它结点相互独立。</p>
<p>针对最小-充足性特征，编码应该满足：<br>$$<br>\mathrm Z^{T+1} &#x3D;\arg\min_{\mathbb P(Z^{T+1}|\mathcal D ,\theta)\in\Omega}\mathrm{DGIB}_{MS}(\mathcal D,\mathrm Y^{I+1};\mathrm Z^{I+1})<br>\triangleq\left[- I(\mathrm Y^{T+1};\mathrm Z^{T+1}) +\beta_1 I(\mathrm D;\mathrm Z^{T+1}) \right].<br>$$<br>这里是与原始数据 $\mathcal D $ 相比，保留了原始BI理念的特点。</p>
<p><strong>变分界：</strong></p>
<p><img src="/../pic/image-20240730004303791.png"></p>
<h4 id="DGIB-C"><a href="#DGIB-C" class="headerlink" title="$DGIB_{C}$"></a>$DGIB_{C}$</h4><p>针对一致性特征，编码应该满足：<br>$$<br>\mathrm Z^{T+1} &#x3D;\arg\min_{\mathbb P(Z^{T+1}|Z^{1:T},C(\theta))\in\Omega}\mathrm{DGIB}_{MS}(Z^{1:T},\mathrm Y^{I+1};\mathrm Z^{I+1})<br>\triangleq\left[- I(\mathrm Y^{T+1};\mathrm Z^{T+1}) +\beta_1 I(Z^{1:T};\mathrm Z^{T+1}) \right].<br>$$<br>这里是与时间尺度上的特征$Z^{1:T}$ 相比，保持了编码空间的一致性。</p>
<p><strong>变分界：</strong></p>
<p><img src="/../pic/image-20240730004334597.png"></p>
<p><img src="/../pic/image-20240730004419028.png"></p>
<h4 id="实际应用"><a href="#实际应用" class="headerlink" title="实际应用"></a>实际应用</h4><p>交叉熵代替互信息：</p>
<p><img src="/../pic/image-20240730004604781.png"></p>
<p>假设 $\mathbb P(\hat{\mathrm A}^t\mid\hat{\mathrm Z}^t,\mathrm Z^{t-1},\mathrm A^t)$服从伯努利or类别分布，进而得到 $A$：</p>
<p><img src="/../pic/image-20240730004918569.png"></p>
<p>假设 $\mathbb P(\mathrm Z^t\mid\hat{\mathrm Z}^t,\mathrm Z^{t-1},\hat{\mathrm A^t})$服从多元正态分布，进而得到 $Z$，其中 $\Phi$是正态分布：</p>
<p><img src="/../pic/image-20240730005208383.png"></p>
<p>对于Eq(14)而言：</p>
<p><img src="/../pic/image-20240730005353997.png"></p>
<h4 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h4><p>优化目标为：<br>$$<br>\mathcal L_{\mathrm{DGIB}}&#x3D;\alpha\mathrm{DGIB}_{MS}+(1-\alpha)\mathrm{DGIB}_C<br>$$<br>而两种信息瓶颈的区别就在于已知量是谁：</p>
<p><img src="/../pic/image-20240730005615993.png"></p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><ul>
<li><p>在原始数据集上训练，然后对测试集进行特征或结构的攻击：</p>
<p><img src="/../pic/image-20240725215038674.png"></p>
</li>
<li><p>使用NETTACK对数据集进行攻击，包括evasion attacking 和 poisoning attacking：</p>
<p><img src="/../pic/image-20240725215227696.png"></p>
</li>
<li><p>消融实验，探究损失函数中的不同部分对结果的影响（Figure 4）</p>
</li>
<li><p>训练过程中DGIB理论每一部分互信息的变化情况（Figure 5）</p>
</li>
<li><p>DGIB中控制最小性和充足性的超参数 $\beta$ 对结果的影响（Figure 6）</p>
<p><img src="/../pic/image-20240725215510232.png"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>按钮无法使用与数学公式无法显示bug修复</title>
    <url>/2024/07/25/http_bug/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="bug发现"><a href="#bug发现" class="headerlink" title="bug发现"></a>bug发现</h3><p>7月17日，当再次提交一个新的博客内容后，发现<strong>提交到github上的网页无法正常显示（但在本地localhost上是正常的）</strong>，直观上有以下几个问题：</p>
<ul>
<li>按钮点击无效，如一键回顶部、白天黑夜模式调整</li>
<li>数学公式无法正常显示</li>
</ul>
<span id="more"></span>

<p><img src="/../pic/image-20240726120459410.png"></p>
<hr>
<h3 id="bug排查"><a href="#bug排查" class="headerlink" title="bug排查"></a>bug排查</h3><h4 id="怀疑文件问题"><a href="#怀疑文件问题" class="headerlink" title="怀疑文件问题"></a>怀疑文件问题</h4><p>因为这个文件是我post一个新文章后才发现的，所以自然而然怀疑这篇文章有问题。删除掉文章后发现问题依旧存在，因此初步排除了文章本身的问题。</p>
<h4 id="怀疑代码问题"><a href="#怀疑代码问题" class="headerlink" title="怀疑代码问题"></a>怀疑代码问题</h4><p>F12进入开发者模式，发现很多报错：</p>
<p><img src="/../pic/image-20240726120340078.png"></p>
<p>经过分析，其中最主要的也是最直接导致错误的应该是如下错误：</p>
<p><img src="/../pic/image-20240726120617980.png"></p>
<p>简单来说本网页使用的是<code>https</code>，但在加载过程中出现了<code>http</code>请求，<strong>请求混用从而<code>http</code>请求被block</strong>，这也就导致一些<code>js</code>组件无法被加载，反映到网页中就是无法正常执行功能。</p>
<p>接下来的任务就是如何解决<code>http</code>请求。</p>
<hr>
<h3 id="bug解决"><a href="#bug解决" class="headerlink" title="bug解决"></a>bug解决</h3><h4 id="网上资料"><a href="#网上资料" class="headerlink" title="网上资料"></a>网上资料</h4><p>搜索了一些资料，解决措施也大差不差，最直接的方式是增加一行代码：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">&quot;Content-Security-Policy&quot;</span> <span class="attr">content</span>=<span class="string">&quot;upgrade-insecure-requests&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>但因为本博客的<code>Html</code>生成是靠着<code>hexo</code>将<code>md</code>文件转写得到的，我不知道如何直接修改其编辑逻辑，于是暂时搁置了这个方案，转而去代码中寻找到底哪里出现了<code>http</code>请求。</p>
<h4 id="代码修改——解决"><a href="#代码修改——解决" class="headerlink" title="代码修改——解决"></a>代码修改——解决</h4><p>浏览生成的网页代码，很容易发现里面并没有<code>http://xxxx</code>，相反，全部都是<code>https://xxxx</code>，这就很奇怪了。</p>
<p>进一步看报错位置所涉及的文件，将报错的文件名反向去<code>Html</code>中寻找，如：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--报错中无法请求pace.min.js文件--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.staticfile.org/pace/1.2.4/pace.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>大概搜了几个，发现报错的资源地址都是<code>&quot;https://cdn.staticfile.org/xxx</code>形式。</p>
<p>直接去搜索这个网址会直接<strong>跳转到</strong><code>https://cdn.staticfile.net/xxx</code>，本质上他们应该指向一个地方。这个地方<strong>恰好也是我在控制台中搜索其对应<code>http://</code>报错所得到的内容</strong>，这便启示我可能是<code>&quot;https://cdn.staticfile.org/xxx</code>的形式不正确，将<code>org</code>改为<code>net</code>即可。</p>
<p>尝试后问题解决，一切恢复正常：</p>
<p><img src="/../pic/image-20240726122515504.png"></p>
<p><img src="/../pic/image-20240726122329111.png"></p>
<p>最终写一个<code>python</code>脚本，遍历编译生成的所有网页源代码，将其中对应的内容进行修改即可：：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">current_directory = <span class="string">&#x27;.&#x27;</span></span><br><span class="line">html_file_pattern = re.<span class="built_in">compile</span>(<span class="string">r&#x27;.*\.html$&#x27;</span>, re.IGNORECASE)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">replace_org_with_net</span>(<span class="params">content</span>):</span><br><span class="line">    <span class="keyword">return</span> re.sub(<span class="string">r&#x27;cdn.staticfile.org&#x27;</span>, <span class="string">&#x27;cdn.staticfile.net&#x27;</span>, content)</span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(current_directory):</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> html_file_pattern.<span class="keyword">match</span>(file):</span><br><span class="line">            file_path = os.path.join(root, file)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                content = f.read()</span><br><span class="line">            new_content = replace_org_with_net(content)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(new_content)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Updated file: <span class="subst">&#123;file_path&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished processing all HTML files.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="bug猜想"><a href="#bug猜想" class="headerlink" title="bug猜想"></a>bug猜想</h3><p>可能是网站协议发生了更新，导致之前可行的方案如今变得不可行。</p>
<p>当然这个问题可能也反映出我安装的库有一些老旧了，但是毕竟好久没有接触到这个环境，我也不太敢去乱动什么，因此才采用了这种较为“麻烦”的方案来进行解决</p>
]]></content>
      <categories>
        <category>test_categories</category>
      </categories>
      <tags>
        <tag>test_tag</tag>
      </tags>
  </entry>
  <entry>
    <title>《Graph Information Bottleneck》论文解读</title>
    <url>/2024/07/25/GIB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://arxiv.org/abs/2010.12811">click here</a></p>
<p>Code：<a href="https://github.com/snap-stanford/GIB">GIB(github.com)</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本篇论文是2020Neurips上的论文。</p>
<p>这篇论文将<strong>信息瓶颈理论</strong>创新性地应用于图神经网络中，具体来说，文章核心围绕着信息瓶颈理论的——minimal sufficient 特点展开的，从理论推导、实例化、实验证明等方面证明了这种方法的重要性。</p>
<span id="more"></span>

<p>信息瓶颈理论的最小-充足特点，能够在<strong>保证特征表达</strong>的同时很好地<strong>提高模型的鲁棒性</strong>。但其若直接应用在图上，会有两个较大的<strong>问题</strong>：</p>
<ul>
<li>IB 的模型假设数据集中的训练示例是<strong>独立的和同分布</strong>的（$i.i.d$）。对于图结构数据，这个假设<strong>不再成立</strong>。</li>
<li><strong>结构</strong>信息对于表示图结构数据是必不可少的。</li>
</ul>
<p>因此如何建模这个问题至关重要。如何将IB理论迁移到图中，让我们正式开始了解这篇论文的内容。</p>
<hr>
<h3 id="前置理论"><a href="#前置理论" class="headerlink" title="前置理论"></a>前置理论</h3><p><img src="/../pic/image-20240725194555026.png"></p>
<h4 id="图上的信息瓶颈理论"><a href="#图上的信息瓶颈理论" class="headerlink" title="图上的信息瓶颈理论"></a>图上的信息瓶颈理论</h4><p><img src="/../pic/image-20240725180435634.png"></p>
<p>图信息瓶颈的核心公式如上图所示，旨在<strong>增加</strong>潜在表示 $Z$ 与目标 $Y$ 之间的互信息，同时<strong>减少</strong>潜在表示 $Z$ 与原始特征 $X$ 之间的互信息。这也就是所谓的“最小 - 充足”原则。</p>
<p>针对之前提到的<strong>两个问题</strong>，文中使用local-dependence assumption来限制 $P(Z|D)$ 的搜索域，同时运用Markov chain来逐层对feature和structure进行提取，使IB原则迁移到图中。</p>
<p><img src="/../pic/image-20240725181530343.png" alt="local-dependence assumption"></p>
<p><strong>local-dependence assumption</strong>：点 $v$ 只与他 $k$ 跳邻居有关，与其他节点是独立的。</p>
<p><img src="/../pic/image-20240725181855813.png" alt="Markov chain"></p>
<p><strong>Markov chain</strong>：第 $l$ 层图结构信息只与原始图结构 $A$ 和第 $l-1$ 层特征信息有关，第 $l$ 层特征信息只与第 $l$ 层图结构信息和第 $l-1$ 层特征信息有关。</p>
<p>所以优化目标函数：<br>$$<br>\min_{\mathbb{P}(Z_X^{(L)}|\mathcal{D})\in\Omega}\mathrm{GIB}_\beta(\mathcal{D},Y;Z_X^{(L)})\triangleq\left[-I(Y;Z_X^{(L)})+\beta I(\mathcal{D};Z_X^{(L)})\right]<br>$$<br>实际上就是在优化两个分布：$\mathbb P(Z_X^{(l)}|Z_X^{(l-1)},Z_A^{(l)}),\ \mathbb{P}(Z_A^{(l)}|Z_X^{(l-1)},A)$。</p>
<h4 id="GIB的变分界"><a href="#GIB的变分界" class="headerlink" title="GIB的变分界"></a>GIB的变分界</h4><p>具体证明可在appendix中找到。</p>
<p>(1) $I(Y;Z_X^{(L)})$ 的下界：</p>
<p><img src="/../pic/image-20240725191245373.png"></p>
<p><del>为什么我看附录感觉第二个加号应该是减号</del></p>
<p>(2) $I(\mathcal D; Z_X^{(L)})$ 的上界：</p>
<p><img src="/../pic/image-20240725191310666.png"></p>
<p>所以模型中<strong>优化函数实际上优化的是GBI的上界</strong>。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><h4 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h4><p>本文给出了两个GIB使用方法：GIB-Cat（基于categorical distributions）和GIB-Bern（基于Bernoulli distribution）。</p>
<p>第三步的邻居采样应用了图注意力机制网络（GAT）来计算目标节点邻居的注意力。</p>
<p>此外：</p>
<ul>
<li>GIB-Cat将注意力值作为分类分布的参数，从多跳邻居中采样 $k$ 个节点构成 $Z_{A,v}^{(l+1)}$（Algorithm 2）</li>
<li>GIB-Bern则是将注意力值（softmax替换为sigmoid）作为对邻居分别独立采样的伯努利分布的参数（Algorithm 3）</li>
</ul>
<p>第3、7步使用了重参数化技巧。</p>
<p><img src="/../pic/image-20240725191938833.png"></p>
<p><img src="/../pic/image-20240725192004626.png"></p>
<h4 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h4><ul>
<li><p>$\widehat{AIB}$的估计：对于两种分布</p>
<p><img src="/../pic/image-20240725192252644.png"></p>
</li>
<li><p>$\widehat{XIB}$的估计：假设 $\mathbb Q(Z_X^{(l)})$ 服从混合的高斯分布，具体而言，每一个点的分布服从于若干高斯分布的加权求和，其中<strong>权重、均值、方差是可学习的</strong>。</p>
<p><img src="/../pic/image-20240725192353031.png"></p>
</li>
</ul>
<p>至此便有：$I(\mathcal D;Z_X^{(L)})\to\sum_{l\in S_A}\widehat{\mathrm{AIB}}^{(l)}+\sum_{l\in S_X}\widehat{\mathrm{XIB}}^{(l)}$。</p>
<ul>
<li><p>$I(Y,Z_X^{(L)})$的估计：通过忽略常量，得</p>
<p><img src="/../pic/image-20240725193036315.png"></p>
</li>
</ul>
<p>至此完成了理论到实际的转换。</p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><p>本文针对性的对鲁棒性进行了验证。</p>
<ul>
<li><p>鲁棒性检验，使用Nettack方式，两种测试模式：模型训练后攻击（Evasive）和模型训练前攻击（Poisoning）。</p>
<p><img src="/../pic/image-20240725194147099.png"></p>
</li>
<li><p>消融实验，使用不停地训练目标</p>
<p><img src="/../pic/image-20240725194249685.png"></p>
<p>只使用AIB或XIB，那岂不是没有了特征与目标之间的训练？？？</p>
</li>
<li><p>对节点特征的噪声攻击：</p>
<p><img src="/../pic/image-20240725194450796.png"></p>
</li>
</ul>
<hr>
<h3 id="可能深入方向"><a href="#可能深入方向" class="headerlink" title="可能深入方向"></a>可能深入方向</h3><p>本文图的结构服务于特征 $Z$ 的生成，并没有显式的计算结构熵，或许可以将结构熵加入，进一步简化图本身的复杂度，来更好的对信息进行抽取。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>《Structural Entropy Based Graph Structure Learning for Node Classification》论文解读</title>
    <url>/2024/07/18/Structural%20Entropy%20based%20GSL/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28679">click here</a></p>
<p>可参考资料：<a href="https://arxiv.org/abs/2201.05540">$CoGSL$</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本篇论文是2024AAAI上的论文。</p>
<p>由于GNN的性能高度依赖于输入图结构的质量，因此如今学者已经提出了各种**图结构学习(GSL)**技术来增强图结构。</p>
<p>大多数现有的GSL方法都专注于融合从图中提取的不同结构特征（基本视图），但很少包含图语义，例如<strong>层次社区</strong>。因此，在处理包含来自现实世界复杂系统的噪声的图时，它们可能还不够。</p>
<span id="more"></span>

<p>本文结合了<strong>信息瓶颈、最大化互信息</strong>等理论，通过<strong>图增强、编码树、图混合</strong>等技术完成了图结构学习，并形成节点的embedding。</p>
<hr>
<h3 id="小梳理"><a href="#小梳理" class="headerlink" title="小梳理"></a>小梳理</h3><p>本篇论文通读下来感觉信息量还是蛮大的，所以在介绍之前我先简单做一个梳理。</p>
<p>本篇论文我理解为是在 $CoGSL$ 后续所做的工作，其最大的贡献是<strong>将图视角与编码树视角相结合</strong>，不仅最大化图之间、编码与标签之间的互信息，同时还要优化图与编码树之间的互信息，因此本文有很多的篇章来描述编码树如何构造以及损失函数如何定义。</p>
<p>整个流程下图描述的很清晰，再读文章的时候与这张图对照能够更好的了解具体流程。</p>
<p><img src="/../pic/image-20240718150406931.png"></p>
<p>简单来说，首先对两个得到的图基础视图进行增强，并根据这两张图生成融合后的图。分别对每张图构造编码树，并根据图上的编码得到编码树上每个节点的编码。接下来优化图与图之间、树与树之间、图与数之间、编码与标签之间的互信息即可。</p>
<p>本篇论文我个人感觉就是在不同视角下不断切换，提供更多的互信息优化依据，以得到更好的模型效果。</p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><h4 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h4><p><strong>图的一维结构熵：</strong><br>$$<br>H^1(G)&#x3D;-\sum_{v\in V}\frac{d_v}{vol(G)}\log_2\frac{d_v}{vol(G)}<br>$$<br>其中 $d_v$ 代表 $v$ 节点所连边的权重和，$vol(G)&#x3D;\sum_v d_v$</p>
<p><strong>编码树的 $K$ 维结构熵：</strong><br>$$<br>H^{K}(G)&#x3D;\min_{\mathcal{T}}\sum_{\alpha\in\mathcal{T},\alpha\neq\lambda}H^{\mathcal{T}}(G;\alpha),\quad\quad H^{\mathcal{T}}(G;\alpha)&#x3D;-\frac{g_\alpha}{vol(G)}\log_{2}\frac{\mathcal V_\alpha}{\mathcal V_{\alpha^-}}<br>$$<br>$\alpha$ 为树上结点，$\lambda$ 为根节点，其中包含图上的所有node。$g_\alpha$ 是从点 $\alpha$ 连向外部的边权之和，$\mathcal V_a$ 是$\alpha$ 内图节点所连边权的和 $\mathcal V_\alpha&#x3D;\sum_{v\in T_\alpha} d_v$，$\alpha^-$是 $\alpha$ 节点的父节点。</p>
<h4 id="理论优化思想"><a href="#理论优化思想" class="headerlink" title="理论优化思想"></a>理论优化思想</h4><p>图结构学习能够用以下公式刻画：<br>$$<br>\mathcal L_{gsl}&#x3D;\mathcal L_{cls}(Z^\star,Y_L)+\mu\mathcal L_{reg}(A^\star,Z^\star,A)<br>$$<br>前者是编码与标签的关系，后者是重建的图结构与原始图结构、标签之间的约束。</p>
<p>在本文总，采用<strong>信息瓶颈理论</strong>进行建模：<br>$$<br>GIB(G,Y;Z^\star)&#x3D;\max_{\boldsymbol{Z}}\left[I(\boldsymbol{Z};Y)-\beta I(\boldsymbol{Z};G)\right]<br>$$<br>旨在最大化编码与标签的关系，同时希望从图 $G$ 中提取较少的信息即可。但是 $I(Z,G)$ 的计算是困难的，因此转化问题（<strong>感觉可以借鉴</strong>）：<br>$$<br>\min_{G_{s}}\max_{\boldsymbol{Z}}I(\boldsymbol{Z};Y_{L})+\beta I(\boldsymbol{Z};G_{s}) \ s.t.,H^{1}(G)&gt;H^{1}(G_{s}),I(G;Y_{L})&#x3D;I(G_{s};Y_{L})<br>$$<br>其中 $G_s$ 为 $G$ 的采样子图。也就是说提取较少有用信息这个限制通过 $G_s$ 来进行限制，换句话来说，其保证了<strong>捕获节点分类的最小和充分信息</strong>。</p>
<p>但是方法中具体而言并不是直接优化这个式子，而是采用不同损失来实现这个思想。</p>
<h4 id="理论方法"><a href="#理论方法" class="headerlink" title="理论方法"></a>理论方法</h4><p><img src="/../pic/image-20240718150406931.png"></p>
<p>首先根据 $CoGSL$ 方法，生成两个基础视图的图结构 $G^1,G^2$。</p>
<h5 id="图增强"><a href="#图增强" class="headerlink" title="图增强"></a>图增强</h5><p>接下来对图进行增强，使用 GCN 网络得到每个节点的编码 $z_i$，根据<strong>余弦相似度</strong>计算出节点对之间的相似度。进一步，根据这些相似度，构造 $kNN$ graph，而 $k$ 的选择需要满足图结构熵的最小：<br>$$<br>H^1(G^1_{k-1}) \geq H^1(G^1_{k}) \leq H^1(G^1_{k+1})<br>$$<br>最终增强后的图为 $G_{en}^1&#x3D;G^1+\xi G_k^{1}$，$G^2_{en}$ 同理。</p>
<h5 id="编码树的构建"><a href="#编码树的构建" class="headerlink" title="编码树的构建"></a>编码树的构建</h5><p>构建目标依旧用到了熵思想：<br>$$<br>\mathcal{T}^{\star}&#x3D;\underset{\forall\mathcal{T}:height(\mathcal{T})\leq K}{\arg\min}(H^{\mathcal{T}}(G))<br>$$<br>为了构建一个树，有三种操作：</p>
<ul>
<li><p>合并：对于两个community $P_i,P_j$，合并操作 $op_m(P_i,P_j)$ 后剩下的community集合为 $\mathcal{P}&#x3D;\{P_{1},…,P_{i-1},P_{i+1},…,P_{j-1},P_{j+1},…,P_{c},P_{x}\}$</p>
<p>另外文中给出了合并后的结构熵变化，我理解与<strong>决策树中的信息增益类似</strong>。选择信息增益最大的一对进行合并。</p>
</li>
<li><p>压缩：$op_c(\mathcal P)$ 即将 $\mathcal P$ 内的所有community分别压缩成一个点，边权为之前若干边权的和。</p>
</li>
<li><p>更新：$op_u(\mathcal T,\mathcal P)$ ，将 $\mathcal P$ 内部所有的community作为 $\mathcal T$ 的叶子结点。</p>
</li>
</ul>
<p>算法过程为：</p>
<p><img src="/../pic/image-20240718154119776.png"></p>
<p>感觉跟决策树、霍夫曼编码思想相似。</p>
<h5 id="最终合并图结构的构建"><a href="#最终合并图结构的构建" class="headerlink" title="最终合并图结构的构建"></a>最终合并图结构的构建</h5><p>合并的适合考虑了community之间的关系，也就是说考虑了<strong>编码树</strong>。定义叶子结点的社区影响：<br>$$<br>\varepsilon_{\alpha}&#x3D;\frac{H^{\mathcal T}(G;\alpha)}{\sum_{\delta\in\mathcal T}H^{\mathcal T}(G;\delta)}<br>$$<br>其中 $\delta$ 是从树根 $\lambda$ 到 $\alpha$ 路径上的点。</p>
<p>接下来获得系数 $a$，以 $G^1$ 为例：<br>$$<br>a_i^1&#x3D;\frac{\sigma(\pi_i^1)\cdot\pi_i^1+\sigma(\varepsilon_i^1)\cdot\varepsilon_i^1}{\sigma(\pi_i^1)+\sigma(\varepsilon_i^1)}<br>$$<br>其中 $\sigma(·)$ 是激活函数，$\pi_i^1$ 是 $v_i$ 对 $G^1$ 的预测置信度（方法与$CoGSL$）一致。</p>
<p>进一步获得权重：<br>$$<br>w_i^1&#x3D;a_i^1&#x2F;(a_i^1+a_i^2),\quad w_i^2&#x3D;a_i^2&#x2F;(a_i^1+a_i^2)<br>$$<br>然后便能得到融合后的图了：<br>$$<br>G_i^\star&#x3D;w_i^1\cdot G_{en,i}^1+w_i^2\cdot G_{en,i}^2<br>$$</p>
<h4 id="双目标优化损失"><a href="#双目标优化损失" class="headerlink" title="双目标优化损失"></a>双目标优化损失</h4><p><strong>第一个</strong>损失当然是预测准确率的交叉熵：<br>$$<br>\mathcal L_{cls}&#x3D;\sum_{i&#x3D;1}^2\mathcal L_{cross}(\Pi^i,Y_L)+\mathcal L_{cross}(\Pi^\star,Y_L)<br>$$<br><strong>第二个</strong>就略有复杂了。</p>
<p>我们先定义编码树上除去叶节点的编码方式（因为叶节点每个节点代表图上一个点，他的编码就是GCN得到的）：<br>$$<br>h_\alpha&#x3D;\sum_{i&#x3D;1}^m\left[\frac{h^{\mathcal{T}}(G;\alpha^{\langle i\rangle})}{\sum_{j&#x3D;1}^mh^{\mathcal{T}}(G;\alpha^{\langle j\rangle})}h_{\alpha\langle i\rangle}\right]<br>$$<br>其中 $m$ 代表的是 $\alpha$ 的子节点。</p>
<p>这样我们就能够刻画节点与树之间的信息关系了：<br>$$<br>\mathcal L_{hc}(\boldsymbol Z;\mathcal{T})&#x3D;-\sum_{l&#x3D;2}^K\theta_l\log_2\sum_{i&#x3D;1}^n\frac{sim(\boldsymbol z_i,\boldsymbol h_{(i,l)})}{\sum_{j&#x3D;1,j\neq i}^nsim(\boldsymbol z_j,\boldsymbol h_{(j,l)})},\quad \theta_l&#x3D;\gamma(1-\gamma)^l<br>$$<br>$h_{(i,l)}$ 是节点 $v_i$ 的第 $l$ 层community在 $\mathcal T$ 中的嵌入。这样每一组图和编码树之间的损失定义为：<br>$$<br>\mathcal L_{mmp}^1&#x3D;\mathcal L_{cross}^1(\Pi^1,Y_L)+\mathcal L_{hc}(Z^1;\mathcal{T}^1)<br>$$<br>因为共有三组（$G^1,G^2,G^\star$），因此 $\mathcal L_{mmp}&#x3D;\mathcal L_{mmp}^{1}+\mathcal L_{mmp}^{2}+\mathcal L_{mmp}^{\star}$</p>
<p>除此之外，还要最大化不同组之间的互信息：<br>$$<br>\mathcal L_{miet}(\mathcal{T}^1,\mathcal{T}^2)&#x3D;\frac{1}{2}\left[\mathcal L_{hc}(Z^1;\mathcal{T}^2)+\mathcal L_{hc}(Z^2;\mathcal{T}^1)\right]<br>$$<br>最终才能得到第二个损失优化目标（太复杂了）：<br>$$<br>\mathcal L_{ve}&#x3D;\mathcal L_{mmp}+(\mathcal L_{miet}(\mathcal T^{1},\mathcal T^{2})+\mathcal L_{miet}(\mathcal T^{1},\mathcal T^{\star}) +\mathcal L_{miet}(\mathcal T^{2},\mathcal T^{\star}))<br>$$</p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><h4 id="不同模型的横向对比"><a href="#不同模型的横向对比" class="headerlink" title="不同模型的横向对比"></a>不同模型的横向对比</h4><p><img src="/../pic/image-20240718161728649.png"></p>
<h4 id="当图被攻击后"><a href="#当图被攻击后" class="headerlink" title="当图被攻击后"></a>当图被攻击后</h4><p>‘Ours_v1’、’Ours_v2’ 和 ‘Ours_both’的曲线是我们方法的第一、第二和所有基本视图的结果，都被攻击。</p>
<p><img src="/../pic/image-20240718162224568.png"></p>
<h4 id="编码树的有效性"><a href="#编码树的有效性" class="headerlink" title="编码树的有效性"></a>编码树的有效性</h4><p>与其他两种社区结构提取方法kNN和Louvain进行比较。同时探究编码树深度的影响。</p>
<p><img src="/../pic/image-20240718162337376.png"></p>
<h4 id="两个视图的混合方法的有效性"><a href="#两个视图的混合方法的有效性" class="headerlink" title="两个视图的混合方法的有效性"></a>两个视图的混合方法的有效性</h4><p>与其他三种机制进行比较：average, attention and prediction confidence</p>
<p><img src="/../pic/image-20240718162442705.png"></p>
<hr>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>后期阅读其他论文发现这篇论文其实是如下论文的一个<strong>改编与延伸</strong>，因为内容很相似，因此不另外书写一篇内容：</p>
<ul>
<li>[<a href="https://arxiv.org/abs/2303.09778">2303.09778] SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization (arxiv.org)</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>《Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural Networks》论文解读</title>
    <url>/2024/07/17/MinGE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://www.ijcai.org/proceedings/2021/381">click here</a></p>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><p>本篇论文是2021IJCAI上的论文。</p>
<p>在Node Embedding Dimension Selection (NEDS)问题中，对于编码维度的设置，常使用梯度搜索或者经验知识的方法来进行选择，但这种方法面临着<strong>庞大的计算量和较差的模型表现</strong>等问题。</p>
<span id="more"></span>

<p>而本文受到维度选择工作的启发，以最小熵原理（minimum entropy principle）重新审视这个问题，提出了<strong>Minimum Graph Entropy 算法</strong>，特别的，从两方面来考虑熵：</p>
<ul>
<li>从feature层面上</li>
<li>从structure层面上</li>
</ul>
<p>结果也证明了这种方法的有效性</p>
<p><strong>注：这篇论文是设计了一种算法找到最优的编码维度空间大小，而非设计了一种深度学习方法。</strong></p>
<hr>
<h3 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h3><p><img src="/../pic/image-20240717142624016.png"></p>
<p>定义图熵为：<br>$$<br>H_g&#x3D;H_f+\lambda H_s<br>$$<br>其中 $H_f$ 是feature熵， $H_s$ 是structure熵。通过设置 $H_g&#x3D;0$ 我们能够得到合适的embedding维度 $n$。</p>
<h4 id="Feature-Entropy"><a href="#Feature-Entropy" class="headerlink" title="Feature Entropy"></a>Feature Entropy</h4><p>说道熵就一定要提到概率分布，那么这里的概率分布如何定义的呢？<br>$$<br>P(v_i,v_j)&#x3D;\frac{e^{\langle v_i,v_j\rangle}}{\sum_{i,j}e^{\langle v_i,v_j\rangle}},<br>$$<br>其中 $\langle v_i,v_j\rangle$ 代表两个节点的embedding向量的点乘。<del>至于点乘越大概率越大是否合理、是否有意义呢</del></p>
<p>简单的化简过后，我们便能够得到熵的表达式：<br>$$<br>H_f&#x3D;logZ-\frac{1}{Z}\sum_{ij}e^{\langle v_i,v_j\rangle}\langle v_i,v_j\rangle, \quad Z&#x3D;\sum_{i,j}e^{\langle v_i,v_j\rangle}<br>$$<br>接下来用<strong>样本的均值来代替分布的期望</strong>：<br>$$<br>Z&#x3D;\sum_{ij}e^{\langle v_{i},v_{j}\rangle}&#x3D;N^{2}\frac{1}{N^{2}}\sum_{ij}e^{\langle v_{i},v_{j}\rangle}\approx N^{2}E_{v_{i},v_{j}}(e^{\langle v_{i},v_{j}\rangle})<br>$$</p>
<p>$$<br>\sum_{ij}e^{\langle v_{i},v_{j}\rangle}\langle v_{i},v_{j}\rangle&#x3D;N^{2}\frac{1}{N^{2}}\sum_{ij}e^{\langle v_{i},v_{j}\rangle}\langle v_{i},v_{j}\rangle\approx N^{2}E_{v_{i},v_{j}}(e^{\langle v_{i},v_{j}\rangle}\langle v_{i},v_{j}\rangle)<br>$$</p>
<p>从而代回熵的计算公式，我们有：<br>$$<br>H_f&#x3D;logN^2+logE_{v_i,v_j}(e^{\langle v_i,v_j\rangle})-\frac{E_{v_i,v_j}(e^{\langle v_i,v_j\rangle}\langle v_i,v_j\rangle)}{E_{v_i,v_j}(e^{\langle v_i,v_j\rangle})}<br>$$<br>接下来遇到的问题就是，点乘并不好计算，因为我不知道编码后向量的具体数值。此处作者采用的方式为：<strong>将embedding映射到半径为 $\sqrt n$ 的 $n$ 维超球体上</strong>。此时有 $\langle v_i,v_j\rangle&#x3D;n\cdot\cos(\theta)$。</p>
<p><img src="/../pic/image-20240717155547471.png"></p>
<p>为了方便计算，将一个向量固定为 $y&#x3D;(1, 0,\cdots,0)$，这样能够的得到 $\cos \theta&#x3D;\varphi_1$</p>
<p>根据文献，能够知道角度的概率密度函数（这是怎么找到的）：<br>$$<br>P_n(\theta)&#x3D;\frac{\Gamma(\frac{n}{2})}{\Gamma(\frac{n-1}{2})\sqrt{\pi}}sin^{n-2}\theta.<br>$$<br>最终<strong>计算点乘的期望</strong>巧妙地转换为<strong>计算角度的期望</strong>：<br>$$<br>E(e^{ncos\theta}ncos\theta)&#x3D;\int_0^\pi e^{ncos\theta}ncos\theta P_n(\theta)d_\theta<br>$$</p>
<p>$$<br>E(e^{ncos\theta})&#x3D;\int_0^\pi e^{ncos\theta}P_n(\theta)d_\theta<br>$$</p>
<h4 id="结构熵"><a href="#结构熵" class="headerlink" title="结构熵"></a>结构熵</h4><p>结构熵考虑的是two-hop邻居。</p>
<p>根据邻接矩阵的特点，两跳邻居便可以通过 $A^2&#x3D;A^TA$ 来进行刻画。进一步得到能够描述度信息的向量 $D_r$：<br>$$<br>D_r&#x3D;D^TA_r^2, \quad A_r^2[i,j]&#x3D;\frac{A^2[i,j]}{\sum_jA^2[i,j]}<br>$$<br>从而有：<br>$$<br>H_s&#x3D;-\sum_i^NP_ilogP_i&#x3D;-\sum_i\frac{D_r[i]}{\sum_iD_r[i]}log(\frac{D_r[i]}{\sum_iD_r[i]}),<br>$$<br>有一些问题：</p>
<ul>
<li>邻接矩阵平方后得到的是二跳邻居的连接信息，此时没有一跳邻居的信息。</li>
<li>$D_r$ 的意义解释是什么。</li>
</ul>
<h4 id="总结来看"><a href="#总结来看" class="headerlink" title="总结来看"></a>总结来看</h4><p>最终我们目标为求解 $H_g&#x3D;0$ 时候的 $n$。<br>$$<br>H_{g}&#x3D;H_f+\lambda H_s &#x3D;logN^2+log\int_0^\pi e^{ncos\theta}P_n(\theta)d_\theta - \frac{\int_0^\pi e^{ncos\theta}ncos\theta P_n(\theta)d_\theta}{\int_0^\pi e^{ncos\theta}P_n(\theta)d_\theta}<br>-\lambda\sum_{i}\frac{D_{r}[i]}{\sum_{i}D_{r}[i]}log(\frac{D_{r}[i]}{\sum_{i}D_{r}[i]})<br>$$<br>整体过程也比较清晰，重复：设计的是<strong>算法</strong>，<strong>不是模型</strong>：</p>
<p><img src="/../pic/image-20240717160733853.png"></p>
<p><strong>能否将其结合到图网络中，形成端到端的模型？</strong></p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><p>文中进行了节点分类与链路预测任务。<strong>从结果上看，在算法得到的维度数量上的实验结果，为最优或接近最优的效果，证明了有效性。</strong></p>
<p><img src="/../pic/image-20240717160924478.png"></p>
<p>这段话也表现了此方法的优越性：</p>
<p><img src="/../pic/image-20240717161012388.png"></p>
<p>另外文中还分析了时间复杂度等问题，说明了其在时间上的消耗是可接受的。</p>
<p><img src="/../pic/image-20240717161101508.png"></p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>《Deep Graph Infomax》论文解读</title>
    <url>/2024/07/14/Deep%20Graph%20Infomax/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文传送门：<a href="https://arxiv.org/pdf/1809.10341">click here</a></p>
<p>推荐参考链接：</p>
<ul>
<li>DIM：<a href="https://www.jiqizhixin.com/articles/2018-10-12-11">深度学习中的互信息：无监督提取特征 | 机器之心 (jiqizhixin.com)</a></li>
<li>$f$ 散度($D_f$)的估算：<a href="https://kexue.fm/archives/6016">f-GAN简介：GAN模型的生产车间 - 科学空间|Scientific Spaces (kexue.fm)</a></li>
</ul>
<h3 id="论文动机"><a href="#论文动机" class="headerlink" title="论文动机"></a>论文动机</h3><span id="more"></span>

<p>图神经网络已经有了很大发展，但大多数成功的方法使用的是监督学习，而在现实中大多数的图数据事实上是未标记的。因此针对这种无标签的图信息，一种<strong>无监督&#x2F;自监督学习方法</strong>是重要的。</p>
<p>目前的无监督表示学习<strong>大多依赖于随机游走</strong>方法，其有如下的缺点：</p>
<ul>
<li>过分强调了邻居之间的信息，而牺牲了整体的结构信息</li>
<li>性能高度依赖于超参设置</li>
<li>可解释性较差，即无法确定随机游走是不是真的提供了有用信息（假设节点与邻居较为相似的观点是一种归纳偏置）</li>
</ul>
<p>因此本文提出了一种<strong>基于互信息</strong>得到的<strong>无监督图学习方法</strong>。</p>
<p>具体来说，本文将<a href="https://arxiv.org/abs/1808.06670">这篇论文</a>的 <code>Deep InfoMax</code> 思想运用到了图神经网络中。</p>
<hr>
<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p><del>（我感觉这篇论文就是把CV中的方法直接运用到图神经网络中，似乎并没有改变什么）</del></p>
<h4 id="我们有什么？"><a href="#我们有什么？" class="headerlink" title="我们有什么？"></a>我们有什么？</h4><ol>
<li>对于图上每一个节点，我们有他们的特征向量集合 $X&#x3D;\{\vec {x_1}, \vec {x_2}, \dots,\vec {x_N}\}$</li>
<li>我们有邻接矩阵 $A$，论文中设置无边权，即 $A_{ij}\in\{0,1\}$</li>
</ol>
<h4 id="我们要做什么？"><a href="#我们要做什么？" class="headerlink" title="我们要做什么？"></a>我们要做什么？</h4><p>我们希望能够训练出一个编码器 ${\mathcal E} : \mathbb{R}^{N\times F} \times \mathbb{R}^{N\times N} \to \mathbb{R}^{N\times F^{\prime}}$，使得 ${\mathcal E}(X,A)&#x3D;H&#x3D;\{\vec {h_1}, \vec {h_2}, \dots,\vec {h_N}\}$表示每个节点编码后的高级表示。</p>
<h4 id="我们怎么做？"><a href="#我们怎么做？" class="headerlink" title="我们怎么做？"></a>我们怎么做？</h4><p>核心思想为<strong>局部-全局互信息最大化</strong>。</p>
<p>具体来说，运用图卷积方法作为编码器 ${\mathcal E}$ ，获得每个节点的表示 $H$ 。事实上，图卷积得到的向量是<strong>以节点为中心的图的patch</strong>。这是<strong>局部</strong>信息。</p>
<p>接下来获得<strong>全局</strong>的图级向量表示 $\vec s$。定义函数 ${\mathcal R} : \mathbb{R}^{N\times F} \to \mathbb{R}^{F}$，实现了从patch到全局的信息汇总：$\vec s&#x3D;\mathcal R({\mathcal E}(X,A))$。在实验中使用的就是均值函数：<br>$$<br>\mathcal R(H)&#x3D;\sigma\left(\frac1N\sum_{i&#x3D;1}^N\vec{h}_i\right)<br>$$<br>接下来的步骤与对比学习类似，构造图的负样例，得到负样本图上的每一个patch的表示 $\tilde H$。与对比学习不同的是，这里希望 $H$ 与 $\vec s$ 尽可能接“近”，$\tilde H$ 与 $\vec s$ 尽可能”远“。如下图：</p>
<p><img src="/../pic/image-20240715001048611.png"></p>
<p>而这里刻画”远近“是通过一个判别器 ${\mathcal D}$ 来实现的，这是网络<strong>学出来的</strong>，具体而言：<br>$$<br>\mathcal D(\vec h,\vec s)&#x3D;\sigma(\vec h^TW\vec s)<br>$$<br>整个方法的优化目标为优化如下函数：</p>
<p><img src="/../pic/image-20240715012617347.png"></p>
<p><strong>优化这个函数事实上就是极大化互信息量</strong>。至于为什么，<strong>参考链接</strong>中给出的两个网址较为清晰全面的进行了推导。</p>
<p>总结！整个过程可以分为五个部分：</p>
<p><img src="/../pic/image-20240715012655032.png"></p>
<hr>
<h3 id="实验设置与结果"><a href="#实验设置与结果" class="headerlink" title="实验设置与结果"></a>实验设置与结果</h3><h4 id="Transductive-learning——直推式学习"><a href="#Transductive-learning——直推式学习" class="headerlink" title="Transductive learning——直推式学习"></a>Transductive learning——直推式学习</h4><p>编码器采用GCN网络：<br>$$<br>\mathcal{E}(\mathbf{X},\mathbf{A})&#x3D;\sigma\left(\mathbf{\hat{D}}^{-\frac{1}{2}}\mathbf{\hat{A}}\mathbf{\hat{D}}^{-\frac{1}{2}}\mathbf{X}\mathbf{\Theta}\right)<br>$$<br>负样例的构造方式为：讲 $X$ 打乱，即每个节点的位置不变，但特征变成其他节点了。至于为什么要保留原图结构，论文给出的说法为 “we find those that preserve the graph structure result in the strongest features.”</p>
<h4 id="Inductive-learning-on-large-graphs——大图上的归纳学习"><a href="#Inductive-learning-on-large-graphs——大图上的归纳学习" class="headerlink" title="Inductive learning  on large graphs——大图上的归纳学习"></a>Inductive learning  on large graphs——大图上的归纳学习</h4><p>编码参考 GraphSAGE-GCN 论文中的方法：<br>$$<br>\mathrm{MP}(\mathbf{X},\mathbf{A})&#x3D;\mathrm{\hat{D}}^{-1}\mathrm{\hat{A}X}\Theta<br>$$<br>改变后得到编码器为：<br>$$<br>\widetilde{\mathrm{MP}}(\mathbf{X},\mathbf{A})&#x3D;\sigma\left(\mathbf{X}\mathbf{\Theta}^{\prime}|\mathrm{MP}(\mathbf{X},\mathbf{A})\right)\quad\mathcal{E}(\mathbf{X},\mathbf{A})&#x3D;\widetilde{\mathrm{MP}}_3(\widetilde{\mathrm{MP}}_2(\widetilde{\mathrm{MP}}_1(\mathbf{X},\mathbf{A}),\mathbf{A}),\mathbf{A})<br>$$<br>又因为图比较大，因此整个图的汇总向量是不方便求解的，因此采用了<strong>采样</strong>以及<strong>minibatch上的汇总向量</strong>。</p>
<p><img src="/../pic/image-20240715130935648.png"></p>
<p><img src="/../pic/image-20240715131002076.png"></p>
<p>创造负样例的方式与直推式学习一致，不过对每一个子图patch来进行这种操作。</p>
<h4 id="Inductive-learning-on-large-graphs——多图上的归纳学习"><a href="#Inductive-learning-on-large-graphs——多图上的归纳学习" class="headerlink" title="Inductive learning on large graphs——多图上的归纳学习"></a>Inductive learning on large graphs——多图上的归纳学习</h4><p>编码器为：a three-layer mean-pooling model with dense skip connections<br>$$<br>\mathbf H_1&#x3D;\sigma\left(\mathrm{MP_1}(\mathbf{X},\mathbf{A})\right) \quad<br>\mathbf H_2&#x3D;\sigma\left(\mathrm{MP_2}(\mathbf{H_1}+\mathbf{XW_{skip}},\mathbf{A})\right)<br>$$<br>得到：<br>$$<br>\mathcal{E}(\mathbf{X},\mathbf{A}) &#x3D;\sigma\left(\mathrm{MP_3}(\mathbf{H_2}+\mathbf{H_1}+\mathbf{XW_\mathrm{skip}},\mathbf{A})\right)<br>$$<br>负样例采取的方式为随机采样 (randomly sampled training graphs)，也采用了dropout。</p>
<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="/../pic/image-20240715131745833.png"></p>
<p><img src="/../pic/image-20240715131824999.png"></p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Adaboost</title>
    <url>/2023/10/29/Adaboost/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>我默认大家已经掌握了 $Adaboost$ 的基本操作方法。这篇博客中我将会首先简要介绍一下 $Adaboost$ 的具体流程，接下来将会用大段的推导解决这两个问题：</p>
<blockquote>
<ul>
<li>$Adaboost$ 的误差上界是多少，收敛速率如何。</li>
<li>$Adaboost$ 中最重要的两个参数：第 $m$ 轮得到分类器 $G_m(x)$ 与其对应的权重 $\alpha_m$ 是如何求得的。</li>
</ul>
</blockquote>
<span id="more"></span>

<h2 id="Adaboost-算法流程"><a href="#Adaboost-算法流程" class="headerlink" title="$Adaboost$ 算法流程"></a>$Adaboost$ 算法流程</h2><p><img src="/../pic/adaboost.png"></p>
<p>定义变量：</p>
<blockquote>
<ul>
<li>$G_m(x)$ 为第 $m$ 次迭代得到的弱分类器，是一种映射：$x_i \to \{-1,+1\}$</li>
<li>$f_m(x) &#x3D; \sum_m^{M} G_m(x)$ 是当前得到的强分类器。即弱分类器的线性组合，<strong>值域是连续的</strong>而非只有 $\pm1$.</li>
<li>$w_{m,i}$ 为第 $m$ 次迭代时第 $i$ 个样本的权重.</li>
<li>$\alpha_m$ 为对应 $G_m(x)$ 的权重.</li>
<li>$I(x)$ 为判断函数，当 $x$ 为真则返回 $1$，否则返回 $0$.</li>
<li>$e_m$ 为 $G_m(x)$ 的得到的误差.</li>
<li>$Z_m &#x3D; \sum_i w_{m,i}\exp(-\alpha_my_iG_m(x_i))$ 是规范化子，为了让权重归一化。</li>
</ul>
</blockquote>
<p> 此算法的<strong>循环过程</strong>是这样的：</p>
<ol>
<li>在当前数据集下训练一个简单的分类模型 $G_m(x)$ 使得<strong>误差最小</strong> $\min(\sum_i w_{m,i} I(y_i \neq G_m(x_i)))$</li>
<li>计算当前分类<strong>误差</strong> $e_m&#x3D;\sum_i w_{m,i} I(y_i \neq G_m(x_i))$</li>
<li>计算当前<strong>分类器的权重</strong> $\alpha_m &#x3D; \frac{1}{2}ln(\frac{1-e_m}{e_m})$</li>
<li>更新<strong>样本权重</strong> $w_{m+1,i}&#x3D;\frac{w_{m,i}\exp(-\alpha_my_iG_m(x_i))}{Z_m}$</li>
<li>将弱分类器加入到强分类器中 $f_m(x) &#x3D; f_{m-1}(x) + \alpha_mG_m(x)$</li>
<li>若迭代未结束，则返回第一步，在新的权值下去<strong>寻找新的弱分类器</strong>。</li>
</ol>
<hr>
<h2 id="Adaboost-的误差上界与收敛速率"><a href="#Adaboost-的误差上界与收敛速率" class="headerlink" title="$Adaboost$ 的误差上界与收敛速率"></a>$Adaboost$ 的误差上界与收敛速率</h2><p>在这个部分中我将首先推导出 $Adaboost$ 的<strong>误差上界</strong>，并通过误差上界进行<strong>放缩</strong>，得出其收敛速率随着新弱分类器的加入是<strong>指数下降</strong>的结论。</p>
<h3 id="Adaboost-误差上界"><a href="#Adaboost-误差上界" class="headerlink" title="$Adaboost$ 误差上界"></a>$Adaboost$ 误差上界</h3><p>先给出结论，然后我们对其进行证明。对于最终的误差 $Loss&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^{N}I(G(x_i)\neq y_i)$ 有：<br>$$<br>\begin{aligned}\frac{1}{N}\sum_{i&#x3D;1}^{N}I(G(x_i)\neq y_i)\leq\frac{1}{N}\sum_{i}exp(-y_if(x_i))&#x3D;\prod_{m}Z_m\end{aligned}<br>$$</p>
<h4 id="首先证明第一个不等号是成立的"><a href="#首先证明第一个不等号是成立的" class="headerlink" title="首先证明第一个不等号是成立的"></a>首先证明第一个不等号是成立的</h4><ul>
<li>当 $G(x_i)&#x3D; y_i$ 时，$I(G(x_i)\neq y_i)&#x3D; 0$ 而 $exp(-y_if(x_i))&gt;0$</li>
<li>当 $G(x_i)\neq y_i$ 时，$I(G(x_i)\neq y_i)&#x3D; 1$，但因为 $-y_if(x_i) \ge 0$，所以 $exp(-y_if(x_i))\ge 1$</li>
</ul>
<p>综上，$I(G(x_i)\neq y_i)\le exp(-y_if(x_i))$ 总是成立的，因此第一个不等号得证。</p>
<h4 id="接下来证明第二个等号是成立的"><a href="#接下来证明第二个等号是成立的" class="headerlink" title="接下来证明第二个等号是成立的"></a>接下来证明第二个等号是成立的</h4><p>考虑在更新权重的时候，为了使得权重归一化，因此权重 $w_{m+1, i}$ 与规范化子 $Z_m$ 有如下关系：<br>$$<br>w_{m+1,i}&#x3D;\frac{w_{m,i}exp(-\alpha_my_{i}G_m(x_i))}{Z_{m}}<br>$$<br>因此：<br>$$<br>w_{m,i}exp(-\alpha_my_{i}G_m(x_i))&#x3D;Z_{m}w_{m+1,i}<br>$$<br>先做一个简单的变换，为我们后续证明做一个铺垫：<br>$$<br>\begin{aligned}<br>&amp;\sum_iw_{m,i}exp(-\alpha_my_iG_m(x_i))<br>\\&#x3D;&amp;\sum_iZ_mw_{m+1,i}<br>\\&#x3D;&amp;Z_m\sum_iw_{m+1,i}<br>\end{aligned}<br>$$<br>所以对于待证明不等式组的中间式子，做如下变形。其中有两点注意：1. 在<strong>初始时刻样本权重均为 $\frac1N$，即 $w_{1,i} &#x3D; \frac1N$<strong>，2. 所有</strong>权重和为1</strong>，即 $\sum_iw_{m,i}&#x3D;1$：<br>$$<br>\begin{aligned}<br>&amp;\frac1N\sum_iexp(-y_if(x_i)) \\<br>&#x3D;&amp;\frac1N\sum_iexp(-\sum_{m&#x3D;1}^M\alpha_my_iG_m(x_i)) \\<br>&#x3D;&amp;\sum_{i}w_{1,i}\cdot exp[-\alpha_{1}y_{i}G_{1}\left(x_{i}\right)-\alpha_{2}y_{i}G_{2}\left(x_{i}\right)-\ldots-\alpha_{M}y_{i}G_{M}\left(x_{i}\right)] \\<br>&#x3D;&amp;\sum_iw_{1,i}\prod_{m&#x3D;1}^Mexp(-\alpha_my_iG_m(x_i)) \\<br>&#x3D;&amp;Z_1\sum_iw_{2,i}\prod_{m&#x3D;2}^Mexp(-\alpha_my_iG_m(x_i)) \\<br>&#x3D;&amp;Z_1Z_2\sum_iw_{3,i}\prod_{m&#x3D;3}^Mexp(-\alpha_my_iG_m(x_i)) \\<br>&#x3D;&amp;\ldots  \\<br>&#x3D;&amp;Z_1Z_2 \cdots Z_{M-1}\sum_iw_{M,i}exp(-\alpha_My_iG_M(x_i)) \\<br>&#x3D;&amp;Z_1Z_2 \cdots Z_{M}\sum_iw_{M+1,i}\\<br>&#x3D;&amp;\prod_m^MZ_m<br>\end{aligned}<br>$$<br>因此我们证明了第二个等号是成立的。</p>
<h3 id="Adaboost-收敛速率"><a href="#Adaboost-收敛速率" class="headerlink" title="$Adaboost$ 收敛速率"></a>$Adaboost$ 收敛速率</h3><p>那么收敛速率如何呢？在我们解决这个问题之前，我们首先要找到 $Z_m$ 与误差 $e_m$ 之间的关系。</p>
<p>在求解过程中我们需要用的 $\alpha_m&#x3D;\frac{1}{2}ln(\frac{1-e_m}{e_m})$ 这个结论。至于为什么 $\alpha_m$ 是这个值，我将会在第三部分讲到。<br>$$<br>\begin{aligned}<br>Z_{m}&amp; &#x3D;\sum_{i&#x3D;1}^{N}\left.w_{m,i}\exp(-\alpha_{m}\left.y_{i}\left(x_{i}\right)\right)\right.  \\<br>&amp;&#x3D;\sum_{y_i&#x3D;G_m{(x_i)}}w_{m,i}e^{-\alpha_m}+\sum_{y_i\neq G_m{(x_i)}}w_{m,i}e^{\alpha_m} \\<br>&amp;&#x3D;e^{-\alpha_m}\sum_{y_i&#x3D;G_m\left(x_i\right)}w_{m,i}+e^{\alpha_m}\sum_{y_i\neq  G_m\left(x_i\right)}w_{m,i} \\<br>&amp;&#x3D;\sqrt{\frac{e_m}{1-e_m}}(1-e_m) + \sqrt{\frac{1-e_m}{e_m}}e_m\\<br>&amp;&#x3D;2\sqrt{e_m\left(1-e_m\right)} \\<br>&amp;&#x3D;\sqrt{1-4{\gamma}_m^2}<br>\end{aligned}<br>$$<br>其中我们令 $\gamma_m &#x3D; \frac12 - e_m$。事实上 $\gamma_m$ 一定是正值，我们考虑某分类器得到的误差 $e_m &gt; \frac12$ ，则将这个分类器的分类结果<strong>加个负号得到新分类器</strong>，而此时 $e_m’&#x3D;1-e_m$，即误差小于 $\frac12$ ，因此在得到最优的 $G_m(x)$ 时 $\gamma_m &gt; 0$ 一定成立。</p>
<p>下面我们来证明指数收敛，我们先证明：<br>$$<br>\sqrt{(1-4\gamma_m^2)}\leq exp(-2\gamma_m^2)<br>$$<br>通过泰勒展开，我们能够较容易的证明这个命题：<br>$$<br>\sqrt{1-4r^2}&#x3D;1-2r^2-2r^4+O(r^4)\\<br>e^{-2r^2}&#x3D;1-2r^2+2r^4+O(r^4)<br>$$<br>通过图像我们能够更直观的看出两者的大小关系：</p>
<img src="../pic/放缩.png" style="zoom:50%;" />



<p>因此我们再次对误差进行放缩，能够得到：<br>$$<br>\prod_{m&#x3D;1}^M\sqrt{(1-4\gamma_m^2)}\leq\prod_{m&#x3D;1}^Mexp(-2\gamma_m^2)&#x3D;exp(-2\sum_{m&#x3D;1}^M\gamma_m^2)<br>$$<br>也就是说，随着分类器的增多，指数项上不断减小，这也就表明了 $Adaboost$ 的训练误差是以指数速度下降的。</p>
<h2 id="Adaboost-中分类器与权重的选取——以加法模型解释"><a href="#Adaboost-中分类器与权重的选取——以加法模型解释" class="headerlink" title="$Adaboost$ 中分类器与权重的选取——以加法模型解释"></a>$Adaboost$ 中分类器与权重的选取——以加法模型解释</h2><p>对于分类器来说：<br>$$<br>f(x)&#x3D;\sum_{m&#x3D;1}^M \alpha_mG_m(x)<br>$$<br>我们针对此问题选择损失函数为：<br>$$<br>Loss &#x3D; \sum_{i&#x3D;1}^N exp(-y_if(x_i))<br>$$<br>设强分类器一共有 $M$ 个弱分类器组成，如果直接优化的话，我们需要同时优化 $2M$ 个参数，体量是大的。所以我们采取逐步学习的方法——一次只学习一组 $\alpha_m,G_m(x)$ ，然后加到强分类器中。在这种情况下我们的优化问题变为：<br>$$<br>\begin{aligned}<br>(\alpha_m,G_m(x))&amp;&#x3D;\arg\min_{\alpha,G_m}\sum_{i&#x3D;1}^{N}exp[-y_i\left(f_{m-1}\left(x_i\right)+{\alpha_m}G_m(x_i)\right)]\\<br>&amp;&#x3D;\arg\min_{\alpha,G_m}\sum_{i&#x3D;1}^N\bar{w}_{m,i}exp[-y_i{\alpha_m}G_m(x_i)]<br>\end{aligned}<br>$$</p>
<p>此时 $\bar w_{m,i}$ 对优化问题来说是一个定值，$\bar w_{m,i} &#x3D; \prod_{m&#x3D;1}exp(-\alpha_my_iG_m(x_i))&#x3D;w_{m,i}N\prod_{m&#x3D;1}Z_m&#x3D;Aw_{m,i}$。值得注意的是 $\bar w_{m+1,i}&#x3D;\bar w_{m,i}exp(-\alpha_my_iG_m(x_i))$ 这就是 $Adaboost$ 的权重更新关系。</p>
<h3 id="G-m-x-的选择"><a href="#G-m-x-的选择" class="headerlink" title="$G_m(x)$ 的选择"></a>$G_m(x)$ 的选择</h3><p>我们希望误差最小，观察上面式子，此时 $\alpha_m$ 作为常量看待。因此最优化上式等价于：<br>$$<br>G_m^*(x)&#x3D;\arg\min_G\sum_{i&#x3D;1}^N\bar w_{m,i}I(y_i\neq G(x_i)) &#x3D; \arg\min_G\sum_{i&#x3D;1}^N w_{m,i}I(y_i\neq G(x_i))<br>$$<br>此分类器 $G_m^*(x)$ 即为 $AdaBoost$ 算法的基分类器 $G_m ( x )$ ，它是使得第m次迭代时加权训练数据分类误差最小的基分类器。</p>
<h3 id="alpha-m-的求解"><a href="#alpha-m-的求解" class="headerlink" title="$\alpha_m$ 的求解"></a>$\alpha_m$ 的求解</h3><p>$$<br>\sum_{i&#x3D;1}^N\bar w_{m,i}exp(-y_i \alpha_m G(x_i))&#x3D;\sum_{y_i&#x3D;G_m(x_i)}\bar w_{m,i}e^{-\alpha_m}+\sum_{y_i\neq G_m(x_i)}\bar w_{m,i}e^{\alpha_m}<br>$$</p>
<p>求极值我们需要令其对 $\alpha_m$ 求偏导等于0：<br>$$<br>e^{-\alpha_m}\sum_{y_i&#x3D;G_m(x_i)}\bar w_{m,i}&#x3D;e^{\alpha_m}\sum_{y_i\neq G_m(x_i)}\bar w_{m,i}<br>$$<br>等式两边取对数：<br>$$<br>\begin{aligned}<br>-\alpha_m + ln(\sum_{y_i&#x3D;G_m(x_i)}\bar w_{m,i})&amp;&#x3D;\alpha_m+ ln(\sum_{y_i\neq G_m(x_i)}\bar w_{m,i}) \\<br>2\alpha_m&amp;&#x3D;ln(\frac{\sum_{y_i&#x3D; G_m(x_i)}\bar w_{m,i}}{\sum_{y_i\neq G_m(x_i)}\bar w_{m,i}}) \\<br>2\alpha_m&amp;&#x3D;ln(\frac{\sum_{y_i&#x3D; G_m(x_i)} w_{m,i}}{\sum_{y_i\neq G_m(x_i)} w_{m,i}}) \\<br>2\alpha_m&amp;&#x3D;ln(\frac{1-\sum_{y_i\neq G_m(x_i)} w_{m,i}}{\sum_{y_i\neq G_m(x_i)} w_{m,i}}) \\<br>\alpha_m&amp;&#x3D;\frac12 ln(\frac{1-e_m}{e_m}) \\<br>\end{aligned}<br>$$<br>综上我们就能够得到 $\alpha_m$ 的取值了。</p>
<p>因此我们知道了 $Adaboost$ 实际上就是以 $Loss &#x3D; \sum_{i&#x3D;1}^N exp(-y_if(x_i))$ 为目标函数的加法模型。</p>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>分类器</tag>
      </tags>
  </entry>
  <entry>
    <title>BP神经网络</title>
    <url>/2023/10/17/BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇博客中，我将会与大家分享最基本的<strong>BP神经网络</strong>的工作原理——主要包括<strong>网络的结构、参数的更新方法（反向传播）、网络优缺点</strong>等。BP神经网络是最基本的一种神经网络，难度小但我们能够见微知著得了解大型网络的训练过程。<span id="more"></span></p>
<h2 id="模型的架构"><a href="#模型的架构" class="headerlink" title="模型的架构"></a>模型的架构</h2><p><strong>反向传播模型</strong>也称B-P模型，<strong>是一种用于前向多层的反向传播学习算法。</strong></p>
<p>具体而言：</p>
<blockquote>
<ul>
<li>它可以对组成前向多层网络的各人工神经元之间的连接<strong>权值进行不断的修改</strong>，从而使该前向多层网络能够将输入它的信息变换成所期望的输出信息，因此是<strong>可学习的</strong>。</li>
<li>在修改各人工神经元的连接权值时，所依据的是该网络的<strong>实际输出与其期望的输出之差</strong>，将这一差值<strong>反向一层一层的向回传播</strong>，因此称作<strong>反向传播</strong>。</li>
</ul>
</blockquote>
<p>首先从整体对BP神经网络有一定的认识：</p>
<p><img src="/../pic/image-20231018004015157.png"></p>
<p>BP神经网络能够实现<strong>多输入——多输出</strong>的任务。</p>
<p>对于每一个节点来说，其是由若干前继节点<strong>加权求和$+$激活</strong>得到的。具体让我们来对<strong>一个神经元</strong>进行观察：</p>
<p><img src="/../pic/image-20231018005640938.png"></p>
<p>从这幅图中我们能够看出当且节点得到的输入为<br>$$<br>o &#x3D; f(\sum_j x_jw_j)<br>$$<br>当然，你也可以加入偏置项（bias），使得网络有更好的拟合效果：<br>$$<br>o &#x3D; f(\sum_j x_jw_j + b_j)<br>$$<br>公式中 $f$ 为激活函数，是一个<strong>非线性映射</strong>。常用的函数有 $Relu$ 及其变种，$Sigmoid$ 函数等等。在这里我们以 $Sigmoid$ 为例。<br>$$<br>Sigmoid:\quad \sigma(t) &#x3D; \frac{1}{1+e^{-t}}<br>$$<br><strong>考虑为什么一定要进行非线性映射？</strong></p>
<blockquote>
<p>倘若不进行非线性映射，则无论网络有多深，输出结果永远是输入的线性组合，但我们欲解决的问题是线性的情况少之又少。因此非线性映射（激活）能够让我们的网络有着更强的拟合能力。</p>
</blockquote>
<p>在经过若干层映射后，我们得到预测的输出 $\hat{y_1}, \hat{y_2}, \dots ,\hat{y_n}$，定义与真实值 $y_1,y_2,\dots,y_n$ 之间的误差函数：<br>$$<br>e&#x3D;E(\overrightarrow{w})&#x3D;\frac12 \sum_i(\hat{y_i}-y_i)^2<br>$$<br>而我们的目的就是调整 $\overrightarrow{w}&#x3D;(w1,w2,\dots,w_m)^T$ 的值<strong>使得误差 $e$ 尽可能小</strong>。</p>
<p>原理部分到此就结束了。实质上就是每一层数据经过加权并激活后传入到下一层。而具体如何更新参数，接下来我们将会讲到。</p>
<hr>
<h2 id="参数的更新"><a href="#参数的更新" class="headerlink" title="参数的更新"></a>参数的更新</h2><p>更新方法我们采用最朴素也最通用的——<strong>梯度下降法</strong>。</p>
<p>梯度下降法简单来说就是：对某一变量，其更新方向应该是沿着误差<strong>梯度方向的反方向</strong>——也就是<strong>梯度下降</strong>方向去更新。这样能够减小我们的误差值。而梯度方向我们可以用<strong>偏导</strong>求出。</p>
<p>让我们来看一个很简单的例子：</p>
<p><img src="/../pic/image-20231018012735470.png"></p>
<p>列出各个节点的关系式：<br>$$<br>\begin{array}{ll}<br>O_1&#x3D;x_1&amp;O_2&#x3D;x_2<br>\\ I_3&#x3D;W_{13}O_1+W_{23}O_2&amp;O_3&#x3D;f(I_3)<br>\\ I_4&#x3D;W_{34}O_3&amp;O_4&#x3D;f(I_4)<br>\\ I_5&#x3D;W_{35}O_3&amp;O_5&#x3D;f(I_5)<br>\\ y_1&#x3D;O_4&amp;y_2&#x3D;O_5<br>\end{array}<br>$$<br>定义误差函数 $e$ ：<br>$$<br>e &#x3D; \frac12 [(\hat{y_1} - y_1)^2 + (\hat{y_2} - y_2)^2]<br>$$</p>
<p>求偏导：<br>$$<br>\begin{gathered}<br>\frac{\partial e}{\partial W_{13}}&#x3D;\frac{\partial e}{\partial I_3}\cdot\frac{\partial I_3}{\partial W_{13}}&#x3D;\frac{\partial e}{\partial I_3}O_1&#x3D;\delta_3 x_1<br>\\ \frac{\partial e}{\partial W_{23}}&#x3D;\frac{\partial e}{\partial I_3}\cdot\frac{\partial I_3}{\partial W_{23}}&#x3D;\frac{\partial e}{\partial I_3}O_2&#x3D;\delta_3 x_2<br>\\ \frac{\partial e}{\partial W_{34}}&#x3D;\frac{\partial e}{\partial I_4}\cdot\frac{\partial I_4}{\partial W_{34}}&#x3D;\frac{\partial e}{\partial I_4}O_3 &#x3D;\delta_4 O_3<br>\\ \frac{\partial e}{\partial W_{35}}&#x3D;\frac{\partial e}{\partial I_5}\cdot\frac{\partial I_5}{\partial W_{55}}&#x3D;\frac{\partial e}{\partial I_5}O_3 &#x3D;\delta_5 O_3<br>\end{gathered}<br>$$<br>所以我们接下来的任务就是求 $\delta_3, \delta_4,\delta_5$<br>$$<br>\begin{gathered}<br>\delta_4&#x3D;\frac{\partial e}{\partial I_4}&#x3D;(\hat{y_1}-y_1)f’(I_4)<br>\\ \delta_5&#x3D;\frac{\partial e}{\partial I_5}&#x3D;(\hat{y_2}-y_2)f’(I_5)<br>\\ \delta_3&#x3D;\frac{\partial e}{\partial I_3}&#x3D;(\delta_4W_{34}+\delta_5 W_{35})f’(I_3)<br>\end{gathered}<br>$$<br><strong>注意激活函数也要求导！</strong></p>
<p>观察结果，能够发现 $\delta_3$ 的值依赖于 $\delta_4,\delta_5$——当且节点计算要依赖于后一层节点的计算——这也就是反向传播的很好表现。 </p>
<p>接下来通过设置学习率 $\alpha$，对参数进行更新即可：<br>$$<br>W_{k}^{(t+1)} &#x3D; W_{k}^{(t)} - \alpha \frac{\partial e}{\partial I_k}<br>$$<br>即沿着梯度下降的方向走一段距离，使得误差减小。我们完成了对参数的一次更新。接下来不断给出新的一组输入与输出，再更新参数，直至 $e &lt; \epsilon$ 停止。</p>
<hr>
<h2 id="前馈网络的表征能力"><a href="#前馈网络的表征能力" class="headerlink" title="前馈网络的表征能力"></a>前馈网络的表征能力</h2><ul>
<li><p><strong>布尔函数</strong>：任何布尔函数可以用两层网络准确表示。<strong>隐层单元数随输入数增加呈指数增长。</strong></p>
</li>
<li><p><strong>连续函数</strong>：每个有界连续函数可以用两层网络以任意小的误差逼近。<strong>隐层使用Sigmoid函数</strong>。</p>
</li>
<li><p><strong>任意函数</strong>：任意函数可以用三层网络以任意精度逼近。输出层线性单元，<strong>隐层Sigmoid单元</strong>。</p>
</li>
</ul>
<hr>
<h2 id="BP网络的优缺点"><a href="#BP网络的优缺点" class="headerlink" title="BP网络的优缺点"></a>BP网络的优缺点</h2><p><strong>优点：</strong></p>
<blockquote>
<ul>
<li><p><strong>理论基础牢固，推导过程严谨，物理概念清晰，通用性好</strong>等。</p>
</li>
<li><p>所以，它是目前用来训练前向多层网络较好的算法。</p>
</li>
</ul>
</blockquote>
<p><strong>缺点：</strong> </p>
<blockquote>
<ul>
<li><p>该学习算法的<strong>收敛速度慢</strong></p>
</li>
<li><p>网络中<strong>隐节点个数</strong>的选取尚<strong>无理论上的指导</strong></p>
</li>
<li><p>从数学角度看，B-P算法是一种梯度最速下降法，这就可能<strong>出现局部极小</strong>的问题。当出现局部极小时，从表面上看，误差符合要求，但这时所得到的解并不一定是问题的真正解。</p>
</li>
</ul>
</blockquote>
<p>再知道原理后，大家已经基本具备了从底层构建BP神经网络的所有知识。如果你进一步学习了<strong>梯度下降算法</strong>，那么你完全有能力手搓一个神经网络。Why not have a try?</p>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Fisher线性判别推导</title>
    <url>/2023/10/12/Fisher%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E6%8E%A8%E5%AF%BC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇文章中，我将主要以三种方式对$Fisher$判别的结果与<strong>最优解以及对应取值</strong>进行详细的推导。需要一定的<strong>多元函数微分</strong>、<strong>线性代数基础</strong>或<strong>凸优化基础</strong>。我将以不同知识背景对原问题进行解释与推导，得出正确结果。</p>
<h4 id="问题重述"><a href="#问题重述" class="headerlink" title="问题重述"></a>问题重述</h4><p>我们的优化目标函数为：<br>$$<br>\max  J(w) &#x3D; \frac{w^TS_bw}{w^TS_ww}<br>$$</p>
<span id="more"></span>

<p>其中 $S_b$ 描述了类间关系，$S_w$ 描述的是类内关系。我们希望让<strong>类间间距尽可能远</strong>，<strong>类内关系尽可能紧密</strong>，因此我们希望 $w^TS_bw$ 尽可能大，$w^TS_ww$ 尽可能小。因此最终的优化函数按上图所示。</p>
<h4 id="1-拉格朗日乘子法"><a href="#1-拉格朗日乘子法" class="headerlink" title="1. 拉格朗日乘子法"></a>1. 拉格朗日乘子法</h4><p>网上大部分方式都是这种证明方法，在这里做出解释并<font color='red'>提出疑问</font>。</p>
<p>我们设 $w^TS_w{w} &#x3D; c$，则原问题变成了：<br>$$<br>\max \quad J(w) &#x3D; w^TS_bw, \quad s.t: w^TS_ww &#x3D; c<br>$$<br>运用拉格朗日乘子法：<br>$$<br>L(w, \lambda) &#x3D; w^TS_bw - \lambda (w^TS_ww - c)<br>$$<br>求极值偏导为0：<br>$$<br>\frac{\partial L(w,\lambda)}{\partial w}&#x3D;2S_bw-2\lambda S_ww&#x3D;0<br>$$<br>则：<br>$$<br>S_b w &#x3D; \lambda S_w w\to (S_w^{-1}S_b)w&#x3D;\lambda w<br>$$<br>从而：<br>$$<br>\lambda w&#x3D;S_w^{-1}S_b w&#x3D;S_w^{-1}(m_1-m_2)(m_1-m_2)^Tw&#x3D;S_w^{-1}(m_1-m_2)R<br>$$<br>所以当取到最优值时：<br>$$<br>{w}^*&#x3D;\frac R\lambda S_w^{-1}(m_1-m_2)<br>$$<br>$w$ 的方向与 $S_w^{-1}(m_1-m_2)$ 是一致的。</p>
<p>但我也有<strong>部分疑惑</strong>：</p>
<blockquote>
<ol>
<li>$w^TS_ww &#x3D; c$ 前提的设置是否有严谨的数学依据，能够<strong>保证最后得到的是最优解</strong>。</li>
<li>$(S_w^{-1}S_b)w&#x3D;\lambda w$ 只能告诉我们 $w$ 是一个特征向量。但为什么求解后的 $w$ <strong>是唯一的</strong>？根据这个式子得出的 $w$ 应该是<strong>任意特征向量都成立</strong>，但事实<strong>只有一个是解</strong>。</li>
</ol>
</blockquote>
<hr>
<h4 id="2-直接求导法"><a href="#2-直接求导法" class="headerlink" title="2. 直接求导法"></a>2. 直接求导法</h4><p>事实上对于求极值问题，我们第一想法应该就是<strong>求导然后求极值</strong>。这个方法便按照这个思路直接进行求解。<br>$$<br>\frac{\partial J}{\partial w} &#x3D; \frac{S_bw * (w^TS_ww) - (w^TS_bw) * S_ww}{(w^TS_ww)^2}&#x3D;0<br>$$<br>我们设 $w^TS_bw &#x3D; R_1, w^TS_ww&#x3D;R_2$ ，其中 $R_1, R_2$ 为<strong>实数</strong>。则当取到极值的时候：<br>$$<br>S_bw*R_2 &#x3D; R_1 * S_ww<br>$$</p>
<p>$$<br>\frac{R_1}{R_2}w&#x3D;(S_w^{-1}S_b)w<br>$$</p>
<p>我们注意到$J &#x3D; R_1 &#x2F; R_2$<br>$$<br>(S_w^{-1}S_b)w&#x3D;J(w)*w<br>$$<br>通过线性代数的知识，我们可以得到：</p>
<blockquote>
<ol>
<li><strong>$J$ 应该是 $S_w^{-1}S_b$ 的一个特征值。</strong></li>
<li><strong>此时 $w$ 应该是对应特征值的特征向量。</strong></li>
</ol>
</blockquote>
<p>因为我们的目标是：<br>$$<br>\max J(w)<br>$$<br>因此我们不难得出：<br>$$<br>\max \quad J(w) &#x3D; \max{\lambda_1, \lambda_2, \dots,\lambda_k}<br>$$</p>
<p>$$<br>w &#x3D; v_{argmax{\lambda_1, \lambda_2, \dots,\lambda_k}}<br>$$</p>
<p>所以我们得出结论：</p>
<blockquote>
<ol>
<li><strong>目标函数 $\max J$ 是 $S_w^{-1}S_b$ 的最大特征值。</strong></li>
<li><strong>取最优值时 $w$ 应该是对应最大特征值的特征向量。</strong></li>
</ol>
</blockquote>
<p> $w$ 的方向可以按照第一种方法进行求解。直接求导法很好地解答了 <strong>为什么结果 $w$ 的方向一定是唯一的</strong>，因为——<strong>最优结果就是最大特征值</strong>。</p>
<hr>
<h4 id="3-从-w-TSw-含义入手验证上述结果"><a href="#3-从-w-TSw-含义入手验证上述结果" class="headerlink" title="3. 从$w^TSw$含义入手验证上述结果"></a>3. 从$w^TSw$含义入手验证上述结果</h4><p>让我们首先来看下 $w^TSw$ 的性质（回顾线性代数相关知识）：<br>$$<br>w^TSw &#x3D; w^T(Sw) &#x3D; a \in R<br>$$<br>所以我们不妨设：<br>$$<br>w^TSw &#x3D; w^T(Sw) &#x3D; w^T \mu w &#x3D; \mu w^Tw&#x3D;\mu k, \quad u \in R,v \in R<br>$$<br>所以 $w^TSw$ 实际上就是对 $k &#x3D; ||w||_2^2&#x3D;w^Tw$ 的一种缩放。其中 <strong>$\mu$ 为 $S$ 一特征值</strong> （$\mu &#x3D; \frac{w^TSw}{w^Tw}$）。</p>
<p>接下来让我们回到原问题，其可以转化为：<br>$$<br>\max J &#x3D; \frac{w^TS_bw}{w^TS_ww} &#x3D; \frac{\mu_b k}{\mu_w k} &#x3D; \frac{\mu_b}{\mu_w}<br>$$<br>即目标函数转化为两<strong>矩阵 $S_b, S_w$ 特征值比值的最大值</strong>。</p>
<p>在方法2中，我们得到的结果是 $S_w^{-1}S_b$ 的最大特征值。而：<br>$$<br>\max \lambda &#x3D; \max (\lambda_w^{-1} \lambda_b) &#x3D; \max \frac{\lambda_b}{\lambda_w} &#x3D; \frac{\mu_b}{\mu_w}<br>$$<br>因此我们进一步验证了方法2的结果是正确的——<strong>答案是 $S_w^{-1}S_b$ 的最大特征值</strong>。</p>
<hr>
<h4 id="4-抛砖引玉：对偶法"><a href="#4-抛砖引玉：对偶法" class="headerlink" title="4. 抛砖引玉：对偶法"></a>4. 抛砖引玉：对偶法</h4><p>首先给出参考连接：<a href="https://zhuanlan.zhihu.com/p/50823110">非线性规划：拉格朗日对偶 - 知乎 (zhihu.com)</a>。鸣谢 $zdc$ 的帮助。</p>
<p>首先介绍拉格朗日对偶。设原问题为：</p>
<p>$$<br>(L)\min_x \quad f_0(x)<br>$$</p>
<p>$$<br>s.t.\quad f_i(x)\leq0,i&#x3D;1,2,\ldots,m;\quad h_j(x)&#x3D;0,j&#x3D;1,2,\ldots,p<br>$$</p>
<p>从而构造拉格朗日函数：<br>$$<br>L(x,\lambda,\nu)&#x3D;f_0(x)+\sum_{i&#x3D;1}^m\lambda_if_i(x)+\sum_{i&#x3D;1}^p\nu_ih_i(x),<br>$$<br>其对偶形式（$inf$ 符号表示取下确界。）：<br>$$<br>\max g(\lambda,\nu)&#x3D;\inf_{x}L(x,\lambda,\nu)<br>\ s.t:\lambda \geq 0<br>$$<br>我们的为似乎也可以转化成对偶再求解。还要验证原问题与对偶问题的最优解是否相同。目前我还没有完整的思路，在这里给大家<strong>抛砖引玉</strong>吧。</p>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>分类器</tag>
        <tag>Fisher判别</tag>
      </tags>
  </entry>
  <entry>
    <title>薛之谦吉他谱</title>
    <url>/2023/08/28/%E8%96%9B%E4%B9%8B%E8%B0%A6%E5%90%89%E4%BB%96%E8%B0%B1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这篇博客中我将会分享<strong>薛之谦</strong>曲子的吉他谱，均是我认为<strong>还原度</strong>不错且<strong>难度</strong>适合弹唱的<strong>免费</strong>曲谱。</p>
<p>我会分别给出<strong>歌名</strong>以及对应的<strong>链接</strong></p>
<p><strong>持续更新中！！！</strong><span id="more"></span></p>
<p><img src="https://ts1.cn.mm.bing.net/th/id/R-C.afd8f3d9eed25da15d5707987bd70b11?rik=XUe69pOOPEAaog&riu=http://pic1.k1u.com/k1u/mb/d/file/20211113/1636766386194231_836_10000.jpg&ehk=aEtP0bXQJEr2u3RdbLqxtwZu0IwwFIs1jq4164CxycU=&risl=&pid=ImgRaw&r=0"></p>
<ol>
<li>《那是你离开了北京的生活》：<a href="http://www.kouqinpu.cn/tanchang/2531.html">http://www.kouqinpu.cn/tanchang/2531.html</a></li>
<li>《这么久没见》：<a href="http://www.jitavip.com/jitapu/top-1690.html">http://www.jitavip.com/jitapu/top-1690.html</a></li>
<li>《刚刚好》：<a href="http://www.kouqinpu.cn/tanchang/1271.html">http://www.kouqinpu.cn/tanchang/1271.html</a></li>
<li>《动物世界》：<a href="http://www.kouqinpu.cn/tanchang/7374.html">http://www.kouqinpu.cn/tanchang/7374.html</a></li>
<li>《绅士》：<a href="http://www.haijt.com/pu/look/6907?form=index">http://www.haijt.com/pu/look/6907?form=index</a></li>
<li>《认真的雪》：<a href="http://www.kouqinpu.cn/tanchang/1677.html">http://www.kouqinpu.cn/tanchang/1677.html</a></li>
<li>《哑巴》：<a href="https://www.kanpula.com/jitapu/379995.html">https://www.kanpula.com/jitapu/379995.html</a></li>
<li>《彩券》：<a href="https://www.jitapai.com/20205649.html">https://www.jitapai.com/20205649.html</a></li>
<li>《绅士》：<a href="https://www.jitapai.com/20201993.html">https://www.jitapai.com/20201993.html</a></li>
<li>《演员》：<a href="https://www.kanpula.com/jitapu/411444.html">https://www.kanpula.com/jitapu/411444.html</a></li>
<li>…</li>
</ol>
]]></content>
      <categories>
        <category>吉他</category>
        <category>弹唱</category>
      </categories>
      <tags>
        <tag>吉他</tag>
        <tag>弹唱</tag>
        <tag>薛之谦</tag>
      </tags>
  </entry>
  <entry>
    <title>多层感知机(MLP)的工程构建</title>
    <url>/2023/08/17/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA-MLP-%E7%9A%84%E5%B7%A5%E7%A8%8B%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>这个博客将以<strong>工程性的</strong>编排思路进行多层感知机的构建。</p>
<p>主要分为三个部分：<code>model.py</code>, <code>util.py</code>, <code>train.py</code>， 分别代表模型的构建、需要用到的函数以及训练主文件。<span id="more"></span></p>
<p>一下我们用神经网络学习“加法”这个运算法则为例进行构建：</p>
<p><strong>model.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义多层感知机模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(in_dim, <span class="number">16</span>)  <span class="comment"># 输入层到第一个隐藏层</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">16</span>, <span class="number">8</span>)  <span class="comment"># 第一个隐藏层到第二个隐藏层</span></span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">8</span>, out_dim)  <span class="comment"># 第二个隐藏层到输出层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(self.fc1(x))</span><br><span class="line">        x = torch.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>util.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_data</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="comment"># 进行打乱处理</span></span><br><span class="line">    np.random.seed(<span class="number">0</span>)</span><br><span class="line">    np.random.shuffle(x)</span><br><span class="line">    np.random.seed(<span class="number">0</span>)</span><br><span class="line">    np.random.shuffle(y)</span><br><span class="line">    <span class="comment"># 开始数据分割</span></span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    lenth = <span class="built_in">len</span>(x)</span><br><span class="line">    <span class="built_in">print</span>(lenth)</span><br><span class="line">    data[<span class="string">&#x27;x_train&#x27;</span>] = x[:<span class="built_in">int</span>(lenth * <span class="number">0.7</span>), :]</span><br><span class="line">    data[<span class="string">&#x27;y_train&#x27;</span>] = y[:<span class="built_in">int</span>(lenth * <span class="number">0.7</span>)]</span><br><span class="line">    data[<span class="string">&#x27;x_val&#x27;</span>] = x[<span class="built_in">int</span>(lenth * <span class="number">0.7</span>):<span class="built_in">int</span>(lenth * <span class="number">0.8</span>), :]</span><br><span class="line">    data[<span class="string">&#x27;y_val&#x27;</span>] = y[<span class="built_in">int</span>(lenth * <span class="number">0.7</span>):<span class="built_in">int</span>(lenth * <span class="number">0.8</span>)]</span><br><span class="line">    data[<span class="string">&#x27;x_test&#x27;</span>] = x[<span class="built_in">int</span>(lenth * <span class="number">0.8</span>):, :]</span><br><span class="line">    data[<span class="string">&#x27;y_test&#x27;</span>] = y[<span class="built_in">int</span>(lenth * <span class="number">0.8</span>):]</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>train.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> util</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">num_samples = <span class="number">10000</span></span><br><span class="line">x_data = np.random.randint(<span class="number">0</span>, <span class="number">1000</span>, (num_samples, <span class="number">2</span>))</span><br><span class="line">y_data = np.<span class="built_in">sum</span>(x_data, axis=-<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># y_data = np.expand_dims(y_data, axis=-1)  # 上面keepdims=True和这行二选一</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">data = util.process_data(x_data, y_data)</span><br><span class="line">x_train = torch.tensor(data[<span class="string">&#x27;x_train&#x27;</span>], dtype=torch.float32)</span><br><span class="line">y_train = torch.tensor(data[<span class="string">&#x27;y_train&#x27;</span>], dtype=torch.float32)</span><br><span class="line">x_val = torch.tensor(data[<span class="string">&#x27;x_val&#x27;</span>], dtype=torch.float32)</span><br><span class="line">y_val = torch.tensor(data[<span class="string">&#x27;y_val&#x27;</span>], dtype=torch.float32)</span><br><span class="line">x_test = torch.tensor(data[<span class="string">&#x27;x_test&#x27;</span>], dtype=torch.float32)</span><br><span class="line">y_test = torch.tensor(data[<span class="string">&#x27;y_test&#x27;</span>], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">net = MLP(in_dim=<span class="number">2</span>, out_dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置一些参数</span></span><br><span class="line">max_epochs = <span class="number">5000</span></span><br><span class="line">learn_rate = <span class="number">0.01</span></span><br><span class="line">criterion = nn.MSELoss()  <span class="comment"># sum((yi-y)^2) / n</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=learn_rate)</span><br><span class="line">loss_all = []</span><br><span class="line">val_acc = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epochs):</span><br><span class="line">    net.train()</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    outputs = net(x_train)</span><br><span class="line">    loss = criterion(outputs, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播和优化</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        loss_all.append(loss.item())</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="comment"># val集进行评估</span></span><br><span class="line">        outputs = net(x_val)</span><br><span class="line">        res = (torch.<span class="built_in">round</span>(outputs) == y_val)</span><br><span class="line">        acc = torch.<span class="built_in">sum</span>(res) / y_val.shape[<span class="number">0</span>]</span><br><span class="line">        val_acc.append(acc)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;max_epochs&#125;</span>], Loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>, val_acc = <span class="subst">&#123;acc * <span class="number">100</span> :<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">torch.save(net.state_dict(), <span class="string">f&#x27;model_save/finish_<span class="subst">&#123;loss_all[-<span class="number">1</span>]:<span class="number">.2</span>f&#125;</span>.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取模型</span></span><br><span class="line"><span class="comment"># net = MLP(2, 1)</span></span><br><span class="line"><span class="comment"># net.load_state_dict(torch.load(&#x27;model_save/finish_0.00.pth&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">net.<span class="built_in">eval</span>()</span><br><span class="line">outputs = net(x_test)</span><br><span class="line">res = (torch.<span class="built_in">round</span>(outputs) == y_test)</span><br><span class="line">acc = torch.<span class="built_in">sum</span>(res) / y_test.shape[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;test_acc = <span class="subst">&#123;acc * <span class="number">100</span> :<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">x = np.arange(<span class="built_in">len</span>(loss_all))</span><br><span class="line">fig1 = plt.plot(x, np.array(loss_all), linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">fig2 = plt.plot(x, np.array(val_acc), linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>关于最后的可视化大家可以去看我绘图的博客进行学习。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>多层感知机</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>MLP</tag>
      </tags>
  </entry>
  <entry>
    <title>绘图3(饼图,桑基图,三维图像)</title>
    <url>/2023/07/29/%E7%BB%98%E5%9B%BE3-%E9%A5%BC%E5%9B%BE-%E6%A1%91%E5%9F%BA%E5%9B%BE-%E4%B8%89%E7%BB%B4%E5%9B%BE%E5%83%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h3><span id="more"></span>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制饼图的代码。</span></span><br><span class="line"><span class="string">1.显示比例关系：饼图能够直观地显示数据各部分与整体的比例关系，帮助人们快速了解数据的分布情况。</span></span><br><span class="line"><span class="string">2.突出占比较大部分：饼图的饼片大小与所占比例成正比，使得占比较大的部分更加突出，便于观察主要数据。</span></span><br><span class="line"><span class="string">3.相对数量比较：饼图适用于展示相对数量的比较，特别是对于几个类别之间的比例关系。</span></span><br><span class="line"><span class="string">4.简单易懂：饼图是一种简单易懂的图表类型，不需要复杂的数学知识就可以理解数据的占比情况。</span></span><br><span class="line"><span class="string">5.适用于少量分类：饼图适用于较少的分类，当分类较多时，饼图的可读性和解析性可能会下降。</span></span><br><span class="line"><span class="string">6.可以显示百分比：饼图可以自动计算并显示每个类别的百分比，进一步增强了数据的可读性。</span></span><br><span class="line"><span class="string">7.适用于非连续数据：饼图适用于离散的、非连续的数据，如分类数据、百分比等。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">labels1 = [<span class="string">&#x27;Group 1&#x27;</span>, <span class="string">&#x27;Group 2&#x27;</span>, <span class="string">&#x27;Group 3&#x27;</span>]</span><br><span class="line">labels2 = [<span class="string">&#x27;Group 4&#x27;</span>, <span class="string">&#x27;Group 5&#x27;</span>, <span class="string">&#x27;Group 6&#x27;</span>]</span><br><span class="line">sizes1 = [<span class="number">30</span>, <span class="number">20</span>, <span class="number">50</span>]</span><br><span class="line">sizes2 = [<span class="number">25</span>, <span class="number">35</span>, <span class="number">30</span>]  <span class="comment"># 这里存放数据，并不是比例，因此求和不一定是100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置颜色列表</span></span><br><span class="line">colors1 = [<span class="string">&#x27;tab:blue&#x27;</span>, <span class="string">&#x27;tab:orange&#x27;</span>, <span class="string">&#x27;tab:green&#x27;</span>]</span><br><span class="line">colors2 = [<span class="string">&#x27;tab:red&#x27;</span>, <span class="string">&#x27;tab:purple&#x27;</span>, <span class="string">&#x27;tab:brown&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制饼图，并设置样式和颜色</span></span><br><span class="line">wedges1, texts1, autotexts1 = ax.pie(sizes1, pctdistance=<span class="number">0.8</span>, labels=labels1, colors=colors1, autopct=<span class="string">&#x27;%1.2f%%&#x27;</span>,</span><br><span class="line">                                     startangle=<span class="number">90</span>, wedgeprops=<span class="built_in">dict</span>(edgecolor=<span class="string">&#x27;w&#x27;</span>))  <span class="comment"># pctdistance=0.8调整文字位置</span></span><br><span class="line">wedges2, texts2, autotexts2 = ax.pie(sizes2, colors=colors2, radius=<span class="number">0.5</span>, autopct=<span class="string">&#x27;%1.1f%%&#x27;</span>, startangle=<span class="number">90</span>,</span><br><span class="line">                                     wedgeprops=<span class="built_in">dict</span>(edgecolor=<span class="string">&#x27;w&#x27;</span>))  <span class="comment"># radius=0.5调整半径大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置文本标签字体大小和颜色</span></span><br><span class="line"><span class="keyword">for</span> autotext <span class="keyword">in</span> autotexts1 + autotexts2:</span><br><span class="line">    autotext.set_fontsize(<span class="number">15</span>)</span><br><span class="line">    <span class="comment"># autotext.set_color(&#x27;white&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图例</span></span><br><span class="line">ax.legend(wedges1 + wedges2, labels1 + labels2, loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;三组数据的饼图&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="桑基图"><a href="#桑基图" class="headerlink" title="桑基图"></a>桑基图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制桑基图的代码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> plotly.graph_objects <span class="keyword">as</span> go</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入数据</span></span><br><span class="line">label = [<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;D&quot;</span>, <span class="string">&quot;E&quot;</span>]</span><br><span class="line">source = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>]  <span class="comment"># 前一列的索引</span></span><br><span class="line">target = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>]  <span class="comment"># 后一列的索引</span></span><br><span class="line">value = [<span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>]  <span class="comment"># 对应的流量值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建桑基图对象</span></span><br><span class="line">fig = go.Figure(data=[go.Sankey(</span><br><span class="line">    node=<span class="built_in">dict</span>(</span><br><span class="line">        pad=<span class="number">15</span>,</span><br><span class="line">        thickness=<span class="number">20</span>,</span><br><span class="line">        line=<span class="built_in">dict</span>(color=<span class="string">&quot;black&quot;</span>, width=<span class="number">0.5</span>),</span><br><span class="line">        label=label,</span><br><span class="line">        <span class="comment"># color=&quot;blue&quot;  # 设置节点颜色</span></span><br><span class="line">    ),</span><br><span class="line">    link=<span class="built_in">dict</span>(</span><br><span class="line">        source=source,</span><br><span class="line">        target=target,</span><br><span class="line">        value=value,</span><br><span class="line">        <span class="comment"># color=&quot;rgba(255, 0, 0, 0.5)&quot;,  # 设置链接颜色和透明度</span></span><br><span class="line">    )</span><br><span class="line">)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图的标题和大小</span></span><br><span class="line">fig.update_layout(title_text=<span class="string">&quot;桑基图&quot;</span>, title_x=<span class="number">0.5</span>, title_font_size=<span class="number">24</span>)</span><br><span class="line">fig.update_layout(width=<span class="number">800</span>, height=<span class="number">600</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏坐标轴</span></span><br><span class="line">fig.update_xaxes(showline=<span class="literal">False</span>, showgrid=<span class="literal">False</span>, zeroline=<span class="literal">False</span>, showticklabels=<span class="literal">False</span>)</span><br><span class="line">fig.update_yaxes(showline=<span class="literal">False</span>, showgrid=<span class="literal">False</span>, zeroline=<span class="literal">False</span>, showticklabels=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="3D函数图像"><a href="#3D函数图像" class="headerlink" title="3D函数图像"></a>3D函数图像</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">3D函数图像绘制代码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sin(np.sqrt(x**<span class="number">2</span> + y**<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成网格点</span></span><br><span class="line">x = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">y = np.linspace(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">100</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line"><span class="comment"># print(X)</span></span><br><span class="line">Z = f(X, Y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建3D图形对象</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制立体函数图像</span></span><br><span class="line">surf = ax.plot_surface(X, Y, Z, cmap=<span class="string">&#x27;viridis&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图的标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;3D立体函数图像&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签</span></span><br><span class="line">ax.set_xticks(np.arange(-<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>))</span><br><span class="line">ax.set_yticks(np.arange(-<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>))</span><br><span class="line">ax.set_zticks(np.arange(-<span class="number">1</span>, <span class="number">1.5</span>, <span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置轴范围</span></span><br><span class="line">ax.set_xlim(-<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">ax.set_ylim(-<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">ax.set_zlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加颜色条</span></span><br><span class="line">fig.colorbar(surf, shrink=<span class="number">0.5</span>, aspect=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 旋转视角，调整角度</span></span><br><span class="line">ax.view_init(elev=<span class="number">30</span>, azim=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏边框</span></span><br><span class="line">ax.xaxis.pane.fill = <span class="literal">False</span></span><br><span class="line">ax.yaxis.pane.fill = <span class="literal">False</span></span><br><span class="line">ax.zaxis.pane.fill = <span class="literal">False</span></span><br><span class="line">ax.xaxis.pane.set_edgecolor(<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">ax.yaxis.pane.set_edgecolor(<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">ax.zaxis.pane.set_edgecolor(<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">ax.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="3D散点图"><a href="#3D散点图" class="headerlink" title="3D散点图"></a>3D散点图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">3D散点图像绘制代码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">cluster1 = np.random.randn(<span class="number">100</span>, <span class="number">3</span>) + [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">cluster2 = np.random.randn(<span class="number">100</span>, <span class="number">3</span>) + [-<span class="number">2</span>, -<span class="number">2</span>, -<span class="number">2</span>]</span><br><span class="line">cluster3 = np.random.randn(<span class="number">100</span>, <span class="number">3</span>) + [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建3D图形对象</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制三维数据点</span></span><br><span class="line">ax.scatter(cluster1[:, <span class="number">0</span>], cluster1[:, <span class="number">1</span>], cluster1[:, <span class="number">2</span>], color=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;Cluster 1&#x27;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">ax.scatter(cluster2[:, <span class="number">0</span>], cluster2[:, <span class="number">1</span>], cluster2[:, <span class="number">2</span>], c=<span class="string">&#x27;g&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, label=<span class="string">&#x27;Cluster 2&#x27;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">ax.scatter(cluster3[:, <span class="number">0</span>], cluster3[:, <span class="number">1</span>], cluster3[:, <span class="number">2</span>], c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;Cluster 3&#x27;</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例，设置位置为右上角</span></span><br><span class="line">ax.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图的标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;三维三点聚类图像&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置坐标轴刻度范围</span></span><br><span class="line">ax.set_xlim(-<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">ax.set_ylim(-<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">ax.set_zlim(-<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置坐标轴刻度间隔</span></span><br><span class="line"><span class="comment"># ax.set_xticks(np.arange(-6, 7, 2))</span></span><br><span class="line"><span class="comment"># ax.set_yticks(np.arange(-6, 7, 2))</span></span><br><span class="line"><span class="comment"># ax.set_zticks(np.arange(-6, 7, 2))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏边框和网格</span></span><br><span class="line"><span class="comment"># ax.xaxis.pane.fill = False</span></span><br><span class="line"><span class="comment"># ax.yaxis.pane.fill = False</span></span><br><span class="line"><span class="comment"># ax.zaxis.pane.fill = False</span></span><br><span class="line"><span class="comment"># ax.xaxis.pane.set_edgecolor(&#x27;black&#x27;)</span></span><br><span class="line"><span class="comment"># ax.yaxis.pane.set_edgecolor(&#x27;black&#x27;)</span></span><br><span class="line"><span class="comment"># ax.zaxis.pane.set_edgecolor(&#x27;black&#x27;)</span></span><br><span class="line"><span class="comment"># ax.grid(True)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整视角</span></span><br><span class="line">ax.view_init(elev=<span class="number">20</span>, azim=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="3D柱状体"><a href="#3D柱状体" class="headerlink" title="3D柱状体"></a>3D柱状体</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">3D柱状图绘制代码</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">y = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">z = [</span><br><span class="line">    [<span class="number">5</span>, <span class="number">4</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">7</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">    [<span class="number">7</span>, <span class="number">5</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">6</span>, <span class="number">7</span>, <span class="number">3</span>],</span><br><span class="line">    [<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建3D图形对象</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制三维柱状图</span></span><br><span class="line">dx = dy = <span class="number">0.5</span>  <span class="comment"># 设置柱子的宽度</span></span><br><span class="line">dz = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z]  <span class="comment"># 设置柱子的高度</span></span><br><span class="line"></span><br><span class="line">color = [<span class="string">&#x27;tab:red&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;tab:green&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y)):</span><br><span class="line">        ax.bar3d(x[i], y[j], <span class="number">0</span>, dx, dy, dz[j], shade=<span class="literal">True</span>, color=color[i], edgecolor=<span class="string">&#x27;black&#x27;</span>,</span><br><span class="line">                 linewidth=<span class="number">1</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建虚拟的图例</span></span><br><span class="line">rect1 = plt.Rectangle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, fc=color[<span class="number">0</span>], edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">rect2 = plt.Rectangle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, fc=color[<span class="number">1</span>], edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">rect3 = plt.Rectangle((<span class="number">0</span>, <span class="number">0</span>), <span class="number">1</span>, <span class="number">1</span>, fc=color[<span class="number">2</span>], edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">ax.legend([rect1, rect2, rect3], [<span class="string">&#x27;Category 1&#x27;</span>, <span class="string">&#x27;Category 2&#x27;</span>, <span class="string">&#x27;Category 3&#x27;</span>], loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;Z轴&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图的标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;三维柱状图&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python绘图</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>画图</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>绘图2(热力图,箱线图,等高线图,雷达图,网络图)</title>
    <url>/2023/07/29/%E7%BB%98%E5%9B%BE2-%E7%83%AD%E5%8A%9B%E5%9B%BE-%E7%AE%B1%E7%BA%BF%E5%9B%BE-%E7%AD%89%E9%AB%98%E7%BA%BF%E5%9B%BE-%E9%9B%B7%E8%BE%BE%E5%9B%BE-%E7%BD%91%E7%BB%9C%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="热力图"><a href="#热力图" class="headerlink" title="热力图"></a>热力图</h3><span id="more"></span>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制热力图代码。</span></span><br><span class="line"><span class="string">常用于显示相关系数矩阵。</span></span><br><span class="line"><span class="string">1.突出关键信息：热力图通过颜色的变化来突出数据的特征和差异，帮助我们快速发现数据中的规律和趋势。</span></span><br><span class="line"><span class="string">2.可视化大规模数据：热力图适用于展示大规模数据矩阵，特别是在数据包含大量值时，热力图可以更好地展示数据的结构。</span></span><br><span class="line"><span class="string">3.探索数据关联性：热力图可以帮助我们发现数据之间的关联性和相关性，尤其在探索多变量数据时特别有用。</span></span><br><span class="line"><span class="string">4.色彩丰富：热力图的颜色映射可以选择多样，可以根据数据类型和需要选择合适的颜色映射，使得图像更美观和易读。</span></span><br><span class="line"><span class="string">5.一目了然：热力图通过色彩的变化和色块的大小，可以在一张图中展示大量数据，让人一目了然。</span></span><br><span class="line"><span class="string">6.强调差异：热力图的颜色变化可以有效地突出数据之间的差异和异常值，有助于快速定位问题。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据（10x10的二维矩阵）</span></span><br><span class="line">data = np.random.randint(<span class="number">1</span>, <span class="number">10</span>, size=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制热力图，并设置样式</span></span><br><span class="line">heatmap = ax.imshow(data, cmap=<span class="string">&#x27;hot&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>, aspect=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">cmap参数设置：</span></span><br><span class="line"><span class="string">&#x27;viridis&#x27;：从蓝色到黄色渐变，用于连续数据，特别适用于数据的渐变效果。</span></span><br><span class="line"><span class="string">&#x27;plasma&#x27;：从紫色到橙色渐变，用于连续数据，较viridis颜色更丰富。</span></span><br><span class="line"><span class="string">&#x27;inferno&#x27;：从黑色到黄色渐变，用于连续数据，较viridis颜色更加明亮。</span></span><br><span class="line"><span class="string">&#x27;magma&#x27;：从黑色到白色渐变，用于连续数据，较viridis颜色更适合打印。</span></span><br><span class="line"><span class="string">&#x27;cividis&#x27;：从蓝色到黄色渐变，用于连续数据，颜色较温和。</span></span><br><span class="line"><span class="string">&#x27;cool&#x27;：从青色到蓝色渐变，用于连续数据，适用于冷色调的数据。</span></span><br><span class="line"><span class="string">&#x27;hot&#x27;：从黑色到红色渐变，用于连续数据，适用于暖色调的数据。</span></span><br><span class="line"><span class="string">&#x27;coolwarm&#x27;：从蓝色到红色渐变，用于连续数据，冷暖色调交替。</span></span><br><span class="line"><span class="string">&#x27;rainbow&#x27;：七色彩虹渐变，用于连续数据，颜色多样。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 添加颜色条</span></span><br><span class="line">cbar = plt.colorbar(heatmap, fraction=<span class="number">0.046</span>, pad=<span class="number">0.04</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;热力图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置颜色条标签字体大小</span></span><br><span class="line">cbar.ax.tick_params(labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置横纵坐标标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="箱线图"><a href="#箱线图" class="headerlink" title="箱线图"></a>箱线图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制箱线图代码</span></span><br><span class="line"><span class="string">1.易读易懂：箱线图是一种直观且易懂的图表类型，无需复杂的数学知识即可解读数据的分布情况。</span></span><br><span class="line"><span class="string">2.高效展示信息：箱线图能够在一个图中展示出数据的多个统计特征，包括中位数、四分位数、最大值、最小值和离群值，简洁高效。</span></span><br><span class="line"><span class="string">3.检测异常值：箱线图可以帮助我们发现数据中的异常值，从而进行数据清洗或者更深入的分析。</span></span><br><span class="line"><span class="string">4.有效比较：箱线图可以同时展示多组数据的分布情况，有助于进行数据间的比较和对比。</span></span><br><span class="line"><span class="string">5.无偏性：箱线图对数据的排序和数量不敏感，其表现是无偏的，适用于多种类型的数据。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">data1 = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">data2 = np.random.normal(<span class="number">2</span>, <span class="number">1.5</span>, <span class="number">100</span>)</span><br><span class="line">data3 = np.random.normal(-<span class="number">2</span>, <span class="number">1.5</span>, <span class="number">100</span>)</span><br><span class="line">data4 = np.random.normal(<span class="number">3</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">data5 = np.random.normal(-<span class="number">1</span>, <span class="number">0.5</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制箱线图</span></span><br><span class="line">boxes = ax.boxplot([data1, data2, data3, data4, data5], labels=[<span class="string">&#x27;Group 1&#x27;</span>, <span class="string">&#x27;Group 2&#x27;</span>, <span class="string">&#x27;Group 3&#x27;</span>, <span class="string">&#x27;Group 4&#x27;</span>, <span class="string">&#x27;Group 5&#x27;</span>],</span><br><span class="line">                   sym=<span class="string">&#x27;o&#x27;</span>, vert=<span class="literal">True</span>, patch_artist=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置每组数据的颜色</span></span><br><span class="line">colors = [<span class="string">&#x27;tab:blue&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;tab:green&#x27;</span>, <span class="string">&#x27;tab:red&#x27;</span>, <span class="string">&#x27;tab:purple&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> box, color <span class="keyword">in</span> <span class="built_in">zip</span>(boxes[<span class="string">&#x27;boxes&#x27;</span>], colors):</span><br><span class="line">    box.<span class="built_in">set</span>(facecolor=color)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend(boxes[<span class="string">&#x27;boxes&#x27;</span>], [<span class="string">&#x27;Group 1&#x27;</span>, <span class="string">&#x27;Group 2&#x27;</span>, <span class="string">&#x27;Group 3&#x27;</span>, <span class="string">&#x27;Group 4&#x27;</span>, <span class="string">&#x27;Group 5&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;组别&#x27;</span>, fontsize=<span class="number">12</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;数值&#x27;</span>, fontsize=<span class="number">12</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;箱线图&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加网格线</span></span><br><span class="line">ax.grid(<span class="literal">True</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="等高线图"><a href="#等高线图" class="headerlink" title="等高线图"></a>等高线图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制等高线图的代码</span></span><br><span class="line"><span class="string">适用于地形、函数、场、势的绘制。</span></span><br><span class="line"><span class="string">1.表现数据等值线：等高线图通过等值线来展示数据的分布情况，帮助人们快速了解数据的变化趋势和模式。</span></span><br><span class="line"><span class="string">2.保留二维信息：等高线图是二维图形，能够清晰表达两个自变量之间的关系，适用于分析二维数据。</span></span><br><span class="line"><span class="string">3.显示数据变化：等高线图通过等值线的间距和形态变化，能够有效显示数据的变化趋势和梯度。</span></span><br><span class="line"><span class="string">4.强调变化梯度：等高线图通过等值线的密集程度和形态变化，突出数据变化的梯度，有助于识别变化的快慢和方向。</span></span><br><span class="line"><span class="string">5.检测异常值：等高线图可以帮助我们发现数据中的异常值，因为异常值通常在等值线中表现为不规则的形状。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据（二维数组）</span></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">y = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line">Z = X ** <span class="number">2</span> - Y ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制等高线图，并设置样式</span></span><br><span class="line">contour = ax.contour(X, Y, Z, levels=<span class="number">50</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, linewidths=<span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加颜色条</span></span><br><span class="line">cbar = plt.colorbar(contour, ax=ax)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;等高线图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置颜色条标签字体大小</span></span><br><span class="line">cbar.ax.tick_params(labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置线条样式为虚线</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> contour.collections:</span><br><span class="line">    line.set_linestyle(<span class="string">&#x27;dashed&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="雷达图"><a href="#雷达图" class="headerlink" title="雷达图"></a>雷达图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制雷达图的代码。</span></span><br><span class="line"><span class="string">可以用来对“属性”进行刻画</span></span><br><span class="line"><span class="string">1.多变量比较：雷达图在展示多个变量之间的关系和差异方面具有优势，可以直观地展示数据在不同维度上的表现。</span></span><br><span class="line"><span class="string">2.易于解读：雷达图是一种直观的图表类型，无需深入的数学知识即可理解数据的多维特征，使得数据分析和传达更容易。</span></span><br><span class="line"><span class="string">3.数据关联性：雷达图将多个变量的信息集中在一个图形中展示，有助于观察不同维度之间的关联性，帮助我们发现隐藏在数据背后的规律。</span></span><br><span class="line"><span class="string">4.强调相对比较：雷达图更注重相对的大小和差异，而非绝对数值，适用于比较多组数据在各个维度上的表现。</span></span><br><span class="line"><span class="string">5.高效传递信息：雷达图以图形化的方式呈现多维数据，使得大量信息能够被快速有效地传达给观众。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据：每个维度的数据值（三组数据）</span></span><br><span class="line">categories = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;E&#x27;</span>]  <span class="comment"># 维度名称</span></span><br><span class="line">values1 = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>]  <span class="comment"># 第一组数据值</span></span><br><span class="line">values2 = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">3</span>]  <span class="comment"># 第二组数据值</span></span><br><span class="line">values3 = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>]  <span class="comment"># 第三组数据值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将第一个维度值复制到最后，以形成闭合</span></span><br><span class="line">values1 += values1[:<span class="number">1</span>]</span><br><span class="line">values2 += values2[:<span class="number">1</span>]</span><br><span class="line">values3 += values3[:<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个维度对应的角度</span></span><br><span class="line">angles = np.linspace(<span class="number">0</span>, <span class="number">2</span>*np.pi, <span class="built_in">len</span>(categories), endpoint=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将角度与数据值对应起来</span></span><br><span class="line">angles = np.concatenate((angles, [angles[<span class="number">0</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图，使用极坐标</span></span><br><span class="line">fig, ax = plt.subplots(subplot_kw=&#123;<span class="string">&#x27;projection&#x27;</span>: <span class="string">&#x27;polar&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制三组雷达图，并设置样式</span></span><br><span class="line">ax.plot(angles, values1, linewidth=<span class="number">1.5</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;数据1&#x27;</span>)</span><br><span class="line">ax.fill(angles, values1, alpha=<span class="number">0.3</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.plot(angles, values2, linewidth=<span class="number">1.5</span>, linestyle=<span class="string">&#x27;-.&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;数据2&#x27;</span>)</span><br><span class="line">ax.fill(angles, values2, alpha=<span class="number">0.3</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.plot(angles, values3, linewidth=<span class="number">1.5</span>, linestyle=<span class="string">&#x27;solid&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;数据3&#x27;</span>)</span><br><span class="line">ax.fill(angles, values3, alpha=<span class="number">0.3</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置雷达图的标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;雷达图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置角度刻度，即设置维度的标签</span></span><br><span class="line">ax.set_xticks(angles[:-<span class="number">1</span>])</span><br><span class="line">ax.set_xticklabels(categories, fontsize=<span class="number">12</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;polar&#x27;</span>].set_color(<span class="string">&#x27;#b0b0b0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏雷达图的刻度线</span></span><br><span class="line"><span class="comment"># ax.xaxis.grid(False)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="网络图"><a href="#网络图" class="headerlink" title="网络图"></a>网络图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制网络图的代码。</span></span><br><span class="line"><span class="string">能够对图结构进行直观刻画，可用于路径规划等问题。</span></span><br><span class="line"><span class="string">同样树结构也能够用这个代码来画，因为树是特殊的有向无环图</span></span><br><span class="line"><span class="string">这个网站也可以：https://csacademy.com/app/graph_editor/</span></span><br><span class="line"><span class="string">1.多对多关系：网络图能够展示多个节点之间的多对多关系，适用于描述复杂的关联和连接。</span></span><br><span class="line"><span class="string">2.可视化复杂结构：网络图可以清晰地展示节点之间的连接和关系，便于理解和观察复杂结构。</span></span><br><span class="line"><span class="string">3.节点和边属性：网络图的节点和边可以附带属性信息，使得数据可以更加丰富，节点和边的样式和颜色可以代表不同的属性。</span></span><br><span class="line"><span class="string">4.异构性：网络图可以描述异构性的数据，即不同类型的节点和边可以同时存在，能够展示多种类型的关系。</span></span><br><span class="line"><span class="string">5.图算法应用：网络图的特点使得其在图算法（例如路径查找、社区发现等）方面具有广泛的应用。</span></span><br><span class="line"><span class="string">6.强调连接：网络图强调节点之间的连接关系，使得观察和分析节点的交互和连接变得更加直观。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个简单的网络图</span></span><br><span class="line">G = nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">3</span>), (<span class="number">3</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">5</span>), (<span class="number">5</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">6</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制网络图</span></span><br><span class="line">pos = nx.circular_layout(G)  <span class="comment"># 设置节点的位置</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整节点和边的样式</span></span><br><span class="line">nx.draw_networkx_nodes(G, pos, node_color=<span class="string">&#x27;skyblue&#x27;</span>, node_size=<span class="number">1000</span>, label=<span class="string">&#x27;节点&#x27;</span>)</span><br><span class="line">nx.draw_networkx_edges(G, pos, edge_color=<span class="string">&#x27;gray&#x27;</span>, width=<span class="number">2</span>)</span><br><span class="line">nx.draw_networkx_labels(G, pos, font_size=<span class="number">12</span>, font_weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图的标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;网络图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">plt.gca().set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 隐藏坐标轴</span></span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调整图例的位置</span></span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python绘图</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>画图</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>绘图1(折线图,柱状图,直方图,散点图,气泡图)</title>
    <url>/2023/07/29/%E7%BB%98%E5%9B%BE1-%E6%8A%98%E7%BA%BF%E5%9B%BE-%E6%9F%B1%E7%8A%B6%E5%9B%BE-%E7%9B%B4%E6%96%B9%E5%9B%BE-%E6%95%A3%E7%82%B9%E5%9B%BE-%E6%B0%94%E6%B3%A1%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h3><span id="more"></span>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制折线图的代码。</span></span><br><span class="line"><span class="string">常用于绘制数据走势。用途广泛。</span></span><br><span class="line"><span class="string">1.显示趋势和变化：折线图特别适合展示数据随时间或其他连续变量的趋势和变化。通过将数据点连接起来，折线图能够直观地显示出数据的走势和趋势，</span></span><br><span class="line"><span class="string">  帮助人们更好地理解数据的演变过程。</span></span><br><span class="line"><span class="string">2.强调数据关系：折线图可以同时展示多条折线，比较多组数据的变化情况。这样，我们可以很容易地发现数据之间的关联和差异。</span></span><br><span class="line"><span class="string">3.易于比较：通过将多个数据系列放在同一张图中，折线图提供了一个很好的比较方式。这样，我们可以很快地看出不同数据之间的差异，而不需要进行复杂的数据分析。</span></span><br><span class="line"><span class="string">4.可视化异常和变动：折线图对于数据的异常值和波动有很好的反应，让人们快速识别出数据的特殊点。</span></span><br><span class="line"><span class="string">5.显示周期性：如果数据具有明显的周期性变化，例如季节性或周期性，折线图能够清晰地表现这种特征。</span></span><br><span class="line"><span class="string">6.突出重点：折线图可以突出数据的特定部分或重点，帮助观众关注关键的数据变化。</span></span><br><span class="line"><span class="string">7.直观易懂：折线图简单直观，不需要高级的数据解读技巧。即使对于非专业人员，也可以很容易地理解数据的变化趋势。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"><span class="comment"># 数据示例，假设有五条折线，每条折线有5个数据点</span></span><br><span class="line">y1 = [<span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">2</span>]</span><br><span class="line">y2 = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">y3 = [<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>]</span><br><span class="line">y4 = [<span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">y5 = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y1))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置折线的线条样式、颜色和标签</span></span><br><span class="line">line_styles = [<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;:&#x27;</span>, <span class="string">&#x27;-.&#x27;</span>, <span class="string">&#x27;dashdot&#x27;</span>]</span><br><span class="line"><span class="comment"># 线条样式有&#x27;-&#x27;, &#x27;--&#x27;, &#x27;-.&#x27;, &#x27;:&#x27;, &#x27;None&#x27;, &#x27; &#x27;, &#x27;&#x27;, &#x27;solid&#x27;, &#x27;dashed&#x27;, &#x27;dashdot&#x27;, &#x27;dotted&#x27;</span></span><br><span class="line">line_colors = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;black&#x27;</span>]  <span class="comment"># 这是线条颜色，也可以用&#x27;#123456&#x27;来表示</span></span><br><span class="line">line_labels = [<span class="string">&#x27;Line 1&#x27;</span>, <span class="string">&#x27;Line 2&#x27;</span>, <span class="string">&#x27;Line 3&#x27;</span>, <span class="string">&#x27;Line 4&#x27;</span>, <span class="string">&#x27;Line 5&#x27;</span>]  <span class="comment"># 这是图例名称</span></span><br><span class="line">line_widths = [<span class="number">1.5</span>, <span class="number">2.0</span>, <span class="number">2.5</span>, <span class="number">1.0</span>, <span class="number">1.5</span>]  <span class="comment"># 调整线条粗细的参数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    ax.plot(x, <span class="built_in">globals</span>()[<span class="string">f&#x27;y<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&#x27;</span>], linestyle=line_styles[i], color=line_colors[i], label=line_labels[i], linewidth=line_widths[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加具体数值</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">    ax.annotate(<span class="string">f&#x27;<span class="subst">&#123;y1[i]&#125;</span>&#x27;</span>, (x[i], y1[i]), textcoords=<span class="string">&quot;offset points&quot;</span>, xytext=(<span class="number">0</span>, <span class="number">10</span>), ha=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;折线图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加网格线</span></span><br><span class="line">ax.grid(<span class="literal">True</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># 绘制置信区间</span></span><br><span class="line"><span class="string">import matplotlib.pyplot as plt</span></span><br><span class="line"><span class="string">import numpy as np</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 示例数据</span></span><br><span class="line"><span class="string">x = np.linspace(0, 10, 100)</span></span><br><span class="line"><span class="string">y = np.sin(x)</span></span><br><span class="line"><span class="string">confidence_interval = 0.2  # Example confidence interval value</span></span><br><span class="line"><span class="string">upper_bound = y + confidence_interval</span></span><br><span class="line"><span class="string">lower_bound = y - confidence_interval</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 创建一个Figure对象和一个子图</span></span><br><span class="line"><span class="string">plt.figure(figsize=(10, 6))</span></span><br><span class="line"><span class="string">plt.xlabel(&#x27;X&#x27;)</span></span><br><span class="line"><span class="string">plt.ylabel(&#x27;Y&#x27;)</span></span><br><span class="line"><span class="string">plt.title(&#x27;Confidence Intervals&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 绘制线条</span></span><br><span class="line"><span class="string">plt.plot(x, y, label=&#x27;Data&#x27;, color=&#x27;blue&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 置信区间填颜色</span></span><br><span class="line"><span class="string">plt.fill_between(x, lower_bound, upper_bound, color=&#x27;lightblue&#x27;, alpha=0.5, label=&#x27;Confidence Interval&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 添加图例</span></span><br><span class="line"><span class="string">plt.legend()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 显示图形</span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="柱状图"><a href="#柱状图" class="headerlink" title="柱状图"></a>柱状图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制柱状图的代码。</span></span><br><span class="line"><span class="string">1.易于理解：柱状图是一种直观的图表类型，可以清晰地展示数据之间的差异和相对大小。每个柱子的高度表示数据的数量或值，使观众能够快速理解数据的特征。</span></span><br><span class="line"><span class="string">2.比较数据：柱状图特别适用于比较多组数据之间的差异。通过将不同类别的数据放置在同一张图表上，柱状图可以直观地呈现它们之间的关系，帮助观众发现数据的模式和趋势。</span></span><br><span class="line"><span class="string">3.可视化分布：柱状图可以用于展示数据的分布情况。例如，可以使用柱状图来显示数据的频率分布或类别分布。</span></span><br><span class="line"><span class="string">4.强调异常值：柱状图能够很容易地识别出数据的异常值。高于或低于其他柱子的柱状图很可能是异常值，使我们能够快速定位数据中的异常情况。</span></span><br><span class="line"><span class="string">5.可用于大数据集：柱状图适用于大量数据的可视化，特别是类别较多的情况。不同类别的柱状图可以并排显示，不会造成混乱。</span></span><br><span class="line"><span class="string">6.易于与其他图表结合：柱状图可以很容易地与其他图表结合使用，如折线图、堆积柱状图等。这样，可以更全面地展示数据的不同方面。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据示例，假设有五个数据的高度</span></span><br><span class="line">heights = [<span class="number">5</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(heights))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同柱子的填充样式和颜色</span></span><br><span class="line"><span class="comment"># patterns = [&#x27;/&#x27;, &#x27;x&#x27;, &#x27;+&#x27;, &#x27;-&#x27;, &#x27;o&#x27;]</span></span><br><span class="line">patterns = [<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>]</span><br><span class="line">colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line"><span class="comment"># 绘制柱状图</span></span><br><span class="line">width = <span class="number">0.5</span>  <span class="comment"># 柱状图宽度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(heights)):</span><br><span class="line">    bar = ax.bar(x[i], heights[i], width, color=colors[i], hatch=patterns[i], label=<span class="string">f&#x27;Bar <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&#x27;</span>)  <span class="comment"># 绘制</span></span><br><span class="line">    height = bar[<span class="number">0</span>].get_height()</span><br><span class="line">    ax.annotate(<span class="string">f&#x27;<span class="subst">&#123;height&#125;</span>&#x27;</span>, xy=(bar[<span class="number">0</span>].get_x() + bar[<span class="number">0</span>].get_width() / <span class="number">2</span>, height), xytext=(<span class="number">0</span>, <span class="number">3</span>),</span><br><span class="line">                textcoords=<span class="string">&quot;offset points&quot;</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>)  <span class="comment"># 在柱状图上添加对应数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend(fontsize=<span class="number">12</span>, loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置xy范围</span></span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;柱状图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签</span></span><br><span class="line">ax.set_xticks(x)</span><br><span class="line">ax.set_xticklabels([<span class="string">f&#x27;Bar <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(heights))], fontsize=<span class="number">12</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置网格线</span></span><br><span class="line">ax.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除图表边框</span></span><br><span class="line"><span class="keyword">for</span> spine <span class="keyword">in</span> ax.spines.values():</span><br><span class="line">    spine.set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="柱状图（多组）"><a href="#柱状图（多组）" class="headerlink" title="柱状图（多组）"></a>柱状图（多组）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制柱状图(多组)代码。</span></span><br><span class="line"><span class="string">在柱状图的基础上对每一组的若干指标进行整体绘制。</span></span><br><span class="line"><span class="string">1.利于反映整体信息</span></span><br><span class="line"><span class="string">2.兼具有柱状图的优势</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">groups = [<span class="string">&#x27;Group 1&#x27;</span>, <span class="string">&#x27;Group 2&#x27;</span>, <span class="string">&#x27;Group 3&#x27;</span>, <span class="string">&#x27;Group 4&#x27;</span>, <span class="string">&#x27;Group 5&#x27;</span>]</span><br><span class="line">indicators = [<span class="string">&#x27;Indicator 1&#x27;</span>, <span class="string">&#x27;Indicator 2&#x27;</span>, <span class="string">&#x27;Indicator 3&#x27;</span>]</span><br><span class="line">data = np.random.randint(<span class="number">1</span>, <span class="number">10</span>, size=(<span class="number">5</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置每个柱子的宽度</span></span><br><span class="line">width = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置颜色列表</span></span><br><span class="line">colors = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制柱状图</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(groups)):</span><br><span class="line">    x = (np.arange(<span class="built_in">len</span>(indicators)) - <span class="built_in">len</span>(indicators)//<span class="number">2</span>) * width + i</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(indicators)):</span><br><span class="line">        ax.bar(x[j], data[i][j], width, color=colors[j], label=indicators[j] <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;组&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;数值&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;柱状图(多组)&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签</span></span><br><span class="line">ax.set_xticks(np.arange(<span class="built_in">len</span>(groups)))</span><br><span class="line">ax.set_xticklabels(groups)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制直方图的代码。</span></span><br><span class="line"><span class="string">1.简单直观：直方图是一种简单直观的图表类型，不需要复杂的数学知识就能理解数据的分布情况。</span></span><br><span class="line"><span class="string">2.大数据适用：直方图适用于大量数据的可视化。对于大数据集，直方图可以帮助我们更好地理解数据的总体分布和趋势。</span></span><br><span class="line"><span class="string">3.强调整体特征：直方图可以清楚地展示数据的整体特征，帮助我们发现数据中的规律和趋势。</span></span><br><span class="line"><span class="string">4.无偏性：直方图不受数据的排序和个数的影响，对数据的表现是无偏的。</span></span><br><span class="line"><span class="string">5.直观比较：直方图可以用来比较不同数据集或不同组别之间的差异，通过颜色或图案样式的设置，直观地显示数据之间的比较结果。</span></span><br><span class="line"><span class="string">6.数据离散化：直方图将连续数据分组成离散区间，有助于对数据进行简化和归纳，更容易理解数据的结构。</span></span><br><span class="line"><span class="string">7.显示数据分布：直方图能够直观地展示数据在不同区间的分布情况，帮助我们了解数据的集中程度、分散程度和峰值等特征。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">data1 = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置直方图的边界和颜色</span></span><br><span class="line">bins = <span class="number">20</span></span><br><span class="line">colors = [<span class="string">&#x27;g&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制直方图</span></span><br><span class="line">ax.hist(data1, bins=bins, color=colors[<span class="number">0</span>],  hatch=<span class="string">&#x27;/&#x27;</span>, alpha=<span class="number">0.7</span>, label=<span class="string">&#x27;Group&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;数值&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;频数&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;直方图&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加网格线</span></span><br><span class="line"><span class="comment"># ax.grid(True, linestyle=&#x27;--&#x27;, alpha=0.7)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制散点图代码。</span></span><br><span class="line"><span class="string">经常用于对聚类结果的可视化。</span></span><br><span class="line"><span class="string">1.显示数据分布：散点图能够清晰地展示数据点在二维坐标系中的分布情况，帮助我们了解数据的密度和分布规律。</span></span><br><span class="line"><span class="string">2.可视化关系：散点图可以直观地显示两个变量之间的关系。通过观察散点图的分布模式，我们可以判断两个变量之间是否存在线性或非线性关系。</span></span><br><span class="line"><span class="string">3.发现异常值：散点图可以帮助我们快速识别数据中的异常值。异常值通常是与其他数据点明显偏离的点，容易在散点图中显现出来。</span></span><br><span class="line"><span class="string">4.可用于大数据集：散点图适用于大量数据的可视化。虽然对于大数据集，点可能会重叠，但散点图仍然能够展示数据点的总体分布和趋势。</span></span><br><span class="line"><span class="string">5.可用于多变量比较：散点图可以同时显示多个变量之间的关系。通过使用不同颜色或标记样式，可以将多个数据集或组别在同一张散点图上比较，帮助发现模式和差异。</span></span><br><span class="line"><span class="string">5.易于解读：散点图是一种简单而直观的图表类型，不需要复杂的数学知识就可以理解数据之间的关系和趋势。</span></span><br><span class="line"><span class="string">6.用于数据预处理：在数据分析的早期阶段，散点图常常用于对数据进行初步探索和预处理，帮助我们了解数据的特点和潜在问题。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">data = np.random.rand(<span class="number">100</span>, <span class="number">2</span>) * <span class="number">5</span>  <span class="comment"># 100个随机数据点，取值范围在[0, 5)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用K-Means算法进行聚类</span></span><br><span class="line">num_clusters = <span class="number">3</span></span><br><span class="line">kmeans = KMeans(n_clusters=num_clusters, random_state=<span class="number">0</span>)</span><br><span class="line">labels = kmeans.fit_predict(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置颜色列表和标记样式列表</span></span><br><span class="line">colors = [<span class="string">&#x27;tab:blue&#x27;</span>, <span class="string">&#x27;tab:orange&#x27;</span>, <span class="string">&#x27;tab:green&#x27;</span>]</span><br><span class="line">markers = [<span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;D&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制散点图，并根据聚类结果使用不同的颜色和标记样式</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_clusters):</span><br><span class="line">    cluster_data = data[labels == i]</span><br><span class="line">    ax.scatter(cluster_data[:, <span class="number">0</span>], cluster_data[:, <span class="number">1</span>], marker=markers[i], color=colors[i], label=<span class="string">f&#x27;Cluster <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>, fontsize=<span class="number">12</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>, fontsize=<span class="number">12</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表标题</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;聚类结果散点图&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加网格线</span></span><br><span class="line">ax.grid(<span class="literal">True</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"># 单纯进行散点图绘制：</span></span><br><span class="line"><span class="string">import matplotlib.pyplot as plt</span></span><br><span class="line"><span class="string">import numpy as np</span></span><br><span class="line"><span class="string">plt.rcParams[&#x27;font.sans-serif&#x27;] = [&#x27;SimHei&#x27;]  # 为了支持中文字体</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 生成示例数据</span></span><br><span class="line"><span class="string">x = np.random.rand(50)</span></span><br><span class="line"><span class="string">y1 = np.random.rand(50)</span></span><br><span class="line"><span class="string">y2 = np.random.rand(50)</span></span><br><span class="line"><span class="string">y3 = np.random.rand(50)</span></span><br><span class="line"><span class="string">y4 = np.random.rand(50)</span></span><br><span class="line"><span class="string">y5 = np.random.rand(50)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 创建一个Figure对象和一个子图</span></span><br><span class="line"><span class="string">fig, ax = plt.subplots()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 绘制散点图</span></span><br><span class="line"><span class="string">ax.scatter(x, y1, marker=&#x27;o&#x27;, color=&#x27;b&#x27;, label=&#x27;Group 1&#x27;)</span></span><br><span class="line"><span class="string">ax.scatter(x, y2, marker=&#x27;x&#x27;, color=&#x27;g&#x27;, label=&#x27;Group 2&#x27;)</span></span><br><span class="line"><span class="string">ax.scatter(x, y3, marker=&#x27;+&#x27;, color=&#x27;r&#x27;, label=&#x27;Group 3&#x27;)</span></span><br><span class="line"><span class="string">ax.scatter(x, y4, marker=&#x27;*&#x27;, color=&#x27;c&#x27;, label=&#x27;Group 4&#x27;)</span></span><br><span class="line"><span class="string">ax.scatter(x, y5, marker=&#x27;s&#x27;, color=&#x27;m&#x27;, label=&#x27;Group 5&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 添加图例</span></span><br><span class="line"><span class="string">ax.legend()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 添加横纵坐标label</span></span><br><span class="line"><span class="string">ax.set_xlabel(&#x27;X轴&#x27;, fontsize=12)</span></span><br><span class="line"><span class="string">ax.set_ylabel(&#x27;Y轴&#x27;, fontsize=12)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 设置图表标题</span></span><br><span class="line"><span class="string">ax.set_title(&#x27;五组数据的散点图&#x27;, fontsize=14)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 显示图形</span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="气泡图"><a href="#气泡图" class="headerlink" title="气泡图"></a>气泡图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">绘制气泡图的代码</span></span><br><span class="line"><span class="string">甚至可以做有范围、权重的作图。如经典的信号覆盖问题。</span></span><br><span class="line"><span class="string">1.强调气泡大小：气泡的大小代表第三个变量的数值，通过气泡的大小变化，突出数据的差异和趋势。</span></span><br><span class="line"><span class="string">2.多变量对比：气泡图可以同时展示多个数据组，每个数据组的气泡大小和颜色可以代表不同的变量，有助于数据的对比和分析。</span></span><br><span class="line"><span class="string">3.突出数据差异：气泡图通过气泡大小的变化，可以清晰地展示数据之间的差异和分布情况。</span></span><br><span class="line"><span class="string">4.聚焦关键数据：气泡图的大小突出了数据的重要特征，有助于识别关键数据和异常值</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 为了支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 上述字库没负号，因此负号不进行字体变换</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成示例数据</span></span><br><span class="line">x = np.random.rand(<span class="number">50</span>)  <span class="comment"># 随机生成50个x坐标</span></span><br><span class="line">y = np.random.rand(<span class="number">50</span>)  <span class="comment"># 随机生成50个y坐标</span></span><br><span class="line">size = np.random.randint(<span class="number">100</span>, <span class="number">500</span>, <span class="number">50</span>)  <span class="comment"># 随机生成50个气泡的大小</span></span><br><span class="line">color = np.random.rand(<span class="number">50</span>)  <span class="comment"># 随机生成50个气泡的颜色</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Figure对象和一个子图</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制气泡图</span></span><br><span class="line">scatter = ax.scatter(x, y, s=size, c=color, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, alpha=<span class="number">0.7</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加颜色条</span></span><br><span class="line">cbar = plt.colorbar(scatter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加图例</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;气泡图&#x27;</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加横纵坐标label</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;X轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Y轴&#x27;</span>, fontsize=<span class="number">14</span>, fontweight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置颜色条标签字体大小</span></span><br><span class="line">cbar.ax.tick_params(labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置刻度标签字体大小</span></span><br><span class="line">ax.tick_params(axis=<span class="string">&#x27;both&#x27;</span>, which=<span class="string">&#x27;major&#x27;</span>, labelsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置背景颜色</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f0f0f0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表边框颜色</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图形</span></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>python绘图</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>画图</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>玩转matlabplot</title>
    <url>/2023/07/29/%E7%8E%A9%E8%BD%ACmatlabplot/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="常见绘图样式"><a href="#常见绘图样式" class="headerlink" title="常见绘图样式"></a>常见绘图样式</h3><p>我共列出近15种绘图类型见下表格，后续将分别会给出相应代码。此外视频教程可以点击<a href="https://www.bilibili.com/video/BV1wP411k7NM/?share_source=copy_web&vd_source=488d446d240b5ab1ec40c0b45bc0625d">数学建模不知道画什么图？这个视频带你入门python画图！</a>进行学习。<span id="more"></span></p>
<p><img src="/../pic/%E7%BB%98%E5%9B%BE%E5%B0%81%E9%9D%A2.png" alt="封面"></p>
<table>
<thead>
<tr>
<th>画图种类</th>
<th>图像特点</th>
<th>图像用途</th>
</tr>
</thead>
<tbody><tr>
<td>1. 折线图（Line Plot）</td>
<td>连续数据的变化趋势，直线连接数据点</td>
<td>显示数据随时间或其他连续变量的趋势，检测趋势和周期性</td>
</tr>
<tr>
<td>2. 散点图（Scatter Plot）</td>
<td>二维数据点的分布，点在二维平面上</td>
<td>观察两个变量之间的关系，检测数据的聚集和离群点</td>
</tr>
<tr>
<td>3. 柱状图（Bar Chart）</td>
<td>长方形条形表示数据大小，用于比较不同类别的数据</td>
<td>显示离散或分类数据的大小比较，展示排名和分组数据</td>
</tr>
<tr>
<td>4. 直方图（Histogram）</td>
<td>数据的分布情况，用矩形条表示数据频率</td>
<td>分析数据的分布和形状，检测数据的偏态和峰值</td>
</tr>
<tr>
<td>5. 饼图（Pie Chart）</td>
<td>扇形表示数据占比，用于显示分类数据的比例关系</td>
<td>展示数据的百分比构成，用于显示相对比例和份额</td>
</tr>
<tr>
<td>6. 箱线图（Box Plot）</td>
<td>显示数据的统计分布情况，包括中位数、四分位数等</td>
<td>检测数据的离群点和异常值，比较不同组数据的分布</td>
</tr>
<tr>
<td>7. 热力图（Heatmap）</td>
<td>二维数据的颜色编码图，用颜色表示数值大小</td>
<td>可视化矩阵或二维数组，观察数据的相关性和关联程度</td>
</tr>
<tr>
<td>8. 3D图（3D Plot）</td>
<td>三维数据的可视化图像，如散点图、曲面图、柱状图等</td>
<td>展示三维数据的关系和分布，可视化空间数据</td>
</tr>
<tr>
<td>9. 等高线图（Contour Plot）</td>
<td>二维数据的等高线图，用线表示等高线</td>
<td>可视化函数的等高线，显示函数的高低和形状</td>
</tr>
<tr>
<td>10. 气泡图（Bubble Chart）</td>
<td>类似散点图，但点的大小还代表附加数值</td>
<td>同时展示两个维度的数据信息，强调第三维度的差异</td>
</tr>
<tr>
<td>11. 雷达图（Radar Chart）</td>
<td>多维数据的可视化图像，用多边形表示数据分布</td>
<td>显示多个维度数据的相对比较，可视化数据特征和优劣</td>
</tr>
<tr>
<td>12. 网络图（Network Graph）</td>
<td>节点和边构成的图形，用于显示关系网络</td>
<td>可视化节点和边的关系网络，显示节点的中心性和连接性</td>
</tr>
<tr>
<td>13. 树状图（Tree Diagram）</td>
<td>分层结构数据的可视化图像，用于展示层次结构</td>
<td>可视化分层结构数据，展示层级关系和层次结构</td>
</tr>
<tr>
<td>14. 桑基图（Sankey Diagram）</td>
<td>流程和能量转移数据的可视化图像，用箭头表示数据流向</td>
<td>显示流程和能量的转移情况，观察数据的流向和转化情况</td>
</tr>
</tbody></table>
<p> 必备<code>matlabplot</code>库。</p>
<p>可自行拓展<code>plotly</code>, <code>seaborn</code>库。</p>
]]></content>
      <categories>
        <category>python绘图</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>画图</tag>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>《她说》指弹</title>
    <url>/2023/07/20/%E3%80%8A%E5%A5%B9%E8%AF%B4%E3%80%8B%E6%8C%87%E5%BC%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>
        <div id="aplayer-iMIDoBRg" class="aplayer aplayer-tag-marker" style="margin-bottom: 20px;">
            <pre class="aplayer-lrc-content"></pre>
        </div>
        <script>
          var ap = new APlayer({
            element: document.getElementById("aplayer-iMIDoBRg"),
            narrow: false,
            autoplay: false,
            showlrc: false,
            music: {
              title: "她说",
              author: "Lucas",
              url: "/music/她说.mp3",
              pic: "/music/她说.jpg",
              lrc: ""
            }
          });
          window.aplayers || (window.aplayers = []);
          window.aplayers.push(ap);
        </script>

<p>这首曲子我选用的曲谱是来自<a href="https://www.jitashe.org/space/126156/">罗翔StevenLaw</a>老师的改编。</p>
<p>从还原度、难易度以及我个人的听觉感受来说，我认为这个谱子很好地还原了音乐本身，又夹杂了吉他这门乐器的特点。</p>
<p>曲谱传送门：<a href="https://www.jitashe.org/thread/160739/">她说吉他谱(PDF谱,指弹)_林俊杰(JJ)</a></p>
<p>省流版 ↓ ：<span id="more"></span></p>
<p><img src="/../pic/shesays1.png"></p>
<p><img src="/../pic/shesays2.png"></p>
]]></content>
      <categories>
        <category>吉他</category>
        <category>指弹</category>
      </categories>
      <tags>
        <tag>吉他</tag>
        <tag>指弹</tag>
        <tag>林俊杰</tag>
      </tags>
  </entry>
  <entry>
    <title>DCRNN</title>
    <url>/2023/07/18/DCRNN/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文较为细致的从原理层面阐述了<strong>DCRNN</strong>网络结构，并简要介绍了一种应用场景。</p>
<p>DCRNN作为图的时空卷积一个重要分支，将时间信息融于图结构，开创了一个<strong>新的方法</strong>。</p>
<p>在文章最后尝试用图注意力网络进行邻接矩阵的学习。但在后续的学习中，发现其实这个思路早已有人做过，如《graph wavenet》中便引入了<strong>自适应邻接矩阵</strong>。</p>
<p><strong>PDF连接↓</strong></p>
<p><a href="/documents/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E5%A4%A7%E4%BD%9C%E4%B8%9A.pdf">DCRNN理解与延伸</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>马尔科夫过程</tag>
        <tag>扩散卷积</tag>
        <tag>图注意力网络</tag>
      </tags>
  </entry>
  <entry>
    <title>mips常用函数</title>
    <url>/2023/07/17/mips%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="将参数压入栈中"><a href="#将参数压入栈中" class="headerlink" title="将参数压入栈中"></a>将参数压入栈中</h4><p><code>%src</code>即为要存储的参数。<strong>注意栈结构是自顶向下的</strong>。<span id="more"></span></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.macro push(%src)</span><br><span class="line">	sw %src, 0($sp)</span><br><span class="line">	subi $sp, $sp, 4</span><br><span class="line">.end_macro </span><br></pre></td></tr></table></figure>

<hr>
<h4 id="将参数弹出栈"><a href="#将参数弹出栈" class="headerlink" title="将参数弹出栈"></a>将参数弹出栈</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.macro pop(%src)</span><br><span class="line">	addi $sp, $sp, 4</span><br><span class="line">	lw %src, 0($sp)</span><br><span class="line">.end_macro </span><br></pre></td></tr></table></figure>

<hr>
<h4 id="求二维数组的index"><a href="#求二维数组的index" class="headerlink" title="求二维数组的index"></a>求二维数组的index</h4><p>因为二维数组实质上是重新标号的一维数组，其在内存中也是<strong>顺序存储</strong>的，因此对于<code>mips</code>要算一维下标是多少。</p>
<ul>
<li>二维下标为 <code>(i, j)</code></li>
<li>二维数组的<code>size(arr[0] = r)</code></li>
<li><code>%dis</code>为要保存到的目标寄存器</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.macro index(%i, %r, %j, %dis)</span><br><span class="line">	multu %i, %r</span><br><span class="line">	mflo %dis</span><br><span class="line">	add %dis, %dis, %j</span><br><span class="line">	sll %dis, %dis, 2</span><br><span class="line">.end_macro</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>计算机组成</category>
      </categories>
      <tags>
        <tag>mips</tag>
        <tag>计算机组成</tag>
      </tags>
  </entry>
  <entry>
    <title>Lab3实验报告</title>
    <url>/2023/07/17/Lab3%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Lab3实验报告"><a href="#Lab3实验报告" class="headerlink" title="Lab3实验报告"></a>Lab3实验报告</h2><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><h4 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h4><p><img src="/pic/lab31.png"></p>
<p>左边：<code>PDX()</code>的作用是获得地址对应的页目录索引，因此<code>e-&gt;env_pgdir[PDX(UVPT)]</code>的含义为<code>e</code>的对应<code>UVPT</code>（用户页表的起始处的内核虚拟地址）页目录号的进程页目录的值。<span id="more"></span></p>
<p>右边：<code>PADDR()</code>用于将内核虚拟地址转成对应的物理地址，<code>e-&gt;env_pgdir</code>代表进程<code>e</code>的页目录的内核虚拟地址。<code>PTE_V</code>是有效权限位。因此右边的意思就是得到<code>e</code>页目录对应的物理地址，并使其有效。</p>
<p>经过这个操作，用户程序能够通过<code>UVPT</code>来读到它的页表。</p>
<hr>
<h4 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h4><p><img src="/pic/lab32.png"></p>
<ol>
<li><p><code>data</code>是传入的进程控制块指针，共有两处被调用：<code>load_icode_mapper</code> 和 <code>load_icode</code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">load_icode_mapper</span><span class="params">(<span class="type">void</span> *data, u_long va, <span class="type">size_t</span> offset, u_int perm,<span class="type">const</span> <span class="type">void</span> *src, <span class="type">size_t</span> len)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">//......</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">load_icode</span><span class="params">(<span class="keyword">struct</span> Env *e, <span class="type">const</span> <span class="type">void</span> *binary, <span class="type">size_t</span> size)</span> &#123;</span><br><span class="line"> 	<span class="comment">//......</span></span><br><span class="line">    panic_on(elf_load_seg(ph, binary + ph-&gt;p_offset, load_icode_mapper, e));</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>作用为在增加虚拟地址到物理地址映射时提供<code>env_pgdir</code>和<code>env_asid</code>两个参数。</p>
</li>
<li><p>没有<code>data</code>的话，<code>load_icode_mapper</code>无法知道页目录及地址和<code>asid</code>，那么后续的<code>page_insert</code>就不知道要将页面插入到哪里。</p>
</li>
</ol>
<hr>
<h4 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h4><p><img src="/pic/lab33.png"></p>
<p>由指导书的图：</p>
<img src="C:\Users\Lenovo User\AppData\Roaming\Typora\typora-user-images\image-20230531152348375.png" alt="image-20230531152348375" style="zoom:80%;" />

<ol>
<li>首先判断<code>offset</code>是否为0。如果不为0则代表地址未对齐，将<code>offset</code>所在的剩下的<code>BY2PG</code>的<code>binary</code>数据写入对应页的对应地址。</li>
<li>若已经对齐，则直接依此将段内的页映射到物理空间。</li>
<li>当文件大小小于内存大小时，其余空间用0填充，直到填满内存空间。</li>
</ol>
<hr>
<h4 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h4><p><img src="/pic/lab34.png"></p>
<p>指导书中说：这里的 <code>env_tf.cp0_epc</code> 字段指示了进程恢复运行时 PC 应恢复到的位置。而PC是CPU所处的指令地址。Lab2中我们知道了对CPU来说，所见都为虚拟地址。因<code>env_tf.cp0_epc</code> 存储的是虚拟地址。</p>
<hr>
<h4 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h4><p><img src="/pic/lab35.png"></p>
<p>在<code>kern/genex.S</code>中，其中<code>handle_int</code>定义如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NESTED(handle_int, TF_SIZE, zero)</span><br><span class="line">        mfc0    t0, CP0_CAUSE</span><br><span class="line">        mfc0    t2, CP0_STATUS</span><br><span class="line">        and     t0, t2</span><br><span class="line">        andi    t1, t0, STATUS_IM4</span><br><span class="line">        bnez    t1, timer_irq</span><br><span class="line">        // TODO: handle other irqs</span><br><span class="line">timer_irq:</span><br><span class="line">        sw      zero, (KSEG1 | DEV_RTC_ADDRESS | DEV_RTC_INTERRUPT_ACK)</span><br><span class="line">        li      a0, 0</span><br><span class="line">        j       schedule</span><br><span class="line">END(handle_int)</span><br></pre></td></tr></table></figure>

<p>而<code>handle_mod, handle_tlb, handle_sys</code>通过<code>BUILD_HANDLER</code>构造。</p>
<hr>
<h4 id="Q6"><a href="#Q6" class="headerlink" title="Q6"></a>Q6</h4><p><img src="/pic/lab36.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># enable_irq 函数</span><br><span class="line">LEAF(enable_irq)</span><br><span class="line">        li      t0, (STATUS_CU0 | STATUS_IM4 | STATUS_IEc)</span><br><span class="line">        # TATUS_IM4代表第4个中断使能位——时钟中断，STATUS_IEc代表中断使能。</span><br><span class="line">        mtc0    t0, CP0_STATUS</span><br><span class="line">        # 将t0的值赋给CP0_STATUS寄存器，这样它就能够控制中断</span><br><span class="line">        jr      ra</span><br><span class="line">        # 跳转返回</span><br><span class="line">END(enable_irq)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># timer_irq 函数</span><br><span class="line">timer_irq:</span><br><span class="line">        sw      zero, (KSEG1 | DEV_RTC_ADDRESS | DEV_RTC_INTERRUPT_ACK)</span><br><span class="line">        # 将寄存器zero的值（零）存储到内存地址 (KSEG1 | DEV_RTC_ADDRESS | DEV_RTC_INTERRUPT_ACK)中。</span><br><span class="line">        # KSEG1 | DEV_RTC_ADDRESS是时钟的位置。</span><br><span class="line">        # DEV_RTC_INTERRUPT_ACK是设备寄存器的偏移量，代表实时时钟（RTC）的中断应答寄存器。</span><br><span class="line">        # 通过将零存储到该寄存器，可以清除实时时钟中断。</span><br><span class="line">        li      a0, 0</span><br><span class="line">        # 将a0设置为0</span><br><span class="line">        j       schedule</span><br><span class="line">        # 跳转到调度函数</span><br><span class="line">END(handle_int)</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Q7"><a href="#Q7" class="headerlink" title="Q7"></a>Q7</h4><p><img src="/pic/lab37.png"></p>
<ol>
<li><p>调用<code>kclock_init</code>完成时钟初始化，并设置中断频率。</p>
</li>
<li><p>调用<code>enable_irq</code>打开中断</p>
</li>
<li><p>若产生中断异常，PC指向<code>0x800000080</code>，跳转到<code>.text.exc_gen_entry</code>代码段进行异常分发。</p>
<p>因为是中断异常，因此属于0号异常，跳转到<code>handle_init</code></p>
<p>继续判断<code>IM4</code>是否为时钟中断，如果是进而跳转到<code>timer_irq</code></p>
<p><code>timer_irq</code>调用<code>schedule</code>实现进程调度</p>
</li>
<li><p><code>schedule</code>首先取出进程控制块</p>
<p>时间片减一(静态变量<code>count--</code>)</p>
<p>如果：（未调度进程 || 时间片已用完 || 程序不是可运行状态 || <code>yield</code>指定发生切换）</p>
<p>​        则进行进程切换</p>
</li>
<li><p>切换过程：</p>
<p>如果进程快依旧为可运行状态，就将其插入调度队列队尾</p>
<p>从队头取一个进程</p>
<p>剩余时间片数量<code>count</code>重新设置为新进城的优先级</p>
</li>
<li><p>运行当前新的选中进程</p>
</li>
</ol>
<hr>
<hr>
<h3 id="实验难点"><a href="#实验难点" class="headerlink" title="实验难点"></a>实验难点</h3><ol>
<li><p>在调用<code>map_segment()</code>时，要求<code>size</code>必须是页面大小的整数倍。因此在<code>env_init</code>中用到了<code>ROUND</code>函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">env_init</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">    map_segment(base_pgdir, <span class="number">0</span>, PADDR(pages), UPAGES, ROUND(npage * <span class="keyword">sizeof</span>(<span class="keyword">struct</span> Page), BY2PG),PTE_G);</span><br><span class="line">    map_segment(base_pgdir, <span class="number">0</span>, PADDR(envs), UENVS, ROUND(NENV * <span class="keyword">sizeof</span>(<span class="keyword">struct</span> Env), BY2PG),PTE_G);</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化时注意链表插入顺序。</p>
</li>
<li><p>暴露 <code>UTOP</code> 往上到 <code>UVPT</code> 之间所有进程共享的只读空间。重要的一句代码为<code>e-&gt;env_pgdir[PDX(UVPT)] = PADDR(e-&gt;env_pgdir) | PTE_V;</code>，能够使得用户程序直接通过<code>UVPT</code>读取页表。具体解释在思考题中涉及。</p>
</li>
<li><p>对<code>SR</code>的理解。如<code>e-&gt;env_tf.cp0_status = STATUS_IM4 | STATUS_KUp | STATUS_IEp;</code>中后三个参数，分别代表四号中断可以被响应、用户状态以及开启中断。</p>
</li>
<li><p>在<code>elf_load_seg</code>中，<code>load_icode_mapper</code>函数是作为参数传入的，辅助<code>ELF</code>的解析。</p>
</li>
<li><p><code>env_run</code>中保存上下文的核心为保存寄存器状态。因为具体信息都在进程结构体中有所记录，因此只需保存当前相关寄存器值在后续即可进行现场还原。具体来说保存上下文是<code>((struct Trapframe *)KSTACKTOP - 1)</code>结构体中的内容。</p>
</li>
<li><p>对进程调度函数的理解：函数中用到了静态变量，而静态变量的特点为在下次调用函数时，这个变量保存的值不会初始化，依旧是之前的值。因此用来记录进程的时间片剩余情况。当时间片都结束后，如果程序依旧未运行完，也仍要将进程挂起——放在队尾，执行新的进程。</p>
</li>
</ol>
<hr>
<hr>
<h3 id="心得体会"><a href="#心得体会" class="headerlink" title="心得体会"></a>心得体会</h3><p>因为进程相关代码与<code>lab2</code>中的页表处理具有一定的相似性，因此整体来说实验难度要小于<code>lab2</code>。从知识密度来讲，我认为其要比<code>lab2</code>多且难理解。此次试验涉及到了更多底层汇编以及寄存器的相关知识，对理解产生了一定的障碍。</p>
<p>本次实验主要完成了进程的创建、切换、调度等功能，并且引入中断、异常处理等机制，再次丰富了操作系统的完整性。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>BUAA</tag>
        <tag>页表</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title>Lab2实验报告</title>
    <url>/2023/07/17/Lab2%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Lab2实验报告"><a href="#Lab2实验报告" class="headerlink" title="Lab2实验报告"></a>Lab2实验报告</h2><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><h4 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h4><p><img src="/pic/lab21.png"></p>
<p>CPU只能发虚拟地址。因此MIPS汇编程序中的<code>lw</code>、<code>sw</code>指令发送的同样都是虚拟地址。<span id="more"></span></p>
<hr>
<h4 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h4><p><img src="/pic/lab22.png"></p>
<ol>
<li><p>因为部分链表结构要经常性地重复使用，使用宏的话能够大大节省代码的编写长度，并且能够更加方便的进行调试。</p>
</li>
<li><p>通过查看文件中的：单向链表<code>singly-linked list</code>，循环链表<code> Circular queue functions</code>部分，与双向链表相比较，有如下结论：</p>
<p>(1) 单向链表：在某一项后插入是，能够直接进行，因为有<code>sle_next</code>；而在元素前面插入的时候，则需要遍历链表来获取相应位置。在删除的时候，也要先遍历找到位置才能进行删除。比如代码中的 <code>while(curelm-&gt;field.sle_next != (elm))curelm = curelm-&gt;field.sle_next;</code>部分。</p>
<p>(2) 循环链表：删除插入操作与单向链表类似。但因为其首尾元素相连，因此可以直接进行尾插。你能够观察到循环链表与单向链表都有一个负责遍历的部分<code>CIRCLEQ_FOREACH()</code>。</p>
<p>(3) 双向链表：除去对尾部元素的处理，其它部分的插入删除都十分方便，因为他记录了前后两个节点的信息，这也就代表了可以在<code>O(1)</code>复杂度内完成。而对队尾元素的处理需要循环遍历找到，再进行操作。</p>
</li>
</ol>
<hr>
<h4 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h4><p><img src="/pic/lab23.png"></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">C:</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Page_list</span> &#123;</span><br><span class="line">    <span class="keyword">struct</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> &#123;</span><br><span class="line">            <span class="keyword">struct</span> <span class="title class_">Page</span> *le_next;</span><br><span class="line">            <span class="keyword">struct</span> <span class="title class_">Page</span> **le_prec;</span><br><span class="line">        &#125; pp_link;</span><br><span class="line">        u_short pp_ref;</span><br><span class="line">    &#125;* lh_first;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h4><p><img src="/pic/lab24.png"></p>
<p>三级页表页目录基地址：<br>$$<br>PT_{base} + PT_{base}&lt;&lt;9+PT_{base}&lt;&lt;18<br>$$<br>映射到页目录自身的页目录项：<br>$$<br>PT_{base} + PT_{base}&lt;&lt;9+PT_{base}&lt;&lt;18+PT_{base}&lt;&lt;27<br>$$</p>
<hr>
<h4 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h4><p><img src="/pic/lab25.png"></p>
<ol>
<li>指导书中提到：<strong>同一虚拟地址在不同的地址空间中通常映射到不同的物理地址</strong>。因此若没有<code>ASID</code>，则当不同进程提供的<code>TLB</code>不同时，会导致虚拟地址映射到错误的物理地址。</li>
<li><code>ASID</code>段占6位，可以被设置为$2^6&#x3D;64$个不同的值，因此<code>R3000</code> 中可最多容纳<code>64</code>个不同的地址空间。</li>
</ol>
<hr>
<h4 id="Q6"><a href="#Q6" class="headerlink" title="Q6"></a>Q6</h4><p><img src="/pic/lab26.png"></p>
<ol>
<li><p><code>tlb_invalidate()</code>中调用<code>tlb_out()</code></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">tlb_invalidate</span><span class="params">(u_int asid, u_long va)</span> &#123;</span><br><span class="line">        tlb_out(PTE_ADDR(va) | (asid &lt;&lt; <span class="number">6</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>清空映射在<code>TLB</code>中的缓存。</p>
</li>
<li><p>位于<code>kern/tlb_asm.S</code>中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LEAF(tlb_out)</span><br><span class="line">.set noreorder</span><br><span class="line">        mfc0    t0, CP0_ENTRYHI		# 将CP0的ENTRYHI寄存器的值赋予t0</span><br><span class="line">        mtc0    a0, CP0_ENTRYHI		# 将a0寄存器的值赋予CP0的ENTRYHI</span><br><span class="line">        nop</span><br><span class="line">        tlbp						# 根据EntryHi中的Key，查找 TLB 中与之对应的										表项，并将表项的索引存入Index寄存器（若未找									  到匹配项，则 Index 最高位被置 1）</span><br><span class="line">        nop</span><br><span class="line">        mfc0    t1, CP0_INDEX		# 将CP0的INDEX寄存器的值赋予t1</span><br><span class="line">.set reorder</span><br><span class="line">        bltz    t1, NO_SUCH_ENTRY	# 如果t1小于零，即没有在TLB中找到EntryHi对									  应的表项（最高位是1），则跳转到												  NO_SUCH_ENTRY标签处</span><br><span class="line">.set noreorder</span><br><span class="line">        mtc0    zero, CP0_ENTRYHI	# 将CP0的ENTRYHI寄存器的值置为0</span><br><span class="line">        mtc0    zero, CP0_ENTRYLO0	# 将CP0的ENTRYLO0寄存器的值置为0</span><br><span class="line">        nop</span><br><span class="line">        tlbwi						# 以 Index 寄存器中的值为索引，将此时											  EntryHi与EntryLo的值写到索引指定</span><br><span class="line">的 TLB 表项中</span><br><span class="line">.set reorder</span><br><span class="line"></span><br><span class="line">NO_SUCH_ENTRY:</span><br><span class="line">        mtc0    t0, CP0_ENTRYHI		# 将CP0的ENTRYHI寄存器的值复原</span><br><span class="line">        j       ra					# 函数跳回</span><br><span class="line">END(tlb_out)</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h4 id="Q7"><a href="#Q7" class="headerlink" title="Q7"></a>Q7</h4><p><img src="/pic/lab27.png"></p>
<p>X86体系结构中的内存管理机制是通过分页和分段结合的方式实现的，且X86支持物理地址的扩展，从32位扩展到36位或更高位，以支持更大的物理内存容量。相比之下，MIPS中的内存管理主要依靠分页机制，不同于X86中的多级页表结构，MIPS采用的是单级页表结构。MIPS的页表包含固定数量的页表项，每个页表项存储虚拟地址和物理地址的映射关系。MIPS体系结构没有像X86那样的分段机制，只有全局和局部两种地址空间。此外，MIPS中的物理地址空间较小，通常为32位，限制了可寻址的物理内存容量。</p>
<hr>
<hr>
<h3 id="难点分析"><a href="#难点分析" class="headerlink" title="难点分析"></a>难点分析</h3><ol>
<li><p>双向队列插入时候指针的编写顺序排列——为了保证在更改指针指向后，不会再用到原本指向的位置。</p>
<p>(1) 后插：</p>
<img src="/pic/lab29.png" alt="" style="zoom:30%;" />

<p>(2) 尾插：</p>
<img src="/pic/lab210.png" alt="" style="zoom:30%;" />
</li>
<li><p><code>page_alloc()</code>中，进行<code>memset</code>时候要对虚拟地址进行初始化<code>memset(page2kva(pp), 0, BY2PG);</code></p>
</li>
<li><p><code>page_walk()</code>中，最终要转化成虚拟地址后才能进行偏移操作，最终赋值。</p>
<p><code>*ppte = (Pte *)KADDR(PTE_ADDR(*pgdir_entryp)) + PTX(va);</code></p>
</li>
<li><p>二级页表的整体关系以及地址计算。</p>
<img src="/pic/lab211.png" alt="" style="zoom:80%;" />

<ul>
<li><strong>31~22位是页目录中的表项号</strong>，可以根据该表项号从页目录(一级页表)中取出对应的页表项，该页表项中为二级页表首地址。</li>
<li><strong>21~12位是二级页表中的表项号</strong>，从二级页表中取出对应的页表项，该页表项中储存的是虚拟地址所对应的物理页框的首地址。</li>
<li><strong>12~0位是页内偏移</strong>，通过将上面得到的物理页框的<strong>首地址和页内偏移相加</strong>，最终就可以得到虚拟地址对应的物理地址。</li>
</ul>
</li>
</ol>
<hr>
<hr>
<h3 id="实验体会"><a href="#实验体会" class="headerlink" title="实验体会"></a>实验体会</h3><p>这次实验最大的感受就是对C语言指针的理解会很深的影响到这次实验的效率。</p>
<p>在双向链表的过程中，与我曾认识的“一个指向下一个元素，一个指向上一个元素”不同，此处的双向是“一个是指向下一个元素的指针，一个是指向上一个元素的next指针的指针”，因此在编写的时候就要十分注意指针的赋值关系。此外，在插入过程中，如何按顺序更改指针的对象，是很重要的。</p>
<p>通过对整个<code>Lab2</code>的编写，除了扎实了我的C语言基础，也让我对页表有了一定的了解，知道了如何一级一级的进行物理地址的寻找。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>BUAA</tag>
        <tag>地址空间</tag>
      </tags>
  </entry>
  <entry>
    <title>Lab1实验报告</title>
    <url>/2023/07/17/Lab1%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Lab1实验报告"><a href="#Lab1实验报告" class="headerlink" title="Lab1实验报告"></a>Lab1实验报告</h2><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><h4 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h4><p>实验中采用过的<code>objdump</code>为<code>objdump -DS 要反汇编的目标文件名 &gt; 导出文本文件名</code>，通过执行<code>man objdump</code>查看参数含义为：<span id="more"></span></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-D：</span><br><span class="line">disassemble the contents of all sections, not just those expected to contain instructions.</span><br><span class="line">-S:</span><br><span class="line">Display <span class="built_in">source</span> code intermixed with disassembly, <span class="keyword">if</span> possible.</span><br></pre></td></tr></table></figure>

<p>发现<code>-D</code>是反汇编所有的section，<code>-S</code>为尽可能展示出反汇编汇合后的源代码。</p>
<p>执行如下代码，其中<code>.c</code>文件是 $Hello world$ 程序：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mips-linux-gnu-gcc -c c_file.c</span><br><span class="line">mips-linux-gnu-gcc -o c_file c_file.c</span><br><span class="line">mips-linux-gnu-objdump -DS c_file.o &gt; a.txt</span><br><span class="line">mips-linux-gnu-objdump -DS c_file &gt; b.txt</span><br></pre></td></tr></table></figure>

<p>得到<code>a.txt</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">c_file.o：     文件格式 elf32-tradbigmips</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disassembly of section .text:</span><br><span class="line"></span><br><span class="line">00000000 &lt;main&gt;:</span><br><span class="line">   0:   27bdffe0        addiu   sp,sp,-32</span><br><span class="line">   4:   afbe001c        sw      s8,28(sp)</span><br><span class="line">   8:   03a0f025        move    s8,sp</span><br><span class="line">   c:   24020001        li      v0,1</span><br><span class="line">  10:   afc20000        sw      v0,0(s8)</span><br><span class="line">  14:   24020002        li      v0,2</span><br><span class="line">  18:   afc20004        sw      v0,4(s8)</span><br><span class="line">  1c:   8fc30000        lw      v1,0(s8)</span><br><span class="line">  20:   8fc20004        lw      v0,4(s8)</span><br><span class="line">  24:   00621021        addu    v0,v1,v0</span><br><span class="line">  28:   afc20008        sw      v0,8(s8)</span><br><span class="line">  2c:   8fc30000        lw      v1,0(s8)</span><br><span class="line">  30:   8fc20004        lw      v0,4(s8)</span><br><span class="line">  34:   00621023        subu    v0,v1,v0</span><br><span class="line">  38:   afc2000c        sw      v0,12(s8)</span><br><span class="line">  3c:   8fc30000        lw      v1,0(s8)</span><br><span class="line">  40:   8fc20004        lw      v0,4(s8)</span><br><span class="line">  44:   70621002        mul     v0,v1,v0</span><br><span class="line">  48:   afc20010        sw      v0,16(s8)</span><br><span class="line">  4c:   8fc30000        lw      v1,0(s8)</span><br><span class="line">  50:   8fc20004        lw      v0,4(s8)</span><br><span class="line">  54:   004001f4        teq     v0,zero,0x7</span><br><span class="line">  58:   0062001a        div     zero,v1,v0</span><br><span class="line">  5c:   00001010        mfhi    v0</span><br><span class="line">  60:   00001012        mflo    v0</span><br><span class="line">  64:   afc20014        sw      v0,20(s8)</span><br><span class="line">  68:   00001025        move    v0,zero</span><br><span class="line">  6c:   03c0e825        move    sp,s8</span><br><span class="line">  70:   8fbe001c        lw      s8,28(sp)</span><br><span class="line">  74:   27bd0020        addiu   sp,sp,32</span><br><span class="line">  78:   03e00008        jr      ra</span><br><span class="line">  7c:   00000000        nop</span><br><span class="line"></span><br><span class="line">Disassembly of section .reginfo:</span><br><span class="line"></span><br><span class="line">00000000 &lt;.reginfo&gt;:</span><br><span class="line">   0:   e000000c        sc      zero,12(zero)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">Disassembly of section .MIPS.abiflags:</span><br><span class="line"></span><br><span class="line">00000000 &lt;.MIPS.abiflags&gt;:</span><br><span class="line">   0:   00002002        srl     a0,zero,0x0</span><br><span class="line">   4:   01010005        lsa     zero,t0,at,0x1</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">Disassembly of section .pdr:</span><br><span class="line"></span><br><span class="line">00000000 &lt;.pdr&gt;:</span><br><span class="line">   0:   00000000        nop</span><br><span class="line">   4:   40000000        mfc0    zero,c0_index</span><br><span class="line">   8:   fffffffc        0xfffffffc</span><br><span class="line">        ...</span><br><span class="line">  14:   00000020        add     zero,zero,zero</span><br><span class="line">  18:   0000001e        0x1e</span><br><span class="line">  1c:   0000001f        0x1f</span><br><span class="line"></span><br><span class="line">Disassembly of section .comment:</span><br><span class="line"></span><br><span class="line">00000000 &lt;.comment&gt;:</span><br><span class="line">   0:   00474343        0x474343</span><br><span class="line">   4:   3a202855        xori    zero,s1,0x2855</span><br><span class="line">   8:   62756e74        0x62756e74</span><br><span class="line">   c:   75203130        jalx    480c4c0 &lt;main+0x480c4c0&gt;</span><br><span class="line">  10:   2e332e30        sltiu   s3,s1,11824</span><br><span class="line">  14:   2d317562        sltiu   s1,t1,30050</span><br><span class="line">  18:   756e7475        jalx    5b9d1d4 &lt;main+0x5b9d1d4&gt;</span><br><span class="line">  1c:   31292031        andi    t1,t1,0x2031</span><br><span class="line">  20:   302e332e        andi    t6,at,0x332e</span><br><span class="line">  24:   地址 0x0000000000000024 越界。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disassembly of section .gnu.attributes:</span><br><span class="line"></span><br><span class="line">00000000 &lt;.gnu.attributes&gt;:</span><br><span class="line">   0:   41000000        mftc0   zero,c0_index</span><br><span class="line">   4:   0f676e75        jal     d9db9d4 &lt;main+0xd9db9d4&gt;</span><br><span class="line">   8:   00010000        sll     </span><br></pre></td></tr></table></figure>

<p>部分<code>b.txt</code>如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">c_file：     文件格式 elf32-tradbigmips</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disassembly of section .interp:</span><br><span class="line"></span><br><span class="line">00400194 &lt;.interp&gt;:</span><br><span class="line">  400194:       2f6c6962        sltiu   t4,k1,26978</span><br><span class="line">  400198:       2f6c642e        sltiu   t4,k1,25646</span><br><span class="line">  40019c:       736f2e31        0x736f2e31</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">Disassembly of section .MIPS.abiflags:</span><br><span class="line"></span><br><span class="line">004001a8 &lt;.MIPS.abiflags&gt;:</span><br><span class="line">  4001a8:       00002002        srl     a0,zero,0x0</span><br><span class="line">  4001ac:       01010005        lsa     zero,t0,at,0x1</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">Disassembly of section .reginfo:</span><br><span class="line"></span><br><span class="line">004001c0 &lt;.reginfo&gt;:</span><br><span class="line">  4001c0:       b20000f6        0xb20000f6</span><br><span class="line">        ...</span><br><span class="line">  4001d4:       00419010        0x419010</span><br><span class="line"></span><br><span class="line">Disassembly of section .note.gnu.build-id:</span><br><span class="line"></span><br><span class="line">004001d8 &lt;.note.gnu.build-id&gt;:</span><br><span class="line">  4001d8:       00000004        sllv    zero,zero,zero</span><br><span class="line">  4001dc:       00000014        0x14</span><br><span class="line">  4001e0:       00000003        sra     zero,zero,0x0</span><br><span class="line">  4001e4:       474e5500        bz.w    $w14,4155e8 &lt;_end+0x4588&gt;</span><br><span class="line">  4001e8:       2dd459bb        sltiu   s4,t6,22971</span><br><span class="line">  4001ec:       eb089062        swc2    $8,-28574(t8)</span><br><span class="line">  4001f0:       d1251b25        0xd1251b25</span><br><span class="line">  4001f4:       7ff6b1d7        0x7ff6b1d7</span><br><span class="line">  4001f8:       5b89d35a        0x5b89d35a</span><br><span class="line"></span><br><span class="line">Disassembly of section .note.ABI-tag:</span><br><span class="line"></span><br><span class="line">004001fc &lt;__abi_tag&gt;:</span><br><span class="line">  4001fc:       00000004        sllv    zero,zero,zero</span><br><span class="line">  400200:       00000010        mfhi    zero</span><br><span class="line">  400204:       00000001        movf    zero,zero,$fcc0</span><br><span class="line">  400208:       474e5500        bz.w    $w14,41560c &lt;_end+0x45ac&gt;</span><br><span class="line">  40020c:       00000000        nop</span><br><span class="line">  400210:       00000003        sra     zero,zero,0x0</span><br><span class="line">  400214:       00000002        srl     zero,zero,0x0</span><br><span class="line">  400218:       00000000        nop</span><br><span class="line"></span><br><span class="line">Disassembly of section .dynamic:</span><br><span class="line"></span><br><span class="line">0040021c &lt;_DYNAMIC&gt;:</span><br><span class="line">  40021c:       00000001        movf    zero,zero,$fcc0</span><br><span class="line">  400220:       0000003d        0x3d</span><br><span class="line">  400224:       0000000c        syscall</span><br><span class="line">  400228:       00400490        0x400490</span><br><span class="line">  40022c:       0000000d        break</span><br><span class="line">  400230:       004007b0        tge     v0,zero,0x1e</span><br><span class="line">  400234:       00000004        sllv    zero,zero,zero</span><br><span class="line">  400238:       004002fc        0x4002fc</span><br><span class="line">  40023c:       00000005        lsa     zero,zero,zero,0x1</span><br><span class="line">  400240:       004003c4        0x4003c4</span><br><span class="line">  400244:       00000006        srlv    zero,zero,zero</span><br><span class="line">  400248:       00400334        teq     v0,zero,0xc</span><br><span class="line">  40024c:       0000000a        movz    zero,zero,zero</span><br><span class="line">  400250:       00000097        0x97</span><br><span class="line">  400254:       0000000b        movn    zero,zero,zero</span><br><span class="line">  400258:       00000010        mfhi    zero</span><br><span class="line">  40025c:       70000016        udi6    zero,zero,zero,0x0</span><br><span class="line">  400260:       00411010        0x411010</span><br><span class="line">  400264:       70000035        0x70000035</span><br><span class="line">  400268:       00010dac        0x10dac</span><br><span class="line">  40026c:       00000015        0x15</span><br><span class="line">  400270:       00000000        nop</span><br><span class="line">  400274:       00000003        sra     zero,zero,0x0</span><br><span class="line">  400278:       00411020        add     v0,v0,at</span><br><span class="line">  40027c:       70000001        maddu   zero,zero</span><br><span class="line">  400280:       00000001        movf    zero,zero,$fcc0</span><br><span class="line">  400284:       70000005        msubu   zero,zero</span><br><span class="line">  400288:       00000002        srl     zero,zero,0x0</span><br><span class="line">  40028c:       70000006        0x70000006</span><br><span class="line">  400290:       00400000        0x400000</span><br><span class="line">  400294:       7000000a        0x7000000a</span><br><span class="line">  400298:       00000006        srlv    zero,zero,zero</span><br><span class="line">  40029c:       70000011        udi1    zero,zero,zero,0x0</span><br><span class="line">  4002a0:       00000009        jalr    zero,zero</span><br><span class="line">  4002a4:       70000012        udi2    zero,zero,zero,0x0</span><br><span class="line">  4002a8:       0000001d        0x1d</span><br><span class="line">  4002ac:       70000013        udi3    zero,zero,zero,0x0</span><br><span class="line">  4002b0:       00000005        lsa     zero,zero,zero,0x1</span><br><span class="line">  4002b4:       6ffffffe        0x6ffffffe</span><br><span class="line">  4002b8:       00400470        tge     v0,zero,0x11</span><br><span class="line">  4002bc:       6fffffff        0x6fffffff</span><br><span class="line">  4002c0:       00000001        movf    zero,zero,$fcc0</span><br><span class="line">  4002c4:       6ffffff0        0x6ffffff0</span><br><span class="line">  4002c8:       0040045c        0x40045c</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<p>链接后的代码依旧十分体积庞大。</p>
<hr>
<h4 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h4><p>自己编写的<code>readelf</code>并不能编译自身，并且通过实验发现若执行<code>gcc -o hello hello.c</code>后，<code>./readelf hello</code>依旧无输出。通过使用自带的<code>readelf -h</code>指令来查看信息，能够得到如下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">% 使用MAKEFILE中的指令生成的可执行文件hello %</span><br><span class="line">ELF 头：</span><br><span class="line">  Magic：   7f 45 4c 46 01 01 01 03 00 00 00 00 00 00 00 00 </span><br><span class="line">  类别:                              ELF32</span><br><span class="line">  数据:                              2 补码，小端序 (little endian)</span><br><span class="line">  Version:                           1 (current)</span><br><span class="line">  OS/ABI:                            UNIX - GNU</span><br><span class="line">  ABI 版本:                          0</span><br><span class="line">  类型:                              EXEC (可执行文件)</span><br><span class="line">  系统架构:                          Intel 80386</span><br><span class="line">  版本:                              0x1</span><br><span class="line">  入口点地址：               0x8049600</span><br><span class="line">  程序头起点：          52 (bytes into file)</span><br><span class="line">  Start of section headers:          746252 (bytes into file)</span><br><span class="line">  标志：             0x0</span><br><span class="line">  Size of this header:               52 (bytes)</span><br><span class="line">  Size of program headers:           32 (bytes)</span><br><span class="line">  Number of program headers:         8</span><br><span class="line">  Size of section headers:           40 (bytes)</span><br><span class="line">  Number of section headers:         35</span><br><span class="line">  Section header string table index: 34</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">% 使用gcc命令生成的可执行文件hello %</span><br><span class="line">ELF 头：</span><br><span class="line">  Magic：   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 </span><br><span class="line">  类别:                              ELF64</span><br><span class="line">  数据:                              2 补码，小端序 (little endian)</span><br><span class="line">  Version:                           1 (current)</span><br><span class="line">  OS/ABI:                            UNIX - System V</span><br><span class="line">  ABI 版本:                          0</span><br><span class="line">  类型:                              DYN (Position-Independent Executable file)</span><br><span class="line">  系统架构:                          Advanced Micro Devices X86-64</span><br><span class="line">  版本:                              0x1</span><br><span class="line">  入口点地址：               0x1060</span><br><span class="line">  程序头起点：          64 (bytes into file)</span><br><span class="line">  Start of section headers:          13976 (bytes into file)</span><br><span class="line">  标志：             0x0</span><br><span class="line">  Size of this header:               64 (bytes)</span><br><span class="line">  Size of program headers:           56 (bytes)</span><br><span class="line">  Number of program headers:         13</span><br><span class="line">  Size of section headers:           64 (bytes)</span><br><span class="line">  Number of section headers:         31</span><br><span class="line">  Section header string table index: 30</span><br></pre></td></tr></table></figure>

<p>发现二者的文件类型一个为<code>ELF32</code>一个为<code>ELF64</code>。因此初步推断自己编写的只能解析<code>ELF32</code>类型的文件。</p>
<p>因为其不能编译自身，因此查看编写的<code>readelf</code>信息如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ELF 头：</span><br><span class="line">  Magic：   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 </span><br><span class="line">  类别:                              ELF64</span><br><span class="line">  数据:                              2 补码，小端序 (little endian)</span><br><span class="line">  Version:                           1 (current)</span><br><span class="line">  OS/ABI:                            UNIX - System V</span><br><span class="line">  ABI 版本:                          0</span><br><span class="line">  类型:                              DYN (Position-Independent Executable file)</span><br><span class="line">  系统架构:                          Advanced Micro Devices X86-64</span><br><span class="line">  版本:                              0x1</span><br><span class="line">  入口点地址：               0x1180</span><br><span class="line">  程序头起点：          64 (bytes into file)</span><br><span class="line">  Start of section headers:          14488 (bytes into file)</span><br><span class="line">  标志：             0x0</span><br><span class="line">  Size of this header:               64 (bytes)</span><br><span class="line">  Size of program headers:           56 (bytes)</span><br><span class="line">  Number of program headers:         13</span><br><span class="line">  Size of section headers:           64 (bytes)</span><br><span class="line">  Number of section headers:         31</span><br><span class="line">  Section header string table index: 30</span><br></pre></td></tr></table></figure>

<p>发现其依旧为<code>ELF64</code>类型。因此验证了上述猜想——我们编写的 <code>readelf</code> 程序无法解析<code>ELF64</code>类型文件。</p>
<hr>
<h4 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h4><p>在内核启动时，首先进行硬件设备初始化，通过<code>ROM</code>中的<code>bootloader</code>执行。在第二阶段中，在<code>ROM</code>中初始化，读取载入内核。此时要执行引导程序，它能够将内核载入内存并跳转，从而保证内核入库能够被正确跳转到。</p>
<hr>
<hr>
<h3 id="实验难点"><a href="#实验难点" class="headerlink" title="实验难点"></a>实验难点</h3><ol>
<li><p><code>shdr</code>的计算</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">shdr = (Elf32_Shdr *)(binary + ehdr-&gt;e_shoff + i * sh_entry_size);</span><br></pre></td></tr></table></figure>

<p>基地址加上<code>ehdr-&gt;e_shoff</code>，得到整个<code>section</code>的头地址，再加上偏移<code>i</code>个<code>section</code>得到每一个段对应的首地址。</p>
<p>值得注意的是，数据类型要转换成<code>Shdr</code>的指针。尽管指针指向的地址都是一些数字，但是因为数据类型不同，因此对地址的结息方式不同，因此一定要转化数据类型。</p>
</li>
</ol>
<hr>
<ol start="2">
<li><p>将节装填到对应位置</p>
<p>通过阅读内存布局图，能够找到<code>text</code>的基地址为<code>0x80010000</code>，在找到这个位置后，后续的<code>data</code>以及<code>bss</code>顺序分配空间即可。</p>
<p><img src="/pic/lab11.png"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">. = 0x80010000 ;</span><br><span class="line">.text : &#123; *(.text) &#125;</span><br><span class="line">.data : &#123; *(.data) &#125;</span><br><span class="line">.bss : &#123; *(.bss) &#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<ol start="3">
<li><p><code>$sp</code>指针的初始位置</p>
<p><img src="/pic/lab12.png"></p>
<p>因此设置指向<code>0x80400000</code>即可</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">li sp, 0x80400000</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<ol start="4">
<li><p>注意<code>printk()</code>参数的初始化</p>
<p>这个不算是难点，但是很容易忽略。我在起初编写就因为没有初始化而导致输出错误，且找了很久才找到这个问题。</p>
</li>
</ol>
<hr>
<hr>
<h3 id="心得体会"><a href="#心得体会" class="headerlink" title="心得体会"></a>心得体会</h3><p>本次<code>Lab</code>的难度我个人感觉要高于<code>Lab0</code>，知识难度以及知识内容都要难理解且更多。对我个人而言，我认为<code>printk()</code>函数是这个任务中相对简单的，可能是因为我有一定的C语言基础。</p>
<p>而难点我认为是<code>ELF</code>结构的阅读理解。通过查看教程书中的表，理解段与节引用的地方一致但用处不同后，便能够对<code>ELF</code>有更好的认识。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>BUAA</tag>
        <tag>编译</tag>
      </tags>
  </entry>
  <entry>
    <title>Lab0实验报告</title>
    <url>/2023/07/16/Lab0%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Lab0实验报告"><a href="#Lab0实验报告" class="headerlink" title="Lab0实验报告"></a>Lab0实验报告</h2><h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><h4 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h4><p><code>Untracked.txt</code> <span id="more"></span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">位于分支 master</span><br><span class="line"></span><br><span class="line">尚无提交</span><br><span class="line"></span><br><span class="line">未跟踪的文件:</span><br><span class="line">  （使用 <span class="string">&quot;git add &lt;文件&gt;...&quot;</span> 以包含要提交的内容）</span><br><span class="line">        README.txt</span><br><span class="line">        Untracked.txt</span><br><span class="line"></span><br><span class="line">提交为空，但是存在尚未跟踪的文件（使用 <span class="string">&quot;git add&quot;</span> 建立跟踪）</span><br></pre></td></tr></table></figure>

<p><code>Stage.txt</code>，我只<code>add</code> 了 <code>README.txt</code> 这一个文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">位于分支 master</span><br><span class="line"></span><br><span class="line">尚无提交</span><br><span class="line"></span><br><span class="line">要提交的变更：</span><br><span class="line">  （使用 <span class="string">&quot;git rm --cached &lt;文件&gt;...&quot;</span> 以取消暂存）</span><br><span class="line">        新文件：   README.txt</span><br><span class="line"></span><br><span class="line">未跟踪的文件:</span><br><span class="line">  （使用 <span class="string">&quot;git add &lt;文件&gt;...&quot;</span> 以包含要提交的内容）</span><br><span class="line">        Stage.txt</span><br><span class="line">        Untracked.txt</span><br></pre></td></tr></table></figure>

<p><code>Modified.txt</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">位于分支 master</span><br><span class="line">尚未暂存以备提交的变更：</span><br><span class="line">  （使用 <span class="string">&quot;git add &lt;文件&gt;...&quot;</span> 更新要提交的内容）</span><br><span class="line">  （使用 <span class="string">&quot;git restore &lt;文件&gt;...&quot;</span> 丢弃工作区的改动）</span><br><span class="line">        修改：     README.txt</span><br><span class="line"></span><br><span class="line">未跟踪的文件:</span><br><span class="line">  （使用 <span class="string">&quot;git add &lt;文件&gt;...&quot;</span> 以包含要提交的内容）</span><br><span class="line">        Modified.txt</span><br><span class="line">        Stage.txt</span><br><span class="line">        Untracked.txt</span><br><span class="line">        </span><br><span class="line">修改尚未加入提交（使用 <span class="string">&quot;git add&quot;</span> 和/或 <span class="string">&quot;git commit -a&quot;</span>）</span><br></pre></td></tr></table></figure>

<p>不一样。</p>
<p>在刚开始创建这个文件时，并没有<code>add</code>到工作区，因此<code>git</code>对这个文件是未跟踪状态，并提示使用<code>git add</code>建立跟踪。</p>
<p>当<code>add commit</code>一次后，因为<code>git</code>对文件已经跟踪，因此得到了修改状态。但是因为文件并未提交因此显示“尚未加入提交”。</p>
<hr>
<h4 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h4><p><img src="/../pic/lab01.png"></p>
<p><code>add the file</code> 对应命令为 <code>git add</code></p>
<p><code>stage the file</code> 对应的命令为 <code>git add</code></p>
<p><code>commit</code> 命令队应为 <code>git commit</code></p>
<hr>
<h4 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h4><ol>
<li><p><code>git checkout -- printf.c</code></p>
</li>
<li><p><code>git reset HEAD printf.c</code></p>
<p><code>git checkout -- printf.c</code></p>
</li>
<li><p><code>git rm --cached hello.txt</code></p>
</li>
</ol>
<hr>
<h4 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h4><p>提交三次后的哈希值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">commit f3be5781f85bd88784d95abd40c47f0b6ccb3d19 (HEAD -&gt; master)</span><br><span class="line">Author: name &lt;<span class="number">21371240</span>@buaa.edu.cn&gt;</span><br><span class="line">Date:   Mon May <span class="number">8</span> <span class="number">23</span>:<span class="number">57</span>:<span class="number">31</span> <span class="number">2023</span> +0800</span><br><span class="line">    <span class="number">3</span></span><br><span class="line"></span><br><span class="line">commit 78e9c55534e8188525c842a59ceae3e744a40244</span><br><span class="line">Author: name &lt;<span class="number">21371240</span>@buaa.edu.cn&gt;</span><br><span class="line">Date:   Mon May <span class="number">8</span> <span class="number">23</span>:<span class="number">56</span>:<span class="number">53</span> <span class="number">2023</span> +0800</span><br><span class="line">    <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">commit 97b5856f4460429e557000f2b71a1a1d4df5da9d</span><br><span class="line">Author: name &lt;<span class="number">21371240</span>@buaa.edu.cn&gt;</span><br><span class="line">Date:   Mon May <span class="number">8</span> <span class="number">23</span>:<span class="number">56</span>:<span class="number">37</span> <span class="number">2023</span> +0800</span><br><span class="line">    <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>执行<code>git reset --hard HEAD^</code>后，切换到测试2：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">commit 78e9c55534e8188525c842a59ceae3e744a40244</span><br><span class="line">Author: name &lt;<span class="number">21371240</span>@buaa.edu.cn&gt;</span><br><span class="line">Date:   Mon May <span class="number">8</span> <span class="number">23</span>:<span class="number">56</span>:<span class="number">53</span> <span class="number">2023</span> +0800</span><br><span class="line">    <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">commit 97b5856f4460429e557000f2b71a1a1d4df5da9d</span><br><span class="line">Author: name &lt;<span class="number">21371240</span>@buaa.edu.cn&gt;</span><br><span class="line">Date:   Mon May <span class="number">8</span> <span class="number">23</span>:<span class="number">56</span>:<span class="number">37</span> <span class="number">2023</span> +0800</span><br><span class="line">    <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>执行<code> git reset --hard 97b5856f4460429e557000f2b71a1a1d4df5da9d</code>后，切换到测试1：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">commit 97b5856f4460429e557000f2b71a1a1d4df5da9d</span><br><span class="line">Author: name &lt;<span class="number">21371240</span>@buaa.edu.cn&gt;</span><br><span class="line">Date:   Mon May <span class="number">8</span> <span class="number">23</span>:<span class="number">56</span>:<span class="number">37</span> <span class="number">2023</span> +0800</span><br><span class="line">    <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>执行<code> git reset --hard f3be5781f85bd88784d95abd40c47f0b6ccb3d19</code>后，切换到测试3，输出与提交三次后相同。</p>
<hr>
<h4 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h4><ol>
<li>正确。“Git 克隆的是该 Git 仓库服务器上的几乎所有数据，而不是仅仅复制完成你的工作所需要文件。 当你执行 <code>git clone</code> 命令的时候，默认配置下远程 Git 仓库中的每一个文件的每一个版本都将被拉取下来。”</li>
<li>正确。因为全部拉取下来了，因此不需要访问远程仓库。</li>
<li>错误。均被克隆了。</li>
<li>正确。</li>
</ol>
<hr>
<h4 id="Q6"><a href="#Q6" class="headerlink" title="Q6"></a>Q6</h4><p>运行结果为：</p>
<p><img src="/../pic/lab02.png"></p>
<p>能够证明<code>&gt;</code>是重定向输出，对覆盖原始内容；而<code>&gt;&gt;</code>是换行追加输出，即<code>forth</code>在<code>third</code>的下一行。</p>
<hr>
<h4 id="Q7"><a href="#Q7" class="headerlink" title="Q7"></a>Q7</h4><p><code>command</code>文件代码为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> Shell Start... &gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> <span class="built_in">set</span> a = 1 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> a=1 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> <span class="built_in">set</span> b = 2 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> b=2 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">set</span> c = a+b &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;c=$[$a+$b]&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;echo c = $c&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> save c to ./file1 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;echo $c&gt;file1&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> save b to ./file2 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;echo $b&gt;file2&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> save a to ./file3 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;echo $a&gt;file3&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> save file1 file2 file3 to file4 &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;cat file1&gt;file4&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;cat file2&gt;&gt;file4&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;cat file3&gt;&gt;file4&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="built_in">echo</span> file4 to ./result &gt;&gt; <span class="built_in">test</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;cat file4&gt;&gt;result&#x27;</span> &gt;&gt; <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p>得到的输出为：</p>
<img src="../pic/lab03.png" alt="" style="zoom:67%;" />

<p>再次运行<code>test</code>，得到的控制台输出与<code>result</code>文件内容为：</p>
<p><img src="../pic/lab04.png" alt="" style="zoom: 70%;" /><img src="../pic/lab05.png" alt="" style="zoom:67%;" /></p>
<p>在实现过程中，如果<code>echo xxx</code>不加引号的话，那么<code>echo</code>后面的参数依旧有效，即本身有特殊的意义。</p>
<p>直接执行<code>echo echo Shell Start</code>与 <code>echo &#39;echo Shell Start&#39;</code>效果没有区别，但<code>echo echo \$c&gt;file1</code> 是把<code>echo $c</code>的内容写入file1,<code>echo &#39;echo \$c&gt;file1&#39;</code>是把echo $c&gt;file1输出到屏幕。</p>
<img src="../pic/lab06.png" alt="" style="zoom:67%;" />

<p>加了引号后，<code>echo</code>后面的内容统一变成字符串，任何内容都可输出。此时运用<code>&gt;</code> <code>&gt;&gt;</code>输出到文件即可。</p>
<hr>
<hr>
<h3 id="难点分析"><a href="#难点分析" class="headerlink" title="难点分析"></a>难点分析</h3><h4 id="Ex0-1-3："><a href="#Ex0-1-3：" class="headerlink" title="Ex0.1.3："></a>Ex0.1.3：</h4><p><strong>通过指令 bash hello_os.sh AAA BBB.c，在 hello_os.sh 所处的文件夹新建一个名 为 BBB.c 的文件，其内容为 AAA 文件的第 8、32、128、512、1024 行的内容提取。</strong></p>
<p>核心代码为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed 	-n 			-e <span class="string">&#x27;8p;32p;128p;512p;1024p&#x27;</span>    <span class="variable">$1</span> 		 &gt; 		 <span class="variable">$2</span></span><br><span class="line">命令 仅显示处理后结果  指定 	对应处理行数			被处理文件	重定向	  目标文件</span><br></pre></td></tr></table></figure>

<p>考量<code>sed</code>的综合用法。</p>
<hr>
<h4 id="Ex0-3"><a href="#Ex0-3" class="headerlink" title="Ex0.3"></a>Ex0.3</h4><p>核心代码为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep -n <span class="variable">$2</span> <span class="variable">$1</span> | awk -F: <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> &gt; <span class="variable">$3</span></span><br></pre></td></tr></table></figure>

<p>在这里运用了管道方法，将第一个指令的输出作为第二个的输入进行处理。</p>
<p>前一条指令<code>grep</code>用来查找，<code>-n</code>将查找的内容行号也输出，从第一个参数文件中查找第二个参数。</p>
<p>第二个指令输入的格式每一行为<code>number: xxxxx</code>，能注意到，行号与内容通过冒号隔开，因此只需提取冒号分割的第一个参数即可达到要求。</p>
<p><code>awk</code>用来将刚刚得到的文本数据进行处理，<code>-F</code>来制定分隔符，在这里即是<code>:</code>，后期的指令就是将分割的第一个部分打印出来，对应着<code>&#39;&#123;print $1&#125;&#39;</code>，最后重定向到目标文件即可。</p>
<hr>
<h4 id="Ex04"><a href="#Ex04" class="headerlink" title="Ex04"></a>Ex04</h4><ol>
<li><p>本任务的难点一我认为在于通过子目录调用<code>make</code>命令。</p>
<p>我的解决方法为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make -C ./code</span><br></pre></td></tr></table></figure>

<p>在这里<code>-C</code>起到的作用就是切换<code>make</code>的文件夹，实现我们的<code>make</code>目标。在起初我的实验中，如果不加<code>-C</code>，即使格式为<code>make ../code</code>即在后面给号目标路径，最后并不会成功，无法成功<code>make</code>。</p>
</li>
<li><p>本任务难点二在于<code>.c</code>文件的编译链接。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o main.o -c main.c -I ../include/</span><br></pre></td></tr></table></figure>

<p>在编译过程中，除去将<code>.c</code>编译为<code>.o</code>，要注意此时头文件信息再上一级目录。因此为了能够成功编译，要使用<code>-I</code>来调取所需的<code>include</code>。</p>
<p>若想要得到可执行文件，需要将两个文件链接起来。这里我直接一起编译来解决这个问题。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -o main.o -c main.c -I ../include/</span><br></pre></td></tr></table></figure>

<p>此处更好的选择是在上一层目录来进行编译链接。</p>
</li>
</ol>
<hr>
<hr>
<h3 id="体会与感想"><a href="#体会与感想" class="headerlink" title="体会与感想"></a>体会与感想</h3><p>本次实验对一些<code>Linux</code>指令进行了一些学习，能够进行简单的操作。但在进行复杂的操作时，我依旧需要查找资料，对参数进行进一步学习理解才能使用。</p>
<p>对重定向有一定学习，此处内容十分常用且操作相对简单。</p>
<p>在<code>gcc</code>中，我学到了部分参数：跨文件编译、仅编译、链接、指定输出文件名称等等。</p>
<p>初步学会了<code>Makefile</code>的编写，体会到其便利程度。同时尝试运用<code>bash</code>批量处理文件，让我感受到其快捷预方便。</p>
<p>总体来说<code>Lab0</code>是对基础工具的运用，整个任务都能在指导书以及网络搜索渠道来完成。我认为最大的困难不是实现，而是要知道<strong>用什么指令才能实现</strong>。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux</tag>
        <tag>git</tag>
        <tag>BUAA</tag>
      </tags>
  </entry>
  <entry>
    <title>信号与系统总结</title>
    <url>/2023/07/16/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此总结是期末复习产物的重新编排, 其中记录了笔者个人认为的重难点以及易混淆部分. 希望通过这个总结能够让读者更加清晰与快速的抓住内知识的精髓, 更好的理解信号与 系统的核心要义. </p>
<p>此总结并非能够完全替代课本与课件, 其内容省略了大部分的基础知识, 默认读者已经 掌握. 其定位偏向于对知识的梳理以及再巩固, 查漏补缺, 以此加深对知识的理解</p>
<p><strong>最后会给出pdf全文连接</strong>以及书籍的$\LaTeX$<strong>模板</strong>。</p>
<h4 id="目录-笔者想法"><a href="#目录-笔者想法" class="headerlink" title="目录 + 笔者想法"></a>目录 + 笔者想法</h4><p>接下来将主要对整本讲义说了什么进行简要的介绍：<span id="more"></span></p>
<p><img src="/pic/menu0.png"></p>
<p><img src="/pic/menu1.png"></p>
<p><img src="/pic/menu2.png"></p>
<p><img src="/pic/menu3.png"></p>
<p><img src="/pic/menu4.png"></p>
<p><img src="/pic/menu5.png"></p>
<p><img src="/pic/menu6.png"></p>
<p><img src="/pic/menu7.png"></p>
<h4 id="放pdf连接！"><a href="#放pdf连接！" class="headerlink" title="放pdf连接！"></a>放pdf连接！</h4><h5 id="！！！！！！仅供个人学习用途！！！！！！"><a href="#！！！！！！仅供个人学习用途！！！！！！" class="headerlink" title="！！！！！！仅供个人学习用途！！！！！！"></a>！！！！！！仅供个人学习用途！！！！！！</h5><p><a href="/documents/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93.pdf">信号与系统核心总结.pdf</a></p>
<p>[书籍的$\LaTeX$模板](<a href="https://github.com/hydrogenhy/elegant-math-book-latex">hydrogenhy&#x2F;elegant-math-book-latex (github.com)</a>)</p>
<h4 id="↓↓↓可以支持一下qwq↓↓↓"><a href="#↓↓↓可以支持一下qwq↓↓↓" class="headerlink" title="↓↓↓可以支持一下qwq↓↓↓"></a>↓↓↓可以支持一下qwq↓↓↓</h4>]]></content>
      <categories>
        <category>基础学科</category>
        <category>信号与系统</category>
      </categories>
      <tags>
        <tag>学科总结</tag>
      </tags>
  </entry>
  <entry>
    <title>Peterson算法&amp;&amp;信号量实现屏障</title>
    <url>/2023/07/16/Peterson%E7%AE%97%E6%B3%95-%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%AE%9E%E7%8E%B0%E5%B1%8F%E9%9A%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="Q1：详细分析Peterson算法如何实现进程互斥，并且分析方法巧妙之处。"><a href="#Q1：详细分析Peterson算法如何实现进程互斥，并且分析方法巧妙之处。" class="headerlink" title="Q1：详细分析Peterson算法如何实现进程互斥，并且分析方法巧妙之处。"></a>Q1：详细分析Peterson算法如何实现进程互斥，并且分析方法巧妙之处。</h4><p>完整的Peterson算法如下，其中最主要的进程互斥部分<strong>用红色标出</strong>。<span id="more"></span></p>
<img src="/pic/peterson.png" alt="peterson算法" style="zoom:67%;" />

<p>两个主要的全局变量为：<code>interested[i]</code>，用来表示<code>i</code>进程是否要访问临界区；<code>turn</code>代表轮到谁去访问临界区域了。</p>
<p>在<code>while()</code>这一行中，当轮到<code>process</code>访问但另一个进程正在访问时，则会堵塞。整个算法 最精妙的部分就在这里，下面我将分别讨论如果这两个条件只有其中一个是否能够完成任务。</p>
<ol>
<li>当只有<code>turn</code>时。此时也就代表轮到谁谁就可以访问，而另一个只能等待。又因为<code>turn</code>指向的永远是两个进程中的一个，而进程又不是时时刻刻都需要访问临界区，这时候就可能出现<code>turn</code>所指向的进程占用临界区但不使用内部数据的情况，导致另一个进程也无法访问临界区。</li>
<li>当只有<code>interested[i]</code>时。考虑其代码结构的堵塞部分为<code>while(interested[other] == true);</code>，倘若两个进程同时需要访问，这时数组几乎同时置为<code>true</code>，这也就导致两个进程的<code>while()</code>都将会执行，且陷入死循环中。</li>
</ol>
<p>因此将两个标志进行结合，能够有效的解决上述情况：</p>
<ol>
<li>针对情况1，<code>interested[i]</code>数组能够控制是否访问临界区。</li>
<li>针对情况2，<code>turn</code>能够保证始终指向其中一个进程，使另外一个的<code>(turn == process) == False</code>，跳出循环访问临界区，避免死循环。</li>
</ol>
<hr>
<h4 id="Q2：如何使用信号量方法实现屏障（Barrier）"><a href="#Q2：如何使用信号量方法实现屏障（Barrier）" class="headerlink" title="Q2：如何使用信号量方法实现屏障（Barrier）"></a>Q2：如何使用信号量方法实现屏障（Barrier）</h4><p>在这里给出实现的伪代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义全局变量和信号量</span></span><br><span class="line">count = <span class="number">0</span>  <span class="comment">// 计数器，跟踪到达屏障的进程数量</span></span><br><span class="line">mutex = Semaphore(<span class="number">1</span>)  <span class="comment">// 互斥信号量，保护对计数器的访问</span></span><br><span class="line">barrier = Semaphore(<span class="number">0</span>)  <span class="comment">// 屏障信号量，用于控制进程的等待和释放</span></span><br><span class="line"><span class="comment">// 进程在屏障处执行的代码</span></span><br><span class="line">function barrier_code():</span><br><span class="line">    <span class="comment">// 执行自己的任务</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进入屏障之前的代码</span></span><br><span class="line">    mutex.wait()  <span class="comment">// 互斥操作，防止多个进程同时修改计数器</span></span><br><span class="line">    count = count + <span class="number">1</span>  <span class="comment">// 将计数器递增1</span></span><br><span class="line">    mutex.signal()  <span class="comment">// 释放互斥信号量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否所有进程都到达屏障</span></span><br><span class="line">    <span class="keyword">if</span> count == num_processes:</span><br><span class="line">        barrier.signal()  <span class="comment">// 释放屏障信号量，唤醒等待的进程</span></span><br><span class="line"></span><br><span class="line">    barrier.wait()  <span class="comment">// 进程进入等待状态，等待其他进程到达屏障</span></span><br><span class="line">    barrier.signal()  <span class="comment">// 释放屏障信号量，允许其他进程继续执行</span></span><br></pre></td></tr></table></figure>

<p>下面我将对其进行详细的解释：</p>
<ol>
<li><p><code>mutex</code>：这是对计数器的保护。能够注意到其初值为1，当有一个进程需要<code>count+1</code>时候，<code>mutex</code>会因为<code>wait()</code>函数减一而变为0，此时其它进程走到这里时变会进行等待，知道计数器加1后执行了<code>signal()</code>，其它进程 才能够继续访问计数器。</p>
</li>
<li><p><code>barrial</code>：进程到达之前都是0或者负值，到达后取正值。其初始值为0，当<code>count&lt;num_processes</code>时，其他进程都会执行到<code>barrier.wait()</code>后进行等待，因为<code>barrier</code>的值一直小于等于0。知道<code>if</code>判断条件成立后，<code>barrier.signal()</code>使得队列中第一个等待的进程被激活，而后最后一个进程进入等待队列。因为第一个进程下一条语句为<code>barrier.signal()</code>，因此队列中的进程再次被释放。以此类推形成连锁反应，最终所有进程都被释放，也就达到了所有进程在此处同时继续运行的效果。而<code>barrier</code>的数值最终会变为<br>$$<br>barrier_ori + num_{signal} - num_{wait}&#x3D;0+num_processes+1-num_processes&#x3D;1<br>$$</p>
</li>
</ol>
<p>整个系统以最基本的信息量为基础，通过<code>barrier</code>与<code>mutex</code>的<code>PV</code>操作，实现了<code>barrier</code>，实现了多进程的并发。</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>进程互斥</tag>
        <tag>信号量</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/07/16/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="This-is-a-page-test"><a href="#This-is-a-page-test" class="headerlink" title="This is a page test."></a>This is a page test.</h3><span id="more"></span>

<h4 id="code-test"><a href="#code-test" class="headerlink" title="code test"></a>code test</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hello world&quot;</span>) <span class="comment">#abcde</span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;hello world\n&quot;</span>); <span class="comment">//abcde</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="font-test"><a href="#font-test" class="headerlink" title="font test"></a>font test</h4><p>这是一段<strong>中文</strong>，我将分别运用<strong>加粗</strong>、<em>斜体</em>、<u>下划线</u>、<del>删除线</del>来进行测试。</p>
<hr>
<h4 id="Inline-test"><a href="#Inline-test" class="headerlink" title="Inline test"></a>Inline test</h4><p>here is a function called <code>print()</code></p>
<p>here is a formula: $a+b&#x3D;c$</p>
<hr>
<h4 id="math"><a href="#math" class="headerlink" title="math"></a>math</h4><p>$$<br>\mathscr{L}{[f(t)g(t)]} &#x3D; F(s)\otimes G(s)<br>$$</p>
<hr>
<h4 id="url-test"><a href="#url-test" class="headerlink" title="url test"></a>url test</h4><p><a href="https://www.bilibili.com/">哔哩哔哩 (゜-゜)つロ 干杯~-bilibili</a></p>
<hr>
<h4 id="pic-test"><a href="#pic-test" class="headerlink" title="pic test"></a>pic test</h4><p><img src="/pic/test.png" alt="test_pic"></p>
]]></content>
      <categories>
        <category>test_categories</category>
      </categories>
      <tags>
        <tag>test_tag</tag>
      </tags>
  </entry>
</search>
